% Definimos el estilo del documento
\documentclass[12pt,A4,spanish]{book}

% Definimos los márgenes de la página
\usepackage[lmargin=2.5cm,rmargin=1.5cm,tmargin=3.0cm,bmargin=3.0cm]{geometry}
%\usepackage{graphicx}
\usepackage[latin1]{inputenc} % Caracteres con acentos.
\usepackage[spanish]{babel} % Caracteres con acentos.
%Para incluir figuras .bmp, .jpeg, .png....
\usepackage[pdftex]{graphicx} % PDFLaTeX
\DeclareGraphicsExtensions{.png,.pdf,.jpg,.gif}
%Paquete para hipervínculos
\usepackage{hyperref}
%Configuración del coloreado
\hypersetup{
   colorlinks,
   citecolor=black,
   filecolor=black,
   linkcolor=black,
   urlcolor=blue %Las url se muestran en azul
}
%Path de las imágenes
\graphicspath{ {./images/} } 
%Para poner color a la fuente
\usepackage{color}
%Párrafos
\setlength{\parskip}{1pc}
%Minimizar las divisiones de las palabras
\sloppy
%Permitir poner páginas en horizontal
\usepackage{pdflscape}
%Para usar apéndice
\usepackage{appendix}

\begin{document}
\renewcommand{\tablename}{Tabla}
\renewcommand{\listtablename}{Índice de Tablas}
%\renewcommand{\chaptername}{Cap\'{\i}tulo}
\title{ADAPTACIÓN, PARA LA LIBRERÍA DE CÓDIGO LIBRE INSIGHT TOOLKIT, DE UN MÉTODO AUTOMÁTICO DE SEGMETACIÓN DE VASOS CORONARIOS EN IMÁGENES DE TOMOGRAFÍA COMPUTARIZADA}
\author{Sara Arencibia García}
\date{Facultad de Informática.\\
        Universidad de Las Palmas de G.C.}
\thispagestyle{empty}
\maketitle

%Definimos página posterior a la portada 
\thispagestyle{empty}
\noindent Facultad de Informática. Universidad de Las Palmas de G.C.

% Definimos página con datos sobre el proyecto 
\newpage
\thispagestyle{empty}
\section*{Proyecto fin de carrera}
  
\bigskip
\noindent {\bf Título: } Adaptación, para la librería de código libre Insight Toolkit, de un método automático de segmentación de vasos coronarios en imágenes de tomografía computarizada\\
{\bf Apellidos y nombre del alumno: } Arencibia García, Sara\\
{\bf Fecha :  } Julio 2010 \\

\vspace{2cm}
\noindent{\bf Tutores: } \\
Krissian, Karl \\
Álvarez León, Luis \\
Esclarín Monreal, Julio \\

% Definimos página posterior 
\newpage
\thispagestyle{empty}
\noindent Facultad de Informática. Universidad de Las Palmas de G.C.
\newpage

% Definimos una  pagina para los agradecimientos
\newpage
\thispagestyle{empty}
\section*{Agradecimientos}
Desde que empecé esta etapa de mi vida me decía, esto nunca va a terminar, esto es un camino sin fin... pero más tarde que temprano he obtenido mi recompensa y he alcanzado mi meta. Por el camino han pasado muchas personas que han ayudado a que el ascenso sea menos duro y más ameno, algunas siguen a mi lado y otras decidieron retirarse... a todas ellas les agradezco el apoyo que me han brindado en todo momento.

Quiero hacer una especial mención a ciertas personas que en mayor o menor medida me han soportado mis neuras y mis quebraderos de cabeza.

En primer lugar, y no podría ser de otra manera, quiero agradecer el trabajo que han realizado mis tutores, en especial Karl, que me ha ayudado siempre que lo he necesitado y ha sido muy paciente conmigo.

A mis padres, por ser cómo son y por estar siempre ahí, apoyándome y haciéndome ver de todo la parte buena. Sin ellos no habría llegado dónde estoy, sin ellos nada sería igual. 

A toda mi familia, que, aún estando lejos han sabido darme fuerzas en todo momento.

A mi novio, que ha hecho todo lo posible para ayudarme en los momentos en los que me volvía loca y no veía la luz.

A Dani, gran ayuda, gran apoyo y gran persona. Sin él, el camino hubiese sido muchísimo más duro.

A Raúl, que gracias a sus locuras esta andadura ha tomado otro color.

A mi Nano, que con su sinceridad y claridad ha conseguido hacerme ver las cosas de otra manera.

A Adaya, que me ha alegrado tantas y tantas noches.

A Charly, un pequeño incomprendido.

A todos ellos, muchísimas gracias por formar parte de esta etapa de mi vida.

% Definimos página posterior 
\newpage
\thispagestyle{empty}
\noindent Facultad de Informática. Universidad de Las Palmas de G.C.
\newpage
\setcounter{page}{1}
\tableofcontents
\listoffigures
\listoftables

% Definimos página posterior 
\newpage
\thispagestyle{empty}
\noindent Facultad de Informática. Universidad de Las Palmas de G.C.
\newpage

\chapter{Introducción}
Son varios los factores que han motivado el desarrollo de este proyecto. Uno de los principales es que el rápido avance tanto de la tecnología médica como informática proporciona un marco en el que desarrollar métodos que proporcionen aplicaciones de ayuda al diagnóstico. En este sentido, el análisis y visualización de imágenes 3D es bastante útil. 

Otro de los motivos ha sido el desarrollo de software libre y la utilización del mismo en la comunidad científica. Gracias a las librerías ITK y al software de tratamiento de imágenes AMILab
hemos conseguido demostrar la fácil interacción entre ambos y posibilitar la difusión tanto de uno
como del otro.

Por último, pero no menos importante, hemos contribuido al continuo cambio y mejora del software AMILab, permitiendo que su uso sobre otras plataformas sea más estable y accesible.

\section{Estado actual del tema}
La técnica de tomografía computarizada es el fundamento básico de este proyecto, ya que sin la cual ninguno de los algoritmos implementados tendría sentido. Es por ello, que es importante abordar este tema y comprender la importancia que tiene hoy en día.

La tomografía computarizada es un método de formación de imágenes médicas basado en la captación de múltiples imágenes (denominadas cortes) a lo largo de un eje. Se utiliza el procesamiento de la geometría digital para generar imágenes en 3D del interior de un objeto partiendo de una gran serie de imágenes en 2D de rayos X tomadas en torno a un único eje de rotación. Combina el uso del ordenador con la rotación del dispositivo de rayos X para crear imágenes detalladas de la sección transversal o capas de los diferentes órganos y partes del cuerpo como los pulmones, hígado, riñones, páncreas, pelvis, extremidades, cerebro, columna vertebral y los vasos sanguíneos.

Entre las diversas técnicas de formación de imágenes como la resonancia magnética y los rallos X, la tomografía computarizada es la única que posee la habilidad de combinar tejidos blandos, huesos y vasos sanguíneos. Por ejemplo, la formación de la imagen de la cabeza mediante rayos X sólo puede mostrar la densidad de las estructuras de los huesos del cráneo. La angiografía por rayos X de la cabeza sólo es capaz de representar los vasos sanguíneos de la misma y del cuello, pero no los tejidos blandos del cerebro. La resonancia magnética hace un excelente trabajo mostrando los tejidos blandos y los vasos sanguíneos, pero no es capaz de dar en detalle las estructuras óseas. La tomografía computarizada de la cabeza permite a los médicos ver los tejidos blandos como los ventrículos del cerebro o la materia gris y blanca. Mediante esta técnica los médicos pueden elegir ver los tejidos blandos, las estructuras óseas o los vasos sanguíneos.

Por tanto la tomografía computarizada es:
\begin{itemize}
\item Una de las herramientas mejores y más rápidas para el estudio del pecho, abdomen y pelvis porque proporciona vistas detalladas y secciones transversales de todos los tipos de tejidos.
\item A menudo es el método más adecuado para el diagnóstico de muchos tipos de cánceres, incluidos los de pulmón, hígado y cáncer de páncreas, ya que la imagen obtenida permite al médico confirmar la presencia del tumor, medir su tamaño, ubicación exacta y grado del mismo ayudándose para ello de los tejidos cercanos.
\item Un examen que desempeña un papel importante en la detección, diagnóstico y tratamiento de enfermedades vasculares que pueden conducir a accidentes cerebro vasculares, insuficiencia renal o incluso la muerte. La tomografía computarizada se utiliza comúnmente para evaluar la embolia pulmonar así como para los aneurismas de la aorta abdominal.
\item Inestimable en el diagnóstico y tratamiento de problemas de columna vertebral y lesiones en las manos, pies y otras estructuras esqueléticas porque incluso puede mostrar claramente huesos muy pequeños, así como los tejidos circundantes, tales como el músculo y los vasos sanguíneos.
\end{itemize}

Los médicos a menudo utilizan la tomografía computarizada para:
\begin{itemize}
\item Identificar rápidamente las lesiones de los pulmones, corazón, vasos sanguíneos, hígado, bazo, riñones y otros órganos internos en los casos de traumatismo.
\item La guía de las biopsias y otros procedimientos, como drenajes de abscesos y tratamientos del tumor mínimamente invasivos.
\item Planificar y evaluar los resultados de la cirugía.
\item Planificar y administrar adecuadamente los tratamientos de radiación para tumores.
\item Medir la densidad mineral ósea para la detección de la osteoporosis.
\end{itemize}

A día de hoy el tratamiento de imágenes de tomografía computarizada está muy extendido, siendo muchos los que se han decidido a abordar este tema. A continuación se citan aquellos que al igual que la librería elegida para el desarrollo de este proyecto se centran en el tratamiento de imágenes promoviendo el uso del software libre.

\subsection{MITK}
`` Medical Imaging Interaction Toolkit ''  es un software libre para el desarrollo de software para el procesamiento interactivo de imágenes médicas. MITK combina ITK y VTK con las librerías basadas en PIC de DKFZ. MITK ofrece un conjunto de características relevantes para el desarrollo de software interactivo para imágenes médicas que ITK y VTK no poseen, como:
\begin{itemize}
\item Múltiples y coherentes vistas de la misma información.
\item Un concepto interactivo basado en máquinas de estado, que le ayuda a estructurar mecanismos de interacción complejos.
\item Un concepto de deshacer /rehacer para las interacciones.
\item Organiza toda la información de la aplicación en un repositorio jerárquico y central. La jerarquía permite representar relaciones lógicas (como que un ventrículo es una parte del corazón).
\item Descripción de los datos por propiedades arbitrarias para la comunicación entre módulos del programa o para el control de renderización.
\end{itemize}


MITK reutiliza prácticamente todo de VTK e ITK. Por lo tanto, no es en absoluto un competidor para VTK o ITK, sino una extensión, que trata de facilitar la combinación de ambos y añadir las características antes mencionadas. Aunque es principalmente una guía y no una aplicación, MITK ofrece apoyo en los niveles de aplicación, por ejemplo, para la combinación estructurada de módulos, o para combinar y cambiar entre una funcionalidad para la segmentación y otra para la correspondencia.

\subsection{ITK (librería elegida)}
ITK son un conjunto de herramientas libres para la realización de correspondencias y segmentación en dos, tres o más dimensiones (análisis de imágenes).


La segmentación es un proceso de identificación y clasificación de la información encontrada en una representación digital de una muestra. Normalmente la representación de la muestra es una imagen adquirida mediante instrumentación médica como escáneres de tomografía computarizada (CT) o de resonancia magnética (MRI). La correspondencia es la tarea de alinear o desarrollar las correspondencias entre datos. Por ejemplo, en un entorno médico, un escáner CT puede ser alineado con un escáner MRI a fin de combinar la información contenida en ambos.


Debido a que ITK es un proyecto de código abierto, los desarrolladores de todo el mundo pueden utilizar, comprobar, mantener y extender el software. ITK utiliza un modelo de desarrollo de software llamado programación extrema. La programación extrema cambia la metodología habitual de desarrollo software por un proceso iterativo y simultaneo de diseño-implementación-prueba-versión. La clave de esta programación extrema es la comunicación y la prueba. La comunicación entre los miembros de la comunidad de ITK es la que ayuda a manejar la rápida evolución del software. La prueba es la que mantiene el software estable. En ITK, un extenso proceso de pruebas día a día son los que determinan la calidad.

\subsection{VTK}
VTK es un software libre para gráficos 3D, modelado, procesamiento de imágenes, renderización de volúmenes, visualización científica y visualización de la información. 


VTK es usado en todo el mundo en aplicaciones comerciales, de investigación y de desarrollo y es la base de muchas aplicaciones de visualización avanzada como: ParaView, VisIt, VisTrails, Slicer, MayaVi, and OsiriX.

\subsection{IGSTK}
IGSTK es un componente de alto nivel basado en un framework que proporciona funcionalidades comunes para aplicaciones de cirugía guiada por imágenes. Este framework está basado en un conjunto de componentes de alto nivel integrados con otras librerías de bajo nivel y código abierto y con interfaces de programación de aplicaciones (API) de los vendedores de hardware.


Lo más importante de IGSTK es la robustez. IGSTK proporciona las siguientes funcionalidades de alto nivel: habilidad para leer y mostrar imágenes médicas incluyendo CT y MRI en formato DICOM; una interfaz común para el seguimiento de hardware; una interfaz gráfica de usuario y capacidad de visualización incluyendo vistas en los cuatro cuadrantes (axial, sagital, coronal y 3D) así como una vista axial de múltiples capas; correspondencia: el punto de correspondencia y un medio para seleccionar estos puntos; servicios para logging, manejo de excepciones y resolución de problemas.

\subsection{VTKEdge}
VTKEdge es una librería de visualización avanzada y de técnicas de procesamiento de datos que complementan a VTK, así como módulos propios que permiten el uso de estas técnicas con ParaView. VTKEdge no reemplaza a VTK, sino que se compila con VTK para proporcionar funcionalidades adicionales.


Las enfermedades de los vasos coronarios son una de las causas de muerte más frecuentes, es por ello que la detección de vasos a partir de imágenes de tomografía computarizada es un método de gran ayuda a nivel médico para la detección de dichas enfermedades. Partiendo de este hecho se ha realizado por parte de un equipo de investigadores un método de detección de vasos coronarios, intentando obtener la línea media de los mismos lo más realista posible. Esto permite la visualización, planificación de operaciones y la segmentación sobre los mismos.


A día de hoy el método escogido para la obtención de la línea media de los vasos coronarios compite con otros 13 métodos.
Aparte de lo comentado anteriormente, es de vital importancia tener un software de visualización de imágenes que ayude al diagnóstico de las posibles enfermedades existentes. Es por ello que se ha creado un software para el tratamiento de imágenes, denominado AMILab.

Existe un amplio abanico de programas que proporcionan funcionalidades para el tratamiento y procesamiento de imágenes. A continuación citaremos algunos que se utilizan en el ámbito médico.

\subsection{OsiriX}
OsiriX es un software de procesamiento de imágenes dedicado principalmente a imágenes en formato DICOM. Ha sido específicamente diseñado para la navegación y visualización de imágenes en varias dimensiones: visor 2D, 3D, 4D y 5D. El visor 3D ofrece todos los modos actuales de renderizado, como son, la reconstrucción multiplanar, el renderizado de superficies, el renderizado volumétrico y la proyección de la intensidad máxima.

Al mismo tiempo OsiriX es un software de procesamiento de imágenes para investigación médica.\cite{osirix}

\subsection{Slicer}
Slicer es un software de código abierto y libre que se utiliza para la visualización y análisis de imágenes. Se diseñó pensando en que fuese multiplataforma.\cite{slicer}

Permite el registro de imágenes, el procesamiento DTI, posee una interfaz para los dispositivos externos para el apoyo de guía por imagen, permite el renderizado volumétrico.
Cuenta con una organización modular que permite la fácil incorporación de nuevas funcionalidades y proporciona una serie de características genéricas que no están disponibles en las herramientas de la competencia.

Las capacidades de visualización de Slicer permiten mostrar cortes de imágenes, crear superficies a través de las imágenes y un alto rendimiento de renderizado volumétrico.\cite{slicer2}


\section{Objetivos}
El proyecto que se plantea viene motivado por la necesidad de implementar un algoritmo de segmentación de vasos coronarios para código libre.


Para la realización de este objetivo se partirá de un método de segmentación de vasos coronarios ({\em A Minimal Cost Path and Level Set Evolution Approach for Carotid Bifurcation Segmentation}), de las librerías de código abierto Insight Toolkit y del software para tratamiento de imágenes AMILab.


Lo que se plantea es el paso de la totalidad o parte del método de segmentación de vasos coronarios seleccionado a las librerías de código abierto Insight Toolkit, permitiendo de esta forma la divulgación de este método a través de estas librerías de programación. Una vez realizada la implementación del método seleccionado se pretende incluir dicha herramienta en el software de tratamiento de imágenes AMILab.


Por tanto, como objetivos principales de este proyecto se pretende:
\begin{itemize}
\item Adaptación de la totalidad o parte del método de segmentación de vasos coronarios a las librerías de código abierto Insight Toolkit.
\item Inclusión de la herramienta desarrollada en el software de tratamiento de imágenes AMILab.
\item Entender el funcionamiento global de los algoritmos actuales, sin necesariamente entrar en los detalles.
\end{itemize}

\section{Metodología}
Dado el carácter de este proyecto se ha tomado la decisión de optar por una metodología de desarrollo en espiral combinada con un desarrollo basado en componentes.

El desarrollo en espiral se basa en un conjunto de iteraciones, en las que en cada una de ellas se van incrementando las funcionalidades del sistema partiendo de lo ya implementado. Por tanto, el sistema va creciendo poco a poco y se va probando a medida que una nueva funcionalidad es creada. Al final se consigue un sistema global formado por múltiples funcionalidades individuales.

La ingeniería de sistemas basada en componentes abarca dos actividades de ingeniería paralelas: la ingeniería de dominios y el desarrollo basado en componentes. La ingeniería de dominios explora un dominio de aplicación con la intención específica de encontrar componentes funcionales, de comportamiento y de datos que sean candidatos para la reutilización. El desarrollo basado en componentes:
\begin{itemize}
\item Selecciona componentes potenciales para la reutilización.
\item Califica los componentes para asegurarse de que encajan adecuadamente en la arquitectura para el sistema.
\item Adapta los componentes si se deben hacer modificaciones para integrarlos adecuadamente.
\item Integra componentes para formar subsistemas y la aplicación como un todo.
\end{itemize}

Por tanto, combinando estas dos metodologías se ha conseguido desarrollar un sistema poco a poco y con la reutilización de componentes ya existentes, tanto de ITK como de AMILab.

En cada iteración, se ha establecido una fase de análisis, diseño, implementación y prueba.

\section{Recursos necesarios}
AMILab es un software que puede ser utilizado en cualquier plataforma, es por esto que se ha decidido usar Windows XP para el desarrollo de este proyecto. Esto ha propiciado que AMILab sea más robusto y estable bajo este S.O., ya que al tener que utilizarlo para el desarrollo del proyecto ha ayudado a su mejora.

Otro detalle a tener en cuenta serán los recursos hardware necesarios para la fluidez del desarrollo del proyecto y la validación del mismo. Debemos recordar que los algoritmos implementados serán aplicados sobre imágenes de tomografía computarizada que ocupan un gran espacio en disco duro. Por lo que será necesaria la presencia de un dispositivo de almacenamiento de gran capacidad y un ordenador que sea capaz de procesar de manera eficiente y potente todo este material. 

Por último, se ha de tener especial cuidado con los datos a utilizar, ya que están sujetos a unas reglas de utilización y distribución. Los datos a utilizar provienen del ``Challenge MICCAI'2009 workshop'' y serán 14 datos distintos pertenecientes a diferentes departamentos de radiología.

Una vez comentados estos puntos pasaremos a numerar el software y el hardware usado para este proyecto:
\begin{itemize}
	\item Software
\begin{itemize}
	\item Cmake
	\item Microsoft Visual Studio 2008
	\item Librerías Insight Toolkit
	\item AMILab
	\item Subversion	
\end{itemize}
	\item Hardware
\begin{itemize}
	\item Disco Duro cómo mínimo de 200GB
	\item Un sobremesa Quadcore con 4Gb de RAM para la fase de validación y obtención de resultados. Un portátil Centrino Duo con 1GB de RAM para el resto de las etapas. Esto es debido al tamaño de las imágenes utilizadas y a las limitaciones de Windows.
\end{itemize}
\end{itemize}

\section{Plan de trabajo y temporización}
A continuación se define el plan de trabajo a seguir. Debido a la metodología de desarrollo elegida las etapas aquí descritas se repetirán en cada iteración hasta llegar al sistema completo.

Por tanto, en cada etapa se describirán los pasos seguidos a la hora de desarrollar este proyecto.

\subsection{Análisis}
En una primera etapa se hará una fase de análisis sobre las herramientas a utilizar, profundizando de manera exhaustiva en el manual de las librerías a utilizar (Insight Toolkit). Esto permitirá mayor soltura a la hora del diseño e implementación de las nuevas clases requeridas. Para la realización de esta etapa se desarrollarán varias tareas que ayudarán a una mejor asimilación de los conceptos, como son:
\begin{itemize}
	\item Análisis de ejemplos simples.
	\item Análisis de ejemplos complejos.
\end{itemize}

A continuación, se podrá realizar un estudio del software de tratamiento de imágenes AMILab. Para conocerlo a fondo se seguirán los tutoriales disponibles y se ejecutarán los scripts, comprobando y entendiendo en todo caso los resultados obtenidos.

Como segunda etapa de esta fase se realizará un análisis de las necesidades de las clases a implementar. Para ello se deberá hacer un estudio de las relaciones existentes entre clases.

Como tercera etapa de esta fase se debe hacer un estudio de los diferentes métodos que intervienen en el algoritmo completo de segmentación de carótidas.
\subsection{Diseño}
En esta fase se pretende determinar el diseño de las nuevas clases a implementar, teniendo en cuenta la fase de análisis previa y el diseño por defecto de las librerías Insight Toolkit.

\subsection{Implementación}
Durante la fase de implementación se desarrollarán las clases propiamente dichas. Esta fase vendrá regida por las fases de análisis y diseño estudiadas anteriormente.

\subsection{Validación}
La última fase del proyecto es una de las más importantes ya que en ella se realizarán los test que validarán las clases implementadas.

Dentro de los test de validación tendremos varias partes:
\begin{itemize}
	\item Definición de los test de validación.
	\item Aplicación de los test de validación.
	\item Análisis de los resultados obtenidos, los cuales serán cotejados con los ya existentes. Estos provienen del método del que se parte para la realización de este proyecto.
\end{itemize}

\chapter{Análisis}
\section{Herramientas}
En esta primera fase del análisis se pretende dar una visión global de las herramientas a utilizar, sus principales características, ventajas e inconvenientes. Partiremos en un primer lugar de la herramienta fundamental en la que se basa todo el desarrollo de este proyecto, las librerías de código abierto Insight Toolkit.

\subsection{Insight Toolkit}
\subsubsection{Introducción}
Las librerías Insight Toolkit son de código abierto, multiplataforma, orientadas a objetos y se utilizan para procesar, segmentar y hacer correspondencia de imágenes. Insight Toolkit está diseñado para ser usado con facilidad una vez que se aprende diseño orientado a objetos y su metodología de implementación. A su vez, Insight Toolkit proporciona métodos novedosos y a la orden del día para segmentación y correspondencia de imágenes en cualquier dimensión posible (2D, 3D,.., ND).

Las principales metas de Insight Toolkit son:
\begin{itemize}
	\item Soportar el proyecto ``Visible Human'' (NLM).
	\item Crear una fundación para la investigación futura.
	\item Crear un repositorio de algoritmos esenciales.
	\item Desarrollar una plataforma para productos de desarrollo avanzados.
	\item Apoyo comercial a la aplicación de la tecnología.
	\item Crear convenciones para trabajos futuros.
	\item Crecer como una comunidad que se alimenta del software de usuarios y desarrolladores. 
\end{itemize}

\subsubsection{Instalación}
En este apartado se dará una pequeña visión de lo que se necesita para la correcta instalación de Insight Toolkit en nuestra máquina. 


Recordemos que Insight Toolkit es multiplataforma por lo que para poder utilizarla en cualquier plataforma deberemos usar CMake (software libre). Este software controla el proceso de compilación usando una plataforma y un compilador de archivos de configuración independiente. CMake genera los ``makefiles'' y los espacios de trabajo que podrán ser usados en el entorno de compilación que se haya elegido. Es bastante sofisticado ya que da soporte a entornos complejos que requieren una configuración del sistema, testeo de características del compilador y generación de código.


CMake genera ``makefiles'' bajo Unix y sistemas Cygwin. Bajo Windows generará espacios de trabajo para Visual Studio. La información usada por CMake es proporcionada por los archivos ``CMakeLists.txt'' que están presentes en todos los directorios del código fuente de Insight Toolkit. Estos archivos contienen información que el usuario proporciona a CMake en tiempo de con\-fi\-gu\-ra\-ción. La información más común es la inclusión de rutas a las utilidades en el sistema y la selección de opciones del software especificadas por el usuario.


Una vez tengamos instalado CMake pasaremos a configurar Insight Toolkit mediante el uso del mismo. 
Cuando Insight Toolkit esté perfectamente instalado en nuestra máquina podremos empezar a utilizar las librerías. Para ello, la forma más fácil de crear un nuevo proyecto con Insight Toolkit es crear un directorio nuevo en el que tendremos dos nuevos archivos. Uno de ellos será el ``CMakeLists.txt'' que será usado por CMake para generar el ``makefile'' bajo Unix o un espacio de trabajo para Visual Studio si trabajamos desde Windows. El otro archivo a usar será el algoritmo en C++ que hará uso de las clases disponibles en Insight Toolkit.


Para una mejor comprensión y entendimiento de cómo instalar Insight Toolkit se recomienda estudiar el manual propio de ITK \cite{ITK05}.

\subsubsection{Organización}
Insight Toolkit está formado por varios subsistemas:
\begin{itemize}
	\item Conceptos esenciales del sistema $\rightarrow$ como cualquier sistema software, Insight Toolkit está basado en torno a algunos conceptos básicos de diseño. Algunos de los conceptos más importantes son la programación genérica, punteros inteligentes para el manejo de memoria, fábricas de objetos, manejo de eventos usando el paradigma de diseño vista controlador y soporte multihilo.
	\item Numéricos $\rightarrow$ Insight Toolkit  utiliza la librería numérica VXL´s VNL.
	\item Representación de datos y acceso $\rightarrow$ existen dos clases principales para representar datos: itk::Image e itk::Mesh. Además, varios tipos de iteradores y contenedores son usados para mantener y recorrer los datos. Otra clase importante es aquella para representar histogramas.
	\item Procesamiento de datos del pipeline $\rightarrow$ las clases de representación de datos (conocidas como objetos de datos) son operadas por filtros que sucesivamente pueden ser organizadas en flujos de datos del pipeline. Estos pipelines mantienen estados y por lo tanto se ejecutan sólo cuando es necesario. También soportan multihilos y streaming (se puede operar sobre parte de los datos para minimizar el uso de memoria).
	\item IO Framework $\rightarrow$ asociado con el procesamiento de datos del pipeline tenemos:
\begin{itemize}
	\item ``Sources'': filtros que inicializan el pipeline.
	\item ``Mappers'': filtros que terminan el pipeline.


Los típicos ejemplos de ``sources'' y ``mappers'' son lectores y escritores respectivamente. Los lectores introducen datos (típicamente desde un archivo), y los escritores extraen datos desde el pipeline.
\end{itemize}
	\item Objetos espaciales $\rightarrow$ las formas geométricas están representadas en Insight Toolkit usando una jerarquía de objetos espaciales. Estas clases están destinadas a soportar el modelado de las estructuras anatómicas. Utilizando una interfaz básica común, los objetos espaciales son capaces de representar regiones del espacio en una variedad de formas diferentes. Por ejemplo: estructuras de mallas, máscaras y ecuaciones implícitas pueden ser usadas como esquemas de representación subyacentes. Los objetos espaciales son una estructura de datos para comunicar los resultados de los métodos de segmentación y para introducir priores anatómicos tanto en los métodos de segmentación como en los de correspondencia de imágenes.
	\item Framework de correspondencia $\rightarrow$ un framework flexible para la correspondencia soporta cuatro tipos de correspondencia: correspondencia de imágenes, correspondencia con multi-resolución, correspondencia basada en PDE y correspondencia FEM (método de elementos finitos).
	\item Framework FEM $\rightarrow$ Insight Toolkit incluye un subsistema para resolver problemas FEM, en particular la correspondencia no rígida. El paquete FEM incluye definición de mallas, cargas y condiciones límite.
	\item Level Set Framework $\rightarrow$ el framework de colección de nivel es una colección de clases para crear filtros para resolver ecuaciones diferenciales parciales sobre imágenes utilizando un plan de actualización de diferencias finito e iterativo. El framework de colección de nivel consiste en resolver diferencias finitas incluyendo una solución bayesiano, una colección de nivel genérica de filtros de segmentación y varias subclases específicas incluyendo umbralizado, Canny y métodos basados en la laplaciana.
	\item Wrapping (encapsulamiento) $\rightarrow$ Insight Toolkit utiliza un sistema único y potente para producir interfaces (por ejemplo, wrappers) para interpretar lenguajes como Tcl y Python. La herramienta GCC XML es utilizada para producir una descripción XML de código complejo en C++; CSWIG es entonces usado para transformar la descripción XML en wrappers usando el paquete SWIG.
	\item Utilidades auxiliares $\rightarrow$ varios subsistemas auxiliares están disponibles para complementar otras clases en el sistema. Por ejemplo, las calculadoras son clases que desempeñan operaciones especializadas en apoyo de los filtros (por ejemplo, MeanCalculator calcula la media de una muestra). Otras utilidades incluyen un analizador parcial DICOM, soporte para archivos MetaIO, visualización de imágenes para los formatos png, zlib y FLTK/Qt e interfaces para el sistema VTK.
\end{itemize}

\subsubsection{Conceptos esenciales del sistema}
A continuación se detallarán algunos de los principales conceptos y características de implementación que podemos encontrar en Insight Toolkit:


\subsubsection{Programación genérica}
La idea de esta forma de programar pretende generalizar las funciones utilizadas para que puedan usarse en más de una ocasión. Es un método de organización de librerías basadas en componentes genéricos o reutilizables.


Las principales ideas de la programación genérica son los contenedores que se utilizan para almacenar datos, los iteradores para acceder a estos datos y los algoritmos genéricos que usan contenedores e iteradores para crear de manera eficiente algoritmos fundamentales tales como la clasificación.


La programación genérica está implementada en C++ con template (template programming) y con el uso de la librería STL (Standard Template Library). 


Insight Toolkit usa programación genérica en su implementación. La ventaja de este enfoque es que una variedad casi ilimitada de tipos de datos están soportados simplemente por la definición de los tipos template apropiados. Por ejemplo, en Insight Toolkit es posible crear imágenes en las que sus píxeles sean casi cualquier tipo. Además, la resolución del tipo es realizada en tiempo de compilación, por lo que el compilador puede optimizar el código para obtener el máximo rendimiento.


La desventaja de la programación genérica es que muchos compiladores aún no soportan este enfoque y no pueden compilar Insight Toolkit. 

\subsubsection{Programación template}
Los templates son una característica del lenguaje de programación C++ que permite a funciones y clases operar con tipos genéricos. Esto permite a una función o clase trabajar con diferentes tipos de datos sin tener que reescribir cada tipo para cada clase o función. Los templates son una gran utilidad para los programadores de C++, sobre todo cuando se combina con la herencia múltiple y la sobrecarga de operadores.


La técnica de programación template permite a los programadores escribir código en términos de uno o más tipos desconocidos T. Para crear código ejecutable, el programador debe especificar todos los tipos T y así procesará el código con el compilador. T puede ser un tipo nativo como un float o un int, o puede ser un tipo definido por el programador (por ejemplo, una clase). En tiempo de compilación, el compilador se debe asegurar que los tipos template son compatibles con el código instanciado y que estos están soportados por los métodos y operadores necesarios.


Por último, veamos ahora una serie de ventajas y desventajas de la programación mediante el uso de template. 


Los template son considerados un tipo seguro, esto es porque requieren un chequeo de tipos en tiempo de compilación. De ahí, que el compilador pueda determinar en tiempo de compilación si el tipo asociado a la definición del template puede realizar todas las funciones requeridas por dicha definición.


Por diseño, los template pueden ser utilizados en problemas muy complejos, mientras que las macros están más limitadas.


Hay algunos principales inconvenientes a la hora de usar templates:
\begin{itemize}
	\item Muchos compiladores tienen un soporte muy pobre de los templates. Por lo que el uso de los mismos decrementa la portabilidad del código.
	\item Muchos compiladores carecen de instrucciones de limpieza cuando detectan un error de definición de un template. Esto ha aumentado el esfuerzo en el desarrollo de templates, y ha impulsado la inclusión de nuevos conceptos en el siguiente estándar de C++.
	\item Puesto que el compilador genera código adicional para cada tipo template, el uso indiscriminado de los mismos puede llevar a sobrecargar el código, generando grandes ejecutables.
	\item El uso de los símbolos $<$ y $>$ como delimitadores es un problema para las herramientas que analizan el código fuente sintácticamente. Esto dificulta, o hace casi imposible para estas herramientas determinar si el uso de estos símbolos es como operadores de comparación o como delimitadores template.
\end{itemize}

\subsubsection{Inclusión de archivos y clases}
Las clases en Insight Toolkit están definidas como máximo por dos archivos: el fichero cabecera ``.h'' y el fichero de implementación, que podrá ser ``.cxx'' sino es una clase template y ``.txx'' si es una clase template. El fichero cabecera contiene las declaraciones de las clases y comentarios que serán usados por el sistema de documentación Doxygen para automáticamente producir manuales en HTML.

\subsubsection{Fábricas de objetos}
La mayoría de las clases en Insight Toolkit están instanciadas a través de un mecanismo de fábrica de objetos. Esto es, en vez de usar el constructor y destructor estándar de C++, las instancias de las clases en Insight Toolkit son creadas con un método estático llamado New(). 


La fábrica de objetos permite al programador controlar en tiempo de ejecución la instanciación de las clases registrando una o más fábricas con itk::ObjectFactoryBase. Estas fábricas registradas se apoyan en el método ``CreateInstance(classname)'' el cual toma como entrada el nombre de la clase a crear. La fábrica puede elegir crear la clase basándose en un número de factores, incluyendo la configuración del sistema y las variables de entorno.


Por ejemplo, en una aplicación particular, un usuario de Insight Toolkit puede querer utilizar su propia clase implementada usando hardware especializado en procesamiento de imágenes. Utilizando el mecanismo de fábrica de objetos, es posible en tiempo de ejecución reemplazar la creación de un filtro en particular de Insight Toolkit por una clase personalizada. Para hacer esto, el usuario compila su clase e inserta el código objeto en una librería compartida o en un DLL. La librería será entonces puesta en un directorio referenciado por la variable de entorno ITK$\_$AUTOLOAD$\_$PATH. En la instanciación, la fábrica de objetos localizará la librería, determinará que puede crear la clase de un nombre particular con la fábrica y usará la fábrica para crear la instancia.


En la práctica, las fábricas de objetos serán usadas principalmente por clases de entrada$/$salida de Insight Toolkit. Para la gran mayoría de los usuarios, el mayor impacto es usar el método New() para crear una clase.

\subsubsection{Punteros inteligentes y manejo de memoria}
Por naturaleza, los sistemas orientados a objetos representan y operan con datos a través de una gran variedad de tipos, objetos o clases. Cuando una clase en particular es instanciada para producir una instancia de esa clase, se produce una reserva de memoria, de manera que la instancia pueda guardar los valores de los atributos y los punteros de los métodos. Este objeto puede ser referenciado por otras clases o por estructuras de datos durante operaciones normales del programa. Normalmente, mientras el programa está en ejecución todas las referencias a la instancia pueden desaparecer, es en este punto cuando la instancia debe ser borrada para recuperar recursos. Saber cuándo se debe borrar una instancia no es fácil. Borrar la instancia muy pronto provoca errores en el programa; borrarla muy tarde provoca consumo de memoria innecesario. Este proceso de reservar y liberación de memoria se conoce como manejo de la memoria.


En Insight Toolkit, el manejo de memoria es implementando a través de un contador de referencias. Esto se puede comparar con otros enfoques (garbage collection) usados por muchos sistemas en los que se incluye Java. En el contador de referencias, una cuenta del número de referencias a cada instancia es guardada. Cuando una referencia llega a cero, el objeto se libera. En el recolector de basura (garbage collection), un proceso en segundo plano barre el sistema identificando instancias que ya no están siendo referenciadas y las elimina. El problema con el recolector de basura es que el momento en el cual se libera la memoria es variable. Esto no se puede permitir cuando el tamaño de un objeto es muy grande. El contador de referencias, en cambio, libera la memoria inmediatamente, una vez que las referencias al objeto hayan desaparecido.


El contador de referencias es implementado a través de las funciones miembro ``Register()'' y  ``Delete()''. Todas las instancias de un objeto de Insight Toolkit tiene un método ``Register()'' que serán invocados por otro objeto que hace referencia a ellos. El método ``Register()'' incrementa el contador de referencias a instancias. Cuando la referencia a una instancia desaparece, el método ``Delete()'' es invocado en la instancia, el cual decrementará el contador de referencias. Cuando el contador de referencias devuelva cero, la instancia se destruirá.


Este protocolo se simplifica enormemente usando la clase auxiliar itk::SmartPointer. El puntero inteligente actúa como un puntero normal, pero automáticamente ejecuta ``Register()'' cuando hay una referencia a una instancia, y ejecuta ``Unregister()'' cuando no apunte más a la instancia. A diferencia de otras instancias de Insight Toolkit, los punteros inteligentes pueden ser alojados en la pila del programa, y son automáticamente borrados cuando el ámbito para el que se creó es cerrado.

\subsubsection{Tratamientos de errores y excepciones}
En general, Insight Toolkit usa el tratamiento de excepciones para manejar errores durante la ejecución del programa. El tratamiento de excepciones es una parte básica del lenguaje C++.


Se puede elegir capturar un tipo de excepción en concreto, por lo tanto un error específico de Insight Toolkit. Pero también se puede capturar cualquier excepción de Insight Toolkit mediante ExceptionObject.

\subsubsection{Manejo de eventos}
El manejo de eventos en Insight Toolkit es implementado usando el patrón de diseño vista/controlador. En este enfoque, los objetos indican que están esperando por un evento en particular (invocado por una instancia) registrando con la instancia que están esperando. Por ejemplo, los filtros en Insight Toolkit periódicamente invocan a itk::ProgressEvent. Los objetos que han registrado su interés en ese evento serán notificados cuando el evento ocurra. La notificación ocurre a través de la invocación de un comando (por ejemplo, un retorno de función, una llamada a un método, etc.) que es especificado durante el registro del proceso.

\subsubsection{Multihilos}
Los multihilos son tratados en Insight Toolkit a través de un alto nivel de abstracción. Este enfoque proporciona multihilos portables y esconde la complejidad de las diferentes implementaciones de hilos en los sistemas soportados por Insight Toolkit.
Los multihilos son normalmente empleados por un algoritmo durante su fase de ejecución. Los multihilos pueden ser usados para ejecutar un único método en múltiples hilos o para especificar un método por hilo. Cuando un único método se ejecuta en múltiples hilos, los hilos tendrán cuidado de dividir la imagen (por ejemplo) en diferentes regiones de manera que no se solapen para las operaciones de escritura.


La filosofía de Insight Toolkit en lo que concierne a la seguridad de los hilos es que el acceso a diferentes instancias de una clase (y sus métodos) es una operación de hilos segura. Invocar métodos en la misma instancia en diferentes hilos está prohibido.

\subsubsection{Visión general del sistema}
Insight Toolkit usa la librería numérica VNL para proporcionar recursos para la programación numérica combinando la facilidad de uso de paquetes como Mathematica y Matlab con la rapidez de C y la elegancia de C++.


La librería numérica VNL incluye clases para:
\begin{itemize}
	\item Matrices y vectores.
	\item Matrices especiales y clases de vectores.
	\item Descomposición de matrices.
	\item Polinomios reales.
	\item Optimización.
	\item Funciones estándar y constantes.
\end{itemize}
Insight Toolkit también proporciona funcionalidades numéricas adicionales, como funciones estadísticas.

\subsubsection{DART}
Una de las características únicas de Insight Toolkit es el uso de DART (sistemas de pruebas de regresión). En pocas palabras, lo que hace DART es proporcionar información cuantificable a los desarrolladores que comprueban código nuevo y hacen cambios.


La información se basa en los resultados de una variedad de tests y los resultados son publicados en una página web, la cual se conoce como ``dashboard''. Dado que todos los usuarios y desarrolladores de Insight Toolkit pueden ver la página web, DART sirve como de vehículo para la comunicación de desarrolladores, especialmente cuando se hacen aportaciones con fallos. Es aconsejable consultar el ``dashboard'' antes de realizar cualquier actualización del software en el repositorio.


Otra característica es que DART es independiente de Insight Toolkit y puede ser utilizado para tener un control de calidad sobre cualquier tipo de proyecto software.


DART soporta una gran variedad de tipos de test. Entre ellos están los siguientes:
\begin{itemize}
	\item Compilación: todo el código fuente y de prueba es compilado y enlazado. Cualquier error o warning será publicado en el ``dashboard''.
	\item Regresión: algunos test en Insight Toolkit producen imágenes de salida. Cada test necesita comparar la imagen de salida con una imagen de referencia válida. Si las imágenes coinciden entonces el test se da por válido. La comparación debe ser realizada con cuidado dado que muchos sistemas que usan gráficos 3D producen resultados ligeramente diferentes en distintas plataformas.
	\item Memoria: los problemas relacionados con la memoria como fallos, accesos a memoria no inicializada, lecturas/escrituras más allá del espacio asignado pueden provocar resultados inesperados y hacer que el programa falle. Insight Toolkit chequea en tiempo de ejecución los accesos y el manejo de memoria utilizando ``Purify''.
	\item ``Printself'': se espera que todas las clases en Insight Toolkit impriman por pantalla todas sus variables (aquellas asociadas con los métodos ``Get y Set'') correctamente. Este test comprueba que realmente esto se realiza.
	\item Módulo: cada clase en Insight Toolkit debería tener su correspondiente módulo de testeo donde las funcionalidades son probadas y comparadas cuantitativamente con los resultados esperados. Estos test normalmente son escritos por el desarrollador de la clase y este debe esforzarse para cubrir todas las líneas de código incluyendo los métodos ``Get/Set'' y el manejo de errores.
	\item Cubrir: aquel código que no se ejecuta durante los test es probable que sea erróneo. Los test de cobertura identifican aquellas líneas que no se están ejecutando en los test de Insight Toolkit, informando del porcentaje total cubierto al final del mismo. Si bien es casi imposible cubrir el 100$\%$, del código debido al código de manejo de errores y construcciones similares que raramente se encuentran en la práctica, se busca cubrir al menos el 75$\%$ o más. Aquel código que no está bien cubierto necesitará pasar pruebas adicionales.
\end{itemize}


Cuando un usuario o un desarrollador decide actualizar el código de Insight Toolkit desde el repositorio es importante verificar primero que el ``dashboard'' está correcto. Esto se puede comprobar rápidamente por la coloración general del ``dashboard''. Cuando está es verde significa que el software está compilado correctamente y que es un buen momento para empezar a utilizar Insight Toolkit o para obtener una actualización. Cuando está en rojo indica inestabilidad en el sistema y, por tanto, los usuarios deben abstenerse de revisar o actualizar el código fuente.

Otra característica de DART es que mantiene un historial de los cambios realizados en el código fuente. Esto es útil para llevar un seguimiento de los problemas y mantenerse al día de las actualizaciones de Insight Toolkit.

Insight Toolkit procesa funciones a través de tres ciclos (el ciclo continuo, el ciclo diario y el ciclo de versión).

El ciclo continuo gira en torno a las acciones de los desarrolladores como comprobación de código en el repositorio. Cuando se cambia o se comprueba código nuevo en el repositorio, el proceso de testeo continuo de DART se inicia. Un pequeño número de test son realizados, y si algo falla, se envía un correo electrónico a todos los desarrolladores que han comprobado el código durante el ciclo continuo. Se espera que los desarrolladores arreglen el problema inmediatamente.

El ciclo diario se produce en un periodo de 24 horas. Los cambios que se realizan en el código fuente durante el día son ampliamente probados por la noche por la secuencia de pruebas de regresión de DART. Estas pruebas ocurren en diferentes máquinas combinadas y en diferentes sistemas operativos alrededor del mundo, y los resultados son publicados diariamente en el ``dashboard'' de DART. Los desarrolladores que comprueban el código deben visitar el ``dashboard'' y asegurarse que sus cambios son aceptables (no introducen errores de compilación o warnings, o fallos en otros test incluyendo la regresión, memoria, ``printself'' y los métodos ``Set y Get'').

El ciclo de versión ocurre un pequeño número de veces al año. Esto requiere etiquetar el repositorio, actualizar la documentación y producir nuevos paquetes para la versión. Además, se realizan pruebas adicionales para asegurar la consistencia del paquete, manteniendo el repositorio libre de errores minimizando de esta forma el trabajo requerido para quitar una versión.
Los usuarios de Insight Toolkit trabajan normalmente con las publicaciones, dado que son más estables. Los desarrolladores trabajan con el repositorio y a veces, con las publicaciones recientes a fin de ver las ventajas de las nuevas características añadidas. Es muy importante que los desarrolladores presten especial atención al ``dashboard'' y actualicen su software únicamente cuando este esté en verde. Si no se hace así puede causar importantes perturbaciones si un día en concreto la versión del software es inestable.

La eficacia de este proceso es bastante buena, al proporcionar información inmediata a los desarrolladores a través del correo electrónico y páginas web, la calidad de Insight Toolkit es excepcionalmente alta, sobre todo considerando la complejidad de los algoritmos y del sistema. Los errores, cuando se introducen accidentalmente, son capturados rápidamente, en comparación a cuando son capturados en el momento de la publicación de una versión. Esperar hasta este punto es esperar demasiado, dado que la relación causal entre el código cambiado o añadido y el error se ha perdido.  

\subsection{CMake}
CMake es un sistema multiplataforma para la automatización de la compilación. Su nombre es una abreviatura de ``cross platform make'', a pesar del uso de ``make'' en su nombre, CMake, es una aplicación separada y de más alto nivel que normalmente se utiliza para el desarrollo en Unix. CMake es una familia de herramientas diseñadas para compilar, probar y empaquetar software. CMake se utiliza para controlar el proceso de compilación del software utilizando una plataforma simple y un compilador de ficheros de configuración independientes. CMake genera ``makefiles'' nativos y espacios de trabajo que pueden ser usados en el entorno de compilación que se elija. Se puede comparar al sistema de compilación de UNIX GNU en que el proceso de compilación está controlado por los archivos de configuración, en el caso de CMake llamados ficheros ``CMakeLists.txt''. Como las herramientas del sistema de compilación de GNU, CMake no genera directamente el software final, en cambio, compila ficheros estándar (por ejemplo, ``makefiles'' en UNIX y proyectos en Windows Visucal C++ o Eclipse) que serán utilizados de manera estándar, permitiendo un enfoque más fácil para los desarrolladores familiarizados con un entorno de desarrollo particular. Sin embargo, a diferencia del sistema de compilación de GNU, el cuál está restringido sólo a plataformas UNIX, CMake soporta la generación de ficheros de compilación para muchos sistemas de compilación en muchos sistemas operativos. CMake, por tanto, soporta desarrollo multiplataforma eliminando la necesidad de mantener sistemas de compilación separados para cada plataforma.

CMake es un sistema extensible, de código abierto, que maneja el proceso de compilación en un sistema operativo y de manera independiente por el compilador. A diferencia de muchos sistemas multiplataforma, CMake está diseñado para ser utilizado en conjunto con entornos nativos de compilación. Los ficheros de configuración (CMakeLists.txt) que están colocados en cada directorio fuente son utilizados para generar archivos de compilación estándares que serán utilizados de forma habitual. CMake es capaz de compilar código fuente, crear librerías, generar contenedores y compilar ejecutables en combinaciones arbitrarias. CMake soporta compilaciones dentro y fuera de sitio (in-place y out-of-place builds)y por lo tanto puede soportar múltiples compilaciones a partir de un único árbol fuente. CMake también soporta la compilación de librerias estáticas y dinámicas. Una característica distintiva de CMake es que genera un fichero cache que está diseñado para ser utilizado con un editor gráfico. Por ejemplo, cuando se ejecuta CMake sitúa ficheros include, librerías y ejecutables pudiendo encontrar directivas opcionales de compilación. Esta información se almacena en la cache, la cuál podrá ser cambiada por el usuario antes de la generación de los ficheros nativos de compilación.

CMake está diseñado para soportar complejas jerarquías de directorios y aplicaciones que dependen de muchas librerías. Por ejemplo, CMake soporta proyectos basados en múltiples conjuntos de herramientas (por ejemplo, librerías), donde cada conjunto de herramientas puede contener varios directorios, y la aplicación depende de los conjuntos de herramientas más codigo adicional. CMake también puede manejar situaciones en las que los ejecutables deben ser compilados para generar código que después será compilado y enlazado en una aplicación final.

El proceso de compilación está controlado por la creación de uno o más ficheros ``CMakeLists.txt'' en cada directorio (incluyendo subdirectorios) que construyen el proyecto. Cada ``CMakeLists.txt'' está formado por uno o más comandos. Cada comando tiene la forma \textbf{COMMAND(args...)} dónde \textbf{COMMAND} es el nombre del comando, y \textbf{args} es una lista de argumentos separados por espacios en blanco. CMake proporciona comandos predefinidos y comandos definidos por el usuario.

\subsection{AMILab}
AMILab es un lenguaje interpretado para el procesamiento y tratamiento de imágenes. Para su diseño se ha utilizado:
\begin{itemize}
\item C/C++
\item Flex/Bison
\item wxWidgets
\item OpenGL
\item VTK
\item ITK
\end{itemize}

AMILab tiene muchas características, y ha sido especialmente utilizado para la investigación académica en el procesamiento de imágenes médicas. A día de hoy la herramienta se encuentra en fase de desarrollo y sufre cambios continuamente.

A continuación se detallan algunas de las herramientas utilizadas por AMILab.

\subsubsection{Lex}
Lex es un programa para generar analizadores léxicos (en inglés scanners o lexers). Lex se utiliza comúnmente con el programa yacc que se utiliza para generar análisis sintáctico. Lex, escrito originalmente por Eric Schmidt y Mike Lesk, es el analizador léxico estándar en los sistemas Unix, y se incluye en el estándar de POSIX. Lex toma como entrada una especificación de analizador léxico y devuelve como salida el código fuente implementando el analizador léxico en C.
Aunque tradicionalmente se trata de software propietario, existen versiones libres de lex basadas en el código original de AT\&T en sistemas como OpenSolaris y Plan 9 de los laboratorios Bell. Otra versión popular de software libre de lex es Flex.

\subsubsection{Bison}
Yacc es un programa para generar analizadores sintácticos. Las siglas del nombre significan Yet Another Compiler-Compiler, es decir, ``Otro generador de compiladores más''. Genera un analizador sintáctico (la parte de un compilador que comprueba que la estructura del código fuente se ajusta a la especificación sintáctica del lenguaje) basado en una gramática analítica escrita en una notación similar a la BNF. Yacc genera el código para el analizador sintáctico en el Lenguaje de programación C.

Fue desarrollado por Stephen C. Johnson en AT\&T para el sistema operativo Unix. Después se escribieron programas compatibles, por ejemplo Berkeley Yacc, GNU bison, MKS yacc y Abraxas yacc (una versión actualizada de la versión original de AT\&T que también es software libre como parte del proyecto de OpenSolaris de Sun). Cada una ofrece mejoras leves y características adicionales sobre el Yacc original, pero el concepto ha seguido siendo igual. Yacc también se ha reescrito para otros lenguajes, incluyendo Ratfor, EFL, ML, Ada, Java, y Limbo.

Puesto que el analizador sintáctico generado por Yacc requiere un analizador léxico, se utiliza a menudo conjuntamente con un generador de analizador léxico, en la mayoría de los casos lex o Flex, alternativa del software libre. El estándar de IEEE POSIX P1003.2 define la funcionalidad y los requisitos a Lex y Yacc.

La versión Yacc de AT\&T se convirtió en software libre; el código fuente está disponible con las distribuciones estándares del Plan 9 y de OpenSolaris.

\subsubsection{VTK}
VTK es un software de código abierto y orientado a objetos para el tratamiento de imágenes y su procesado. Aunque VTK es amplio y complejo, está diseñado para su fácil utilización siempre y cuando se haga un estudio previo de los conceptos básicos de diseño orientado a objetos y la metodología de implementación.

Debido a que VTK es un software de código abierto, son muchos los usuarios que han participado en su desarrollo.
\subsubsection{ITK}
Como ya se vio anteriormente, las librerías Insight Toolkit son de código abierto, multiplataforma, orientadas a objetos y se utilizan para procesar, segmentar y hacer correspondencia de imágenes. Insight Toolkit está diseñado para ser usado con facilidad una vez que se aprende diseño orientado a objetos y su metodología de implementación. A su vez, Insight Toolkit proporciona métodos novedosos y a la orden del día para segmentación y correspondencia de imágenes en cualquier dimensión posible (2D, 3D,.., ND).

\subsubsection{wxWidgets}
wxWidgets es un conjunto de herramientas para implementar aplicaciones con interfaz gráfica (GUI). Es un framework en el sentido que hace muchas tareas de limpieza y proporciona un comportamiento para la aplicación por defecto. La librería de wxWidgets contiene un gran número de clases y métodos que facilitan su uso y personalización.

Las aplicaciones por norma general muestran ventanas que contienen controles básicos, son capaces de trazar imágenes y gráficos especializados y pueden responder a eventos de ratón, teclado u otras fuentes. También se puede comunicar con otros procesos y manejar otros programas. En otras palabras, wxWidgets hace que la implementación de una aplicación sea relativamente sencilla proporcionando todas las funcionalidades propias de las aplicaciones de hoy en día.

Puede que wxWidgets esté considerado como un conjunto de herramientas para el desarrollo de GUI, pero de hecho es mucho más que eso ya que posee algunas características que la hacen muy útil en muchos aspectos del desarrollo de aplicaciones. Esto es así debido a que todas las aplicaciones implementadas con wxWidgets debe ser portables a diferentes plataformas, no sólo la parte gráfica.

wxWidgets proporciona clases para trabajar con ficheros y flujos de datos, ejecución multihilo, configuración de las aplicaciones, comunicación entre procesos, ayuda online, acceso a bases de datos y mucho más.

\subsubsection{Boost}
Las librerías de Boost C++, son un conjunto de librerías C++ portables peer-reviewed que extienden las funcionalidades de C++.

Las librerias de Boost están registradas bajo la licencia de software de Boost, diseñanadas para que Boost pueda ser utilizado tanto en proyectos de software libre como en proyectos privados.

Las librerías están destinadas a una amplia gama de usuarios de C++ y a un amplio dominio de aplicaciones. Van desde las librerías de propósito general como la libería smart\_ptr (punteros inteligentes), abstracciones del funcionamiento del sistema como el sistema de ficheros de Boost, a las librerías principalmente dirigidas a usuarios avanzados de C++ y a desarrolladores de otras librerías, como el template de meta programación (MPL) y el de creación DSL (Proto).

Con el fin de garantizar la eficiencia y la flexibilidad, Boost hace un amplio uso de los templates. Boost ha sido una fuente de intenso trabajo e investigación en la programación genérica y la meta programación en C++.

La actual versión de Boost contiene cerca de 80 liberías individuales, incluyendo librerías para algebra lineal, pseudo generación numérica, multihilos, procesamiento de imágenes, expresiones regulares, unidad de prueba, y muchas más.

La mayoría de las librerías de Boost están basadas en ficheros cabeceras, que consisten en funciones inline y templates, y como tal no tienen que ser contruidas antes de su uso.

El principal uso de estas librerías en AMILab es el de dar formato a las salidas por pantalla (printf en C++). A día de hoy y gracias a su utilidad se ha incluido el uso de los punteros inteligentes, permitiendo gestionar de manera más eficientes los recursos disponibles.

\subsubsection{PThreads}
Desde siempre, los diseñadores de hardware han implementado sus propias versiones de hilos. Estas implementaciones eran totalmente diferentes unas de otras haciendo que el desarrollo de aplicaciones multihilos portables fuese muy complicado.

Con el fin de aprovechar al máximo las capacidades proporcionadas por la ejecución multihilo, se hizo necesario una interfaz de programación estandarizada.

Para los sistemas Unix, esta interfaz viene especificada por el estándar IEEE POSIX 1003.1c (1995). Las implementaciones que utilizan este estándar son conocidas como hilos POSIX o Pthreads. Muchos diseñadores hardware ofrecen Pthreads además de su propia API.

El estándar POSIX ha seguido evolucionando y ha sido revisado en múltiples ocasiones, incluyendo la especificación de Pthreads. La última versión conocida es IEEE Std 1003.1, 2004.

Pthreads se define como un conjunto de tipos de lenguaje de programación C y llamadas a procedimientos, implementado con el fichero de cabecera \textit{pthread.h} y la librería multihilos, aunque esta librería puede ser parte de otra librería, como \textit{libc}, en algunas implementaciones.

Los principales motivos para utilizar multihilos son:
\begin{itemize}
\item Realizar mejoras sustanciales en el rendimiento del programa.
\item Cuando se compara el coste de crear y manejar un proceso, el sistema multihilos es capaz de crearlo con una sobrecarga mucho menor del sistema operativo. El manejo de multihilos utiliza menos recursos del sistema que el manejo de procesos.
\item Todos los hilos dentro de un proceso comparten el mismo espacio de direcciones. La comunicación entre hilos es mucho más eficiente y en muchos casos muchos más fácil de utilizar que la comunicación entre procesos.
\item Las aplicaciones multihilos ofrecen ganancias potenciales de rendimiento frente a las aplicaciones que no son multihilos en muchos sentidos:
\begin{itemize}
\item Sobrecarga del procesador con entrada/salida: por ejemplo, un programa puede tener secciones en las que se está realizando una operación larga de entrada/salida. Mientras un hilo está esperando a que la llamada al sistema de entrada/salida se complete, el trabajo del procesador puede ser realizado por otros hilos.
\item Cola de prioridad: aquellas tareas que sean más importantes serán ejecutadas antes que aquellas que tienen menor prioridad, o incluso pueden interrumpirlas para ejecutarse ellas.
\item Manejo de eventos asíncronos: tareas que sus eventos de servicio son de frecuencia y duración indeterminadas pueden ser intercaladas. Por ejemplo, un servidor web puede, tanto transferir datos de las peticiones previas, como manejar la entrada de nuevas peticiones.
\end{itemize}
\item La principal motivación para considerar el uso de Pthreads en un sistema multihilos es la de alcanzar un rendimiento óptimo.
\end{itemize}

Dado que AMILab es multiplataforma y que este proyecto ha sido desarrollado bajo Windows, se ha tenido que utilizar \textit{Pthreads Win32}. Un gran número de sistemas operativos modernos incluyen una librería para el tratamiento de hilos propia: Solaris,  Win32 threads, DCE threads, etc. La tendencia es que la mayoría de estos sistemas poco a poco adopten la API estándar de hilos (POSIX 1003.1-2001), pero este no es el caso de Win32, que es bastante improbable que lo haga, por lo que se ha de utilizar Pthreads Win32.

\subsubsection{¿Cómo implementar un script en AMILab?}
Una parte fundamental en AMILab es la existencia de scripts, esto permite al usuario la creación de una interfaz que facilitará la ejecución de los filtros o tareas que desee realizar. 

Gracias a los recursos que posee AMILab, se puede crear una interfaz completa, con todas aquellas necesidades que requiera el usuario. Esto es posible debido a wxWidgets, ya que AMILab hace uso de sus funcionalidades y día a día éstas se amplían para proporcionar más y más recursos.

Un script en AMILab parte de un fichero ``.amil'' en el cuál se incluyen ciertas directivas que harán que se pueda mostrar la interfaz. A continuación se verá una pequeña descripción en la que se nombrarán diferentes aspectos a la hora de escribir una interfaz.

En primer lugar, lo más importante a tener en cuenta, es que AMILab es un lenguaje interpretado orientado a objetos por lo que cuando se crea un script se parte de la base que un script será una clase, es decir, el script en sí será una clase que podrá ser instanciada tantas veces se quiera e incluso incluida y utilizada por otro script (clase). Partiendo de esto, como toda clase tendrá sus atributos y sus métodos.

Para poder inicializar nuestra clase, tenemos un método que se encarga de fijar todos los valores de los atributos a un valor por defecto, digamos que este método seria el constructor de nuestra clase. Dentro de este constructor podemos declarar atributos de los siguientes tipos:
\begin{itemize}
\item init
\item boolean
\item enum
\item float
\item string
\end{itemize}
Una vez sabemos los tipos que se pueden utilizar, es importante tener en cuenta los siguientes puntos:
\begin{itemize}
\item Al declarar una variable como int o enum se debe inicializar como INT(``\textit{valor}'').
\item Cuando declaras un tipo float no hace falta especificar al inicializarlo que es tipo float, porque por defecto ya sabe que lo es.
\item Una variable de tipo boolean debe ser inicializada con el tipo UCHAR(``\textit{valor}'').
\item Al inicializar una variable de tipo string basta con asignarle el valor que queramos que tenga.
\end{itemize}
Otro método importante en un script es el que se encarga de crear la interfaz propiamente dicha. Normalmente y para tener un ``convenio'' este método se llama ``Gui''. Esta puede estar formada por:
\begin{itemize}
\item AddInt $\rightarrow$ Añadirá un slider que permitirá inicializar la variable dentro de un rango especificado.
\item AddFloat $\rightarrow$ Añadirá un slider que permitirá inicializar la variable dentro de un rango especificado.
\item AddEnum $\rightarrow$ Añadirá un combobox que permite elegir una de las opciones disponibles.
\item AddBoolean $\rightarrow$ Añadirá un checkbox que activará o desactivará una opción.
\item AddString $\rightarrow$ Añadirá un textbox en el que se puede introducir una string.
\item AddDirname $\rightarrow$ Permitirá seleccionar un directorio o un archivo en concreto.
\item AddButton $\rightarrow$ Añadirá un botón que permite hacer una llamada a uno de los métodos de la clase.
\end{itemize}
Todas estas opciones están asociadas a la ventana de parámetros que se crea utilizando ``ParamPanel'', una vez creada esta se pueden utilizar.

Para darle formato a la interfaz existen una serie de comandos que ayudan a ordenarla:
\begin{itemize}
\item BeginBoxPanel \& EndBoxPanel $\rightarrow$ permiten formar un marco.
\item BeginBook \& EndBook $\rightarrow$ creará un ``libro'' en el que se podrán añadir las ``páginas'' (pestañas) que se deseen.
\item AddPage $\rightarrow$ se utiliza para crear las ``páginas'' que estarán dentro del ``libro''.
\item BeginHorizontal \& EndHorizontal $\rightarrow$ permite ordenar las opciones que se quieran de manera horizontal. Sino se especifica las opciones se colocarán de manera vertical, una detrás de otra.
\end{itemize}
Por último se debe llamar al comando Update(-1) y a continuación de Display() para que la interfaz se muestre actualizada con los valores que hemos fijado en el constructor.
\subsubsection{¿Cómo añadir un filtro en AMILab?}
Como ya se ha visto AMILab es un software libre lo que nos permite añadir funcionalidades siempre que se necesiten. Para ello, basta con añadir los ficheros necesarios en la sección correspondiente de AMILab, siempre para mantener un orden y una lógica.

En nuestro caso, las posibles funcionalidades creadas se añadirán a la sección ``Wrapping/WrapITK''. Para que estén disponibles en AMILab se deben declarar como variables mediante ``ADDOBJECTVAR\_NAME''. También será posible especificar si la nueva funcionalidad es una función o un procedimiento permitiendo definir el tipo que devolverá.

\subsubsection{Ejecución de scripts}
Una vez se ha creado el script deseado se puede cargar en AMILab para ver el resultado, comprobar que todo funciona correctamente y utilizarlo.

Para cargar un script en AMILab se puede hacer de varias formas:
\begin{enumerate}
\item Accediendo a la barra de menú y seleccionando el script que se desee.
\item Cargando el script mediante el comando func ``nombre del script''.
\end{enumerate}
Para la primera opción si queremos cargar un script que hemos creado nosotros tendremos que añadirlo al fichero ``Add2Menu.amil'' en el directorio correspondiente. De esta forma se incluirá en la lista que se despliega cuando vamos a Script en la barra de menú.

\section{¿Cómo implementar un filtro?}
Los filtros se definen en base al tipo de datos de entrada y en base al tipo de datos de salida. La clave para escribir un filtro en Insight Toolkit es identificar el número y tipo de las entradas y salidas. Una vez hecho esto, hay superclases que simplifican la tarea a través de la derivación. Por ejemplo, la mayoría de los filtros en Insight Toolkit toman una imagen como entrada y producen una única imagen como salida. La superclase itk::ImageToImageFilter es la clase más adecuada para este filtro.
\begin{itemize}
	\item ``ImageToImageFilter'' $\rightarrow$ es el filtro más común utilizado para algoritmos de segmentación. Toma una imagen y produce una nueva imagen, por defecto con el mismo tamaño.
\end{itemize}

\subsubsection{Consideraciones a tener en cuenta}
\subsubsection{Multihilos}
Los filtros que pueden procesar datos por partes pueden normalmente trabajar utilizando los datos en paralelo. Para crear un filtro multihilo, simplemente se define y se implementa el método ``ThreadedGenerateData()''. Por ejemplo, itk::ImageToImageFilter crearía el método:
\textit{void  ThreadedGenerateData(const OutputImageRegionType $\&$outputRegionForThread, int threadId)}


La clave del procesamiento multihilo es generar una salida para la región de salida dada (como primer parámetro de la lista de argumentos). En Insight Toolkit esto es fácil de hacer porque el iterador de salida puede ser creado utilizando la región proporcionada. Por tanto, la salida puede ser iterada, accediendo a los pixeles correspondientes de la entrada según sea necesario para calcular los valores de los pixeles de salida.


La ejecución multihilos necesita tener cuidado cuando trabaja con I/O (cerr o cout) o cuando invoca eventos. Un método seguro es sólo permitir que un único hilo con identificador cero realice I/O o genere eventos. (El identificador id es pasado como argumento en ``ThreadedGenerateData''). Si más de un hilo intenta escribir en el mismo sitio al mismo tiempo, el programa puede comportarse de manera errónea y posiblemente se produzca un fallo.

\subsubsection{Convenios a la hora de implementar un filtro}
Se pretende que los filtros en Insight Toolkit sigan una serie de convenios. A continuación se explican los requisitos mínimos para la integración de un filtro en Insight Toolkit.


La declaración de la clase para un filtro debe incluir la macro ``ITK$\_$EXPORT'', de manera que en determinadas plataformas una declaración de exportación pueda ser incluida. 


Un filtro debe definir tipos públicos para la clase propia (Self), para su superclase (Superclass) y para los punteros inteligentes constantes y no constantes:

\begin{center}
\textit{typedef ExampleImageFilter Self;}

\textit{typedef ImageToImageFilter<TImage,TImage> Superclass;}

\textit{typedef SmartPointer<Self> Pointer;}

\textit{typedef SmartPointer<const Self> ConstPointer;}

\end{center}



El tipo Pointer es bastante útil, ya que es un puntero inteligente que será utilizado por todos los usuarios del código para mantener un contador de referencias al filtro (instancias al filtro).


Una vez tenemos definidos estos tipos, se pueden utilizar las siguientes macros, las cuales permiten al filtro implementado participar en el mecanismo de fábrica de objetos y ser creado utilizando el método New().
\begin{itemize}
	\item Método para crear a través de la fábrica de objetos $\rightarrow$ ``itkNewMacro(Self)''
	\item Escritura en tiempo de ejecución de la información y de los métodos relacionados $\rightarrow$ ``itkTypeMacro(ExampleImageFilter, ImageToImageFilter)''
\end{itemize}


El constructor por defecto debe ser ``protected''. La copia del constructor y el operador de asignación deben ser declarados privados y no se deben implementar para impedir instanciaciones del filtro sin los métodos de la fábrica.


Por último, la implementación del código template debe ser incluida y catalogada por un test para una instanciación manual:


\textit{$\#$ifndef ITK$\_$MANUAL$\_$INSTANTIATION}

\textit{$\#$include ``itkExampleFilter.txx''}

\textit{$\#$endif}

\section{Filtro NLMeans Básico}
El filtro Non Local Means básico ha sido utilizado como método de estudio de las funcionalidades que proporciona Insight Toolkit, pero en la práctica no ha sido utilizado debido a motivos de implementación. 

A efectos prácticos no es utilizado en la implementación final del método de segmentación de carótidas. Esto es debido a diferentes motivos:
\begin{itemize}
\item El principal motivo es que en el método que se iba a utilizar en un principio se hacía necesario su uso, pero en el que al final se utiliza no es del todo necesario. Este cambio de método se ha debido a la participación en el workshop de Miccai09, se ha visto más correcto utilizar el nuevo método ya que había un mayor conocimiento del mismo.
\item En el método final de segmentación de carótidas no se utiliza debido a que en ciertos casos ayuda a la segmentación pero en otros la entorpece.
\item En la práctica el filtro Non Local Means necesita demasiado tiempo para su ejecución debido a la arquitectura interna de Insight Toolkit.
\end{itemize}

Se ha mantenido en el contenido del proyecto ya que ha sido de gran ayuda a la hora de asimilar conocimientos sobre la utilización de Insight Toolkit.

Dada una imagen con ruido el valor estimado para un punto se calcula como una media ponderada de todos los píxeles de la imagen, donde los pesos dependerán de la similitud entre dos píxeles dados.


El algoritmo NLMeans básico se centra en que cada para cada píxel de la imagen de entada se calculan dos vecindades alrededor del píxel, una será la ventana de búsqueda (t) y otra la ventana patrón (f). Para cada ventana de búsqueda y cada píxel actual se calcula su media ponderada en relación al resto de píxeles de la ventada de búsqueda y a sus ventanas patrón. Esto se hace de la siguiente forma:
\begin{enumerate}
	\item Se delimita la ventana de búsqueda centrada en el píxel actual.
	\item Se delimita la ventana patrón centrada en el píxel actual.
	\item Para todos los píxeles de la ventana de búsqueda se calculará la distancia entre la ventana patrón del píxel actual y cada ventana patrón de cada píxel de la ventana de búsqueda. A continuación se hace la promedia y se continúa el proceso con el siguiente píxel de la ventana de búsqueda. Así hasta completarla.
	\item Una vez se termina con la ventana de búsqueda se hace la media en base a las promedias obtenidas y se fija un valor para el píxel del salida.
\end{enumerate}

\begin{figure}
\centering
\includegraphics[scale=0.7]{image089.JPG}%ext=pdf,jpg,png
\caption{Non Local Means}
\label{fig:NLM}
\end{figure}

En base a lo expuesto con anterioridad, se deben seleccionar aquellas clases que se pueden reutilizar para el desarrollo del algoritmo. 


Gracias al estudio realizado en una primera fase de las librerías ITK se ha tomado la decisión de utilizar las siguientes clases para el desarrollo del filtro en cuestión:
\begin{itemize}
	\item La clase relativa a las imágenes en ITK, ``itkImage.h''. Se utiliza esta clase ya que permite tener imágenes de cualquier dimensión (n-D), siendo el tipo de los píxeles cualquiera.
	\item La clase utilizada en el tratamiento de filtros, aquella que a partir de una imagen de entrada, la transforma y genera otra imagen de salida, ``itkImageToImageFilter.h''. Esta clase además proporciona soporte para el procesamiento de imágenes mediante multihilos.
	\item Las clases que permite iterar sobre toda la imagen, ``itkImageRegionIterator.h'' e ``itkImageRegionConstIteratorWithIndex.h''. La primera permite iterar sobre una región de una imagen de forma rápida. La segunda realiza lo mismo que la primera pero con la diferencia de que en cada píxel de la imagen tenemos el índice del mismo, es decir, sabemos la posición del iterador en cada momento. Este hecho produce que el iterador sea más lento pero no tanto como si para el primer iterador le pidiésemos el índice del iterador en cada momento.
	\item La clase relativa al tratamiento de la ventana patrón, es decir, la clase iterador de vecindades, ``itkConstNeighborhoodIterator.h''. Permite tener para cada píxel de la imagen una vecindad del tamaño que se desee, normalmente suele ser un tamaño pequeño ya que si no se pierde eficiencia.
	\item Para poder hacer un uso eficiente de los iteradores de vecindades, se activará la opción de comprobación de los límites. Esto permite, que sólo aquellas zonas cercanas a los límites sean evaluadas como tal, mientras que el resto se recorrerán de forma normal obteniendo de esta forma un aumento significativo de la velocidad, para ello se hará uso del objeto ``itk::ImageBoundaryFacesCalculator'' que se encuentra en la clase ``itkNeighborhoodAlgorithm.h''. Dividir la imagen en las regiones necesarias es una tarea sencilla cuando se utiliza este objeto, se llama así porque devuelve una lista con las ``caras'' del conjunto de datos N-D. Las caras son aquellas regiones donde todos los píxeles se encuentran a una distancia ``d'' del límite, siendo ``d'' el radio del patrón de vecindades utilizado. En otras palabras, las ``caras'' son aquellas regiones donde el iterador de vecindades de radio ``d'' siempre se superpondrá a los límites de la imagen. Este objeto también devuelve el interior de la región, en la cual los valores fuera de los límites nunca serán utilizados y el chequeo de límites no es necesario.
	\item Es necesario leer la imagen de entrada y poder escribir la imagen resultante, para ello se utilizarán las siguientes clases, ``itkImageFileReader.h'' e ``itkImageFileWriter.h''. Utilizando el tipo de datos de la imagen se puede instanciar la clase encargada de leer la imagen. El tipo de la imagen es utilizado como un parámetro template para definir cómo los datos serán representados una vez sean cargados en memoria. Este tipo no tiene porque corresponder exactamente con el tipo almacenado en el fichero. Se puede realizar una conversión de un tipo a otro, siempre y cuando el tipo elegido para representar los datos en el disco admita dicha conversión.
\end{itemize}

\section{Segmentación de la carótida}
\begin{figure}
\centering
\includegraphics[scale=0.7]{image016.png}%ext=pdf,jpg,png
\caption{Región de interés}
\label{fig:ROI}
\end{figure}
La arteria carótida común y la arteria carótida interna son clínicamente las arterias más relevantes en la bifurcación de las carótidas. Por tanto, será en estas dos arterias en las que nos centraremos principalmente. Se incluirá también una pequeña parte de la arteria carótida externa para evitar problemas a la hora de la evaluación en el lugar dónde la arteria carótida externa se bifurca de la arteria carótida interna. Esto permite incluir una bifurcación que dificultará el método.

El objetivo principal a conseguir es segmentar con precisión el interior de las bifurcaciones de las carótidas en un conjunto de imágenes de tomografía computarizada. Se partirá de tres puntos iniciales proporcionados por el usuario.
La región a segmentar está definida alrededor de la bifurcación, que se define como la primera parte dónde el interior de la arteria carótida común se divide en dos partes, la de la arteria carótida interna y la de la arteria carótida externa. La segmentación debe contener la arteria carótida común, comenzando por lo menos a 20mm de la bifurcación, la arteria carótida interna, con un máximo de 40mm desde la bifurcación y la arteria carótida externa, hasta entre 10 y 20mm desde la bifurcación \ref{fig:ROI}

Las medidas de rendimiento serán determinadas únicamente sobre la región de interés especificada anteriormente. Sin embargo, la ubicación de la bifurcación no se especifica. Por tanto, se debe estar seguro que la parte segmentada la contiene. La definición de la bifurcación y las regiones especificadas deberían ser suficientes para determinar la región adecuada de interés para la segmentación.

Para la arteria carótida externa, el interior segmentado debe ser cortado entre 10 y 20mm desde la bifurcación. Para permitir un poco más de flexibilidad a la hora del corte de la arteria carótida externa, la región alrededor de la arteria carótida externa entre 10 y 20mm desde la bifurcación es una ``máscara'' dónde la evaluación de las medidas de rendimiento no serán consideradas.

Los datos de entrada serán:
\begin{itemize}
\item El conjunto de datos de imágenes de tomografía computarizada (incluyendo en las cabeceras de los ficheros el tamaño de voxel y el sistema de coordenadas) y tres puntos iniciales:
\begin{itemize}
\item Un punto en la arteria carótida común, a la altura del lado craneal de la glándula tiroidea. 
\item Un punto en la arteria carótida interna, justo antes de que la arteria entre en la base craneal.
\item Un punto en la arteria carótida externa, donde la arteria se encuentra más cercana a la mandíbula.
\end{itemize}
\end{itemize}

\section{Vesselness}
El algoritmo Vesselnes se basa en un esquema de difusión anisotrópico guiado por posibilidad de igualdad de vasos a nivel de pixel. Es básicamente un filtro de suavizado, dónde la fuerza y la dirección de difusión vienen determinados por una medida llamadas ``vesselness''. La medida de vesselness es analizada mediante el sistema de autovectores de la matriz Hessiana. Se han propuesto varias funciones de vesselness. El algoritmo de Vesselness de Manniesing´s está basado en la función de vesselness de Frangi. 
Para incrementar la magnitud de los autovalores de la matriz Hessiana
\begin{equation}
|\lambda_{1}| \leq |\lambda_{2}| \leq |\lambda_{3}|
\label{eqn:eigen}
\end{equation}
la función de vesselness de Frangi está formada por tres componentes formulados para discriminar las estructuras tubulares de las estructuras similares a manchas o placas como se puede ver en la ecuación \ref{eqn:Ff}
\begin{equation}
V_F(\lambda)=\cases{0 &if $\lambda_{2} > 0$ or $\lambda_{3} > 0$ \cr (1-e^{-\frac{R_A^2}{2\alpha ^2}})\cdot(e^{-\frac{R_B^2}{2\beta ^2}})\cdot(1-e^{-\frac{S^2}{2\gamma ^2}}) &$otherwise$}
\label{eqn:Ff}
\end{equation}
donde
\begin{equation}
R_A=\frac{|\lambda _2|}{|\lambda _3|}
\label{eqn:RA}
\end{equation}
\begin{equation}
R_B=\frac{|\lambda _1|}{\sqrt{|\lambda _2\lambda _3|}}
\label{eqn:RB}
\end{equation}
\begin{equation}
S=\sqrt{\lambda _1^2+\lambda _2^2+ \lambda _3^2}
\label{eqn:S}
\end{equation}
$\alpha$, $\beta$, $\gamma$ son umbrales que controlan la sensibilidad de la medida de vesselness.

Sin embargo, la función de vesselness de Frangi no es continúa y no puede ser utilizada en el proceso de difusión. Por tanto, Manniesing y otros propusieron una versión suavizada de la versión de la función de vesselness de Frangi como se ve a continuación.
\begin{equation}
V_S(\lambda)=\cases{0 &if $\lambda _2 \geq 0$ or $\lambda _3 \geq 0$ \cr (1-e^{-\frac{R_A^2}{2\alpha ^2}})\cdot(e^{-\frac{R_B^2}{2\beta ^2}})\cdot(1-e^{-\frac{S^2}{2\gamma ^2}})\cdot(e^{-\frac{2c^2}{|\lambda _2||\lambda _3^2|}}) &$otherwise$}
\label{sqn:SmoothV}
\end{equation}
Para un análisis multiescala, la función de vesselness es calculada para un rango de escalas y se selecciona la máxima respuesta.
\begin{equation}
V=max_{\alpha _{min} \leq \alpha \leq \alpha _{max}} V_s(\lambda)
\label{eqn:maxV}
\end{equation}
A continuación, se define un tensor de difusión de tal manera que la difusión se promueve a lo largo del vaso, pero no de forma perpendicular a los mismos.
\begin{equation}
D=Q\lambda'Q^T
\label{eqn:difusion}
\end{equation}
Donde $Q$ es una matriz que contiene los autovectores de la matriz Hessiana y $\lambda'$ es la matriz diagonal que contiene los siguientes elementos:
\begin{equation}
\lambda_1' = 1+(w-1)V^{\frac{1}{S}}
\label{eqn:DiaM}
\end{equation}
\begin{equation}
\lambda_2'=\lambda_3' = 1+(\varepsilon-1)\cdot V^{\frac{1}{S}}
\label{eqn:DiaM2}
\end{equation}
Donde $\varepsilon$, $w$ y $S$ son parámetros del algoritmo.

Utilizando esta definición de tensor, la ecuación de difusión quedaría de la siguiente forma:
\begin{equation}
L_t = \nabla\cdot(D\nabla L)
\label{eqn:TDE}
\end{equation}
Las estructuras vasculares se mejorarán por la evolución de la imagen de acuerdo a la ecuación \ref{eqn:TDE}.\cite{Vesselness}
\section{Level Sets}
\begin{figure}
\centering
\includegraphics[scale=0.7]{level.png}%ext=pdf,jpg,png
\caption{Concepto de ``zero set'' en un Level Set}
\label{fig:LS}
\end{figure}
El paradigma de Level Set es un método numérico para el seguimiento de la evolución de contornos y superficies. En lugar de manipular el contorno directamente, el contorno se incrusta como el ``zero level set'' de la función dimensional mayor llamada función de {\em Level Set}, $\Psi(X,t)$. La función de Level Set entonces evoluciona bajo el control de una ecuación diferencial. En cada momento, la evolución del contorno se puede obtener extrayendo el ``zero level set'' $\Gamma((X),t)=\{\Psi(X,t)=0\}$ de la salida. La principal ventaja de utilizar Level Set es que la complejidad aleatoria de las formas puede ser modelada y los cambios topológicos como las mezclas y las divisiones se manejan de forma implícita.

Level Set puede ser utilizado para la segmentación de imágenes basándose en características como la media de la intensidad, el gradiente y los bordes en la ecuación diferencial que lo rige. En un enfoque típico, un contorno se inicializa por un usuario y después este evoluciona hasta que se adapta a la forma de una estructura anatómica en la imagen. Existen muchas implementaciones diferentes y variantes de este concepto básico.

ITK posee diferentes filtros de segmentación mediante Level Set pero todos tienen en común una serie de características. Cada filtro hace uso de una ecuación genérica de Level Set para calcular la actualización de la solución $\Psi$ de la ecuación diferencial parcial.
\begin{equation}
\frac{d}{dt}\Psi = -\alpha A(x)\cdot\nabla\Psi -\beta P(x)|\nabla\Psi | +\gamma Z(x)\kappa |\nabla\Psi|
\label{eqn:diferencial}
\end{equation}
donde $A$ es el término de advección (atrae al Level Set a los límites del objeto), $P$ es el término de propagación (expansión), y $Z$ es un término modificador espacial para la curvatura media $\kappa$. Las constantes escalares $\alpha$, $\beta$ y $\gamma$ miden el peso de la influencia relativa de cada una de los términos en el movimiento de la interfaz. Un filtro de segmentación puede utilizar todo estos términos para sus cálculos, o puede omitir el uso de uno o más términos. Si se deja un término fuera de la ecuación, los ajustes en el peso de su correspondiente constante escalar no tendrán efecto.

Todos los filtros de segmentación basados en Level Set deben trabajar con valores reales (float) para producir resultados correctos. Por defecto, se utilizan valores reales en los filtros, pero si se quiere mayor precisión se tendrá que hacer uso de valores tipo ``double''. 

Como entrada necesitaremos dos imágenes, un modelo inicial $\Psi(X,t=0)$ y una imagen ``característica'' (feature image), que es, o bien la imagen que se desea segmentar o una imagen preprocesada. Se debe especificar el ``isovalue'' que representa a la superficie $\Gamma$ en tu modelo inicial. La única imagen de salida es la función $\Psi$ en el último momento. Se debe tener en cuenta que el contorno que representa la superficie $\Gamma$ es el ``zero level set'' de la imagen de salida y no el ``isovalue'' especificado por el modelo inicial. Para representar $\Gamma$ utilizando el ``isovalue'' original, sólo se tiene que añadir el valor de nuevo a la salida.

La solución $\Gamma$ se calcula con una precisión subpixel. La mejor aproximación discreta de la superficie es, por tanto, el conjunto de posiciones de la rejilla cercanas al paso por cero en la imagen, como se puede ver en \ref{fig:gridLS}. El filtro de paso por cero opera buscando exactamente estas posiciones de rejilla y puede ser utilizado para extraer la superficie.

Hay dos detalles importantes cuando analizamos el tiempo de procesamiento de la segmentación mediante Level Set:
\begin{itemize}
\item El área de la superficie.
\item La distancia total que la superficie recorre.
\end{itemize}
Debido a que la ecuación de Level Set suele resolverse sólo en los píxeles cercanos a la superficie, el tiempo empleado en cada iteración dependerá del número de puntos de la superficie. Esto significa que a medida que la superficie crece, el tiempo de resolución aumentará proporcionalmente, debido a que la superficie debe evolucionar de manera más lenta para prevenir inestabilidades numéricas en la solución. La distancia que la superficie debe recorrer en la imagen determina el número total de iteraciones necesarias.\cite{ITK05}

\begin{figure}
\centering
\includegraphics[scale=0.7]{grid.PNG}%ext=pdf,jpg,png
\caption{La superficie del Level Set implícito $\Gamma$ es la línea negra  superpuesta encima de la rejilla. La ubicación de la superficie es interpolada en los valores de pixel de la imagen. Los píxeles cercanos a la superficie implícita se muestran en gris.\cite{ITK05}}
\label{fig:gridLS}
\end{figure}


\chapter{Diseño}

\section{Multihilos}
Insight Toolkit está diseñado para trabajar en entornos multiprocesador. Muchos de los filtros de Insight Toolkit usan multihilos. Cuando un filtro que usa multihilos se ejecuta, este automáticamente divide el trabajo entre los procesadores haciendo uso de la memoria compartida, esto se llama ``Filter Level Multithreading''.

Las aplicaciones compiladas con Insight Toolkit pueden también manejar la ejecución de sus propios hilos. Por ejemplo, una aplicación podría utilizar un hilo para procesar información y otro hilo para la interfaz de usuario, esto se llama ``Application Level Multithreading''.

\begin{figure}
\centering
\includegraphics[scale=0.7]{sshot-1.PNG}%ext=pdf,jpg,png
\caption{Multihilos \cite{ITK05}}
\label{fig:Multihilos}
\end{figure}

Un filtro que utiliza multihilos proporciona una implementación del método ``ThreadedGenerateData()''. La superclase del filtro producirá varios hilos (normalmente se corresponde con el número de procesadores del sistema) y llamará a ``ThreadedGenerateData()'' por cada hilo especificando la parte de la salida que cada hilo debe generar. Por ejemplo, en un ordenador con dual core, un filtro que procese una imagen generará dos hilos, cada hilo producirá una de las mitades de la imagen de salida y a cada hilo sólo se le permite escribir en su porción de imagen asignada. Un detalle a tener en cuenta es que la imagen completa de entrada y la imagen completa de salida está disponibles en cada llamada de ``ThreadedGenerateData()''. Cada hilo es libre de leer cualquier posición de la imagen de entrada pero en el momento de la escritura sólo pueden hacerlo en su porción asignada.


La imagen de salida es un único bloque contiguo de memoria que es utilizado por todos los hilos. Cada hilo tiene asignado una serie de pixeles para los que tiene que generar los valores correspondientes. Todos los hilos escriben en el mismo bloque de memoria pero a cada hilo se le permite escribir sólo un conjunto de píxeles.

\section{Wrapping en AMILab}
Se ha propuesto realizar una mejora en la distribución de los filtros ITK en AMILab. Lo que se ha buscado es que cada filtro que se añada a AMILab esté contenido en un fichero diferente para así facilitar el entendimiento del código.


En un principio todos los filtros ITK que se añadían a AMILab venían contenidos en un mismo fichero, lo que provocaba códigos demasiados largos y difíciles de seguir. Se partía de un fichero cabecera .h y un fichero dónde estaban las implementaciones .cpp. En el fichero cabecera estaban contenidas las cabeceras de los nuevos filtros y sobretodo la cabecera del procedimiento encargado de añadir una nueva variable a AMILab, la cual será la encargada de permitir la llamada y ejecución del nuevo filtro añadido. Este procedimiento es de vital utilidad ya que nos permite ir añadiendo, de manera sencilla, funcionalidades a AMILab.


A día de hoy, lo que se ha buscado es que cada nueva funcionalidad venga englobada en un fichero por separado, de manera que facilite el entendimiento de los mismos y permita que las posibles modificaciones que se necesiten realizar se hagan de manera más sencilla y rápida. Se ha mantenido un fichero .cpp que contiene la implementación del procedimiento que permite añadir funcionalidades a AMILab, de manera que cada vez que se quiera añadir un nuevo filtro se ha de crear su variable en este fichero. A su vez cada nueva funcionalidad tendrá un fichero .h y un .cpp dónde estarán la cabecera e implementación de cada una.


Por tanto, tendremos dos ficheros por cada nueva funcionalidad y dos ficheros que se irán incrementando encargados de añadir dichas funcionalidades a AMILab.

\section{Representación de datos}
Hay dos tipos principales para representar datos en Insight Toolkit: imágenes y mallas. Estas funcionalidades se implementan en las clases Image y Mesh, siendo ambas subclases de itk::DataObject.


Itk::Image representa un muestro de datos n-dimensional y regular. La dirección del muestro es paralela a cada eje de coordenadas. El origen del muestreo, el espacio entre píxeles y el número de muestras en cada dirección (por ejemplo, la dimensión) puede ser especificado. El tipo del muestreo o del pixel en Insight Toolkit puede ser aleatorio (un parámetro template TPixel especifica el tipo una vez instanciado el template). La dimensión de la imagen deberá ser especificada cuando la clase imagen es instanciada. La clave es que el tipo del pixel debe soportar ciertas operaciones (por ejemplo, suma o resta) si el código es compilado en todos los casos (por ejemplo, para ser procesado por un filtro en particular que usa estas operaciones). En la práctica los usuarios de Insight Toolkit usan tipos simples de C++ (por ejemplo, int o float) o tipos de pixel predefinidos y raramente crearán un nuevo tipo de pixel.


Uno de los conceptos más importantes en Insight Toolkit en lo que a las imágenes se refiere es que los trozos rectangulares y continuos de una imagen se conocen como regiones. Las regiones son usadas para especificar que parte de la imagen se va a procesar, por ejemplo en multihilos, o que parte se guarda en memoria. En Insight Toolkit hay tres tipos básicos de regiones:
\begin{enumerate}
	\item LargestPossibleRegion: la imagen en su totalidad.
	\item BufferedRegion: la parte de la imagen guardada en memoria.
	\item RequestedRegion: la parte de la región solicitada por un filtro o por otra clase cuando se opera en la imagen.
\end{enumerate}

\section{Procesamiento de datos en el pipeline}
Mientras los objetos de datos (por ejemplo, imágenes y mallas) son usados para representar datos, los objetos de procesos son clases que operan en los objetos de datos y pueden producir nuevos objetos de datos. Los objetos de procesos son clases como sources, objetos de filtros o mappers. Sources (tal que los lectores) producen datos, los objetos de filtros toman datos y los procesan para producir nuevos datos y los mappers aceptan datos desde el exterior o de un archivo o de otro sistema. A veces el término filtro es usado en líneas generales para referirse a los tres tipos.


El procesamiento de datos en el pipeline vincula los objetos de datos con los objetos de procesos. El pipeline suporta un mecanismo automático de actualización que causa que se ejecute un filtro si y sólo si su entrada o su estado interno ha cambiado. Además, el pipeline de datos soporta streaming, la habilidad de automáticamente dividir los datos en partes más pequeñas, procesar cada parte y juntar los datos procesados en un resultado final.


Normalmente los objetos de datos y los objetos de procesos están conectados entre sí usando los métodos ``SetInput()'' y ``GetOutput()''.


Cuando el método ``Update()'' es invocado en el escritor, el procesamiento de datos del pipeline provoca en cada uno de los filtros la finalización, escribiendo los datos finales en un archivo en disco.

\section{Clases básicas a utilizar}
En este apartado se comentarán aquellas clases básicas que se han utilizado a la hora de desarrollar este proyecto.

\subsection{Clase Image}
La clase itk::Image sigue el espíritu de la programación genérica, donde los tipos están separados del comportamiento algorítmico de la clase. Insight Toolkit soporta imágenes formadas por cualquier tipo de pixel y de cualquier dimensión espacial.


A continuación se detalla cómo realizar una serie de operaciones sobre imágenes que nos pueden ser de ayuda:

\subsubsection{Crear una imagen}
Lo primero que debemos hacer para crear una clase imagen es incluir el fichero cabecera ``itkImage.h''. Después decidiremos de qué tipo serán los píxeles de nuestra imagen y qué dimensión tendrá. Con estos dos parámetros ya podemos instanciar la clase imagen. La imagen puede entonces ser creada invocando al operador ``New()'' del tipo de imagen correspondiente y asignando el resultado a un puntero inteligente.


En Insight Toolkit, las imágenes existen por la combinación de una o más regiones. Una región es un subconjunto de la imagen e indica la parte de la imagen que puede ser procesada por otras clases en el sistema. 


En Insight Toolkit, la creación manual de una imagen requiere que la imagen sea instanciada como hemos explicado anteriormente y que las regiones que describen la imagen sean entonces asociadas con ella.


Una región se define por dos clases: itk::Index e itk::Size. El origen de una región dentro de la imagen con la que está asociado se define mediante ``Index''. La extensión, o el tamaño, de la región viene dado por ``Size'', el cual vendrá representado por un array dónde los componentes del mismo son enteros que indican la extensión en pixeles de la imagen a lo largo de todas las dimensiones. ``Index'' se representa por un vector n-dimensional donde cada componente es un entero (en coordenadas de la image) que indica el pixel inicial de la imagen. Cuando una imagen es creada manualmente, el usuario es responsable de la definición del tamaño de la misma y del índice en el cual la imagen comienza. Estos dos parámetros hacen posible el proceso de selección de regiones.


Teniendo definido el comienzo y el tamaño de la imagen, estos dos parámetros serán usados para crear un objeto de tipo ``ImageRegion'' el cual encapsula estos dos conceptos. La región será inicializada con el índice y el tamaño.


Por último, la región será pasada al objeto imagen con el fin de definir su extensión y origen, esto se realiza mediante el método ``SetRegions()''. Por último se llamará al método ``Allocate()'' para tomar memoria dónde almacenar los datos de los pixeles de la imagen.


En la práctica es raro reservar memoria e inicializar una imagen directamente. Las imágenes se leen normalmente de un recurso, como un archivo o de sistema de adquisición.

\subsubsection{Leer una imagen de un archivo}
El primer requisito para leer una imagen desde un archivo es incluir el fichero cabecera ``itkImageFileReader.h''.
Después, el tipo de la imagen debe ser definido especificando el tipo utilizado para representar los pixeles. También se deberá indicar la dimensión de la imagen.


Usando el tipo de la imagen, es posible instanciar la clase encargada de leer la imagen. El tipo de la imagen es usado como parámetro template para definir como los datos serán representados una vez sean cargados en memoria. Este tipo no tiene porque corresponder con el tipo guardado en el archivo. De todos modos, se utiliza una conversión como la utilizada por C en la conversión entre tipos. Los lectores no aplican ninguna transformación a los datos de los pixeles a excepción de la conversión realizada entre el tipo del pixel del archivo y el tipo del pixel del lector. Una vez tengamos instanciado el tipo del lector podremos usarlo para crear un objeto lector (ImageFileReader). Un puntero inteligente será usado para recibir la referencia al nuevo lector creado. El método ``New()'' será invocado para crear una instancia del lector.


La información mínima que necesita un lector es la ruta del archivo que va a ser cargado en memoria. Esto se obtiene a través del método ``SetFileName()''.


Los objetos lectores son referidos como los objetos recursos del pipeline; ellos responden a las peticiones de actualización del pipeline e inicializan el flujo de datos del pipeline. El mecanismo de actualización del pipeline se asegura de que el lector sólo se ejecuta cuando una petición de datos es hecha al lector y este no esté leyendo ninguna información. El método ``Update()'' puede ser invocado explícita o implícitamente. Si se realiza explícitamente puede ser porque la salida del lector no está conectada al resto de los filtros. Normalmente la salida del lector está conectada a la entrada de un filtro y la actualización en el filtro produce una actualización en el lector.


Para acceder a la imagen leída basta con llamar al método ``GetOutput()'' del lector. Este método se puede ejecutar incluso antes de que se realice la actualización del lector, lo que pasará será que la referencia a la imagen será válida aunque la imagen estará vacía hasta que el lector actual se ejecute.


Cualquier intento de acceder a los datos de la imagen antes de que el lector se ejecute producirá una imagen sin datos en los pixeles.

\subsubsection{Definiendo el origen y el espacio}
Aunque Insight Toolkit se puede usar para trabajar con tareas de procesamiento de imágenes generales, el objetivo principal del sistema es el procesado de imágenes médicas. En este sentido, cierta información adicional acerca de las imágenes es necesaria. En particular la información asociada con el espacio físico entre los píxeles y la posición de la imagen en el espacio respecto a un sistema de coordenadas son muy importantes.


El origen y el espacio de una imagen son fundamentales para muchas aplicaciones. Las imágenes médicas sin información espacial no podrán ser usadas ni para diagnóstico médico, análisis de imágenes, extracción de características, terapias de radiación asistida o cirugía guiada por imágenes. En otras palabras, las imágenes médicas carentes de información espacial no sólo son inútiles sino que además son peligrosas.

\begin{figure}
\centering
\includegraphics[scale=0.7]{image003.PNG}%ext=pdf,jpg,png
\caption{Origen y espacio \cite{ITK05}}
\label{contexto:figura}
\end{figure}

\subsubsection{Imágenes RGB}
El espacio RGB ha sido construido como una representación de las respuestas fisiológicas a la luz por los tres tipos de conos del ojo humano. RGB no es un espacio de vectores.  Por ejemplo, los números negativos no son apropiados en un espacio de colores porque serían el equivalente a una estimulación negativa en el ojo humano. En el contexto de la colorimetría, los valores de colores negativos se usan como una construcción artificial para la comparación de colores 
\begin{equation} Color A = Color B - Color C \end{equation}

Es sólo una forma de decir que podemos producir el Color B mediante la combinación del Color A y el Color C. Sin embargo, debemos ser conscientes de que (por lo menos en la emisión de luz) no es posible restar luz.


Cuando tratamos con color impreso y con pinturas, en contraposición con la luz emitida en las pantallas de los ordenadores, el comportamiento físico del color permite la resta. Esto es porque estamos hablando estrictamente de objetos que lo que vemos como rojo es aquello que ha absorbido todas las frecuencias de luces excepto aquellas que en su espectro posean el rojo.


El concepto de suma y resta en los colores debe ser interpretado cuidadosamente. De hecho, RGB tiene una definición diferente en lo que respecta a si estamos hablamos acerca de los canales asociados a los tres colores de los sensores del ojo humano, o a los tres fósforos encontrados en la mayoría de los monitos o a las tintas de color utilizadas en las impresoras. El espacio de colores no suele ser linear  y a veces ni siquiera es de un grupo. Por ejemplo, no todos los colores que vemos pueden ser representados en el espacio RGB.


Insight Toolkit introduce el tipo itk::RBGPixel como soporte para la representación de los valores de un espacio de color RGB. Como tal, la clase ``RGBPixel'' expresa un concepto diferente de la de itk::Vector en el espacio. Por esta razón, ``RGBPixel'' carece de muchos de los operadores que cabrían esperar de él. En particular, no están definidas las operaciones de resta y suma.
Cuando pensamos en la realización de la media en un tipo RGB estamos presuponiendo que en el espacio de colores proporcionado, la acción de encontrar un color en el centro de dos colores, puede ser calculada utilizando una operación linear entre sus representaciones numéricas. Este no es, por desgracia, el caso de los colores en el espacio debido a que están basados en las respuestas fisiológicas del ser humano.


Si se decide interpretar las imágenes RGB simplemente como tres canales independiente se tendrá que usar bastante el tipo itk::Vector como tipo para los píxeles. En este sentido, se tendrá acceso a todo el conjunto de operaciones definidas para los espacios de vectores. La implementación actual de ``RGBPixel'' en Insight Toolkit supone que las imágenes de color RGB están previstas para ser usadas en aplicaciones donde se requiera una interpretación formal del color, de ahí que sólo las operaciones que son válidas en los espacios de colores estarán disponibles para la clase ``RBGPixel''.


Gracias a la flexibilidad ofrecida por el estilo de programación genérica en el que Insight Toolkit está basado, es posible instanciar imágenes en las que sus píxeles sean de cualquier tipo. 


Existe una clase en Insight Toolkit prevista para soportar píxeles del tipo RGB, por lo que si queremos tener una imagen con colores RGB podremos hacerlo. Para usar esta clase (itk::RGBPixel) debemos incluir el fichero cabecera ``itkRGBPixel.h''. El acceso a los componentes de color de los píxeles  puede ser realizado con los métodos proporcionados por la clase ``RGBPixel''.

\subsection{Clase Iterator}
La programación genérica parte de los contenedores y de los algoritmos. Los contenedores almacenan datos y los algoritmos operan con estos datos. Para acceder a los datos en los contenedores, los algoritmos usan tres tipos de objetos llamados iteradores. Un iterador es una es una abstracción de un puntero de memoria. Todos los tipos contenedor definen sus propios tipos iterador, pero todos los iteradores están escritos para proporcionar una interfaz común de tal manera que el algoritmo puede referenciar los datos de una forma genérica y mantener cierta independencia funcional con los contenedores.


El iterador se llama así porque se es usado para el acceso secuencial e iterativo a los valores de un contenedor. Los iteradores aparecen en las estructuras for y while. Un puntero en C es, por ejemplo, un tipo de iterador. Puede ser incrementado o decrementado a través de la memoria para referenciar secuencialmente los elementos de un vector. Muchas implementaciones de los iteradores tienen una interfaz similar a la de un puntero en C.


En Insight Toolkit se usan los iteradores para escribir código de procesamiento de imágenes genéricas. Con ello se permite instanciar imágenes formadas por combinaciones diferentes de tipos de píxeles,  por tipos contenedor de píxeles y por dimensiones variadas. Debido a que los iteradores de imágenes están especialmente diseñados para trabajar con contenedores de imágenes, su interfaz e implementación están optimizadas para tareas de procesamiento de imágenes. El uso de un iterador de Insight Toolkit en vez del acceso directo a los datos a través de la interfaz itk::Image proporciona muchas ventajas. El código es mucho más compacto, los algoritmos son mucho más rápidos y los iteradores simplifican tareas como multihilos y procesamiento de imágenes basado en vecindades.


A continuación se detallarán algunas operaciones fundamentales para el uso de los iteradores:

\subsubsection{Crear un iterador}
Todos los iteradores de imágenes tienen al menos un parámetro template que es el tipo de la imagen sobre el cual van a iterar. No hay ninguna restricción sobre la dimensión de la imagen o sobre el tipo de píxeles que contiene la misma.

  
Un constructor de iteradores necesita al menos dos argumentos, un puntero inteligente a la imagen que tiene que recorrer y una región de una imagen. La región de la imagen, llamada región de iteración, es un área rectangular en la cual se producirá el recorrido. La región de iteración debe estar totalmente contenida dentro de la imagen. Más específicamente, una región de iteración válida es cualquier subregión de una imagen (BufferedRegion).


Hay versiones constantes y no constantes para la gran mayoría de los iteradores de imágenes en Insight Toolkit. Un iterador no constante no puede ser instanciado apuntando a una imagen que sea constante. La versión constante de un iterador puede leer pero no puede escribir los valores de los píxeles.

\subsubsection{Mover un iterador}
Un iterador se va moviendo por su región de iteración. En cada momento, el iterador apuntará, punto a punto, a la ubicación de un pixel en una imagen N-dimensional. La iteración hacia adelantes va desde el comienzo de la región de iteración hasta el final de la misma. La iteración hacia atrás va desde pasado el último píxel de la región hasta el comienzo ce la misma. Por tanto, hay dos puntos de comienzo para los iteradores, el principio y el final de una imagen. Un iterador puede ser movido directamente a una de estas dos posiciones utilizando los siguientes métodos:
\begin{itemize}
	\item ``GoToBegin()'' $\rightarrow$ Fija el iterador en el primer elemento válido de la región.
	\item ``GoToEnd()'' $\rightarrow$ Fija el iterador en la siguiente posición al último elemento de la región.
\end{itemize}

\begin{figure}
\centering
\includegraphics[scale=0.7]{image005.PNG}%ext=pdf,jpg,png
\caption{Recorrido de un iterador \cite{ITK05}}
\label{fig:iterador}
\end{figure}

Se debe recordar que la posición a la que apunta GoToEnd() no está dentro de la región de iteración. Este hecho se debe recordar ya que si se intenta liberar el iterador en este punto obtendremos resultados indefinidos.


Los iteradores de Insight Toolkit son movidos usando los operadores de incremento y decremento:
\begin{itemize}
	\item ``Operator++()'' $\rightarrow$ incrementa el iterador una posición en dirección positiva.
	\item ``Operator++()'' $\rightarrow$ decrementa el iterador una posición en dirección negativa.
\end{itemize}

En la figura \ref{fig:iterador} se puede ver cómo actúa un iterador en una región de una imagen. Un iterador primero se mueve a través de las columnas, después por filas, después capa a capa y así sucesivamente.
Además de la iteración secuencial a través de la imagen, algunos iteradores pueden definir operadores de acceso aleatorio. A diferencia de los operadores incrementales, los operadores de acceso aleatorio pueden no estar optimizados para ser rápidos y requieren algunos conocimientos de la dimensión de la imagen y de la extensión de la región de iteración para poder ser usados correctamente.
\begin{itemize}
	\item ``Operator+=(OffsetType)'' $\rightarrow$ mueve el iterador a la ubicación del pixel que surja como resultado de sumar el índice actual al desplazamiento dado.
	\item ``Operator-=(OffsetType)'' $\rightarrow$ mueve el iterador a la ubicación del pixel que surja como resultado de restar el índice actual al desplazamiento dado.
\end{itemize}


El método ``SetPosition()'' puede ser extremadamente lento para los iteradores más complicados. En general, sólo se utiliza para fijar la posición de comienzo, tal y como hacen los métodos ``GoToBegin()'' y ``GoToEnd()''.
Muchos iteradores no siguen la ruta que se espera que sigan a través de sus regiones de iteración y no tienen establecido la posición de comienzo o de fin. Los iteradores aleatorios, por ejemplo, incrementan y decrementan de manera aleatoria la posición del iterador. De esta forma pueden visitar una posición más de una vez.
A un iterador se le puedo preguntar si está al comienzo o al final de una región de iteración: 
\begin{itemize}
	\item ``bool IsAtEnd()'' $\rightarrow$ devuelve verdadero si el iterador apunta a la siguiente posición del último pixel de la región de iteración.
	\item ``bool IsAtbegin()'' $\rightarrow$ devuelve verdadero si el iterador apunta a la primera posición de la región de iteración. Este método se utiliza para comprobar si estamos en el final de una iteración al revés.
\end{itemize}

Un iterador también puede informar de su posición actual en la imagen:
\begin{itemize}
	\item ``IndexType GetIndex()'' $\rightarrow$ devuelve el índice de la posición actual del iterador.
\end{itemize}


Por eficiencia, la mayoría de los iteradores de imágenes en Insight Toolkit no realizan comprobación de límites. Por lo que es posible mover un iterador fuera de su región válida de iteración.

\subsection{Clase Image Iterator}
A continuación se describirán aquellos iteradores que recorren regiones de imágenes rectilíneas y apuntan a una posición en concreto en cada momento. itk::ImageRegionIterator es el iterador de imágenes más común en Insight Toolkit y suele ser la primera elección para la gran mayoría de las aplicaciones. El resto de los iteradores que se explicarán son especializaciones de ``ImageRegionIterator''. Estos se han diseñado para realizar tareas básicas de procesamiento de imágenes de manera más eficiente o para facilitar la implementación.

\subsubsection{ImageRegionIterator}
itk::ImageRegionIterator está optimizado para iterar de forma rápida y es la primera elección para operaciones iterativas en lo que respecta a píxeles cuando la posición en la imagen no es importante. ``ImageRegionIterator'' es el iterador menos especializado de las clases iterador de imágenes de Insight Toolkit.

\subsubsection{ImageRegionIteratorWithIndex}
La familia de iteradores ``WithIndex'' están diseñados para algoritmos que usan tanto el valor como la posición del pixel para sus cálculos. A diferencia de itk::ImageRegionIterator, el cual calcula el índice sólo si se requiere, itk::ImageRegionIteratorWithIndex guarda la posición del índice como variable miembro la cual será actualizada mientras se incrementa o decrementa la iteración. La rapidez con la que se realiza la iteración es más lenta pero las peticiones de la posición del índice son más eficientes.

\subsubsection{ImageLinearIteratorWithIndex}
itk::ImageLinearIteratorWithIndex está diseñado para ir procesando línea por línea una imagen. Este iterador recorre de forma linear la imagen en dirección paralela a uno de los ejes de coordenadas. Conceptualmente, este iterador divide la imagen en una serie de líneas paralelas que se extienden a lo largo del tamaño de la imagen.


Como todos los iteradores de imágenes, el movimiento de ``ImageLinearIteratorWithIndex'' está limitado dentro de la región de la imagen R. La línea ``l'' a través de la cual se mueve el iterador está definida seleccionando una dirección y un origen. La línea l se extiende desde el origen hasta el límite superior de R. El origen puede ser movido a cualquier posición a lo largo de los límites inferiores de R.


Existen varios métodos adicionales para este iterador que controlan el movimiento del mismo a lo largo de la línea l y el desplazamiento del origen de l:
\begin{itemize}
	\item ``NextLine()'' $\rightarrow$ mueve el iterador a la primera posición de la siguiente línea de la imagen. 
	\item ``PreviousLine()'' $\rightarrow$ mueve el iterador a la última posición válida de la línea anterior.
	\item ``GoToBeginOfLine()'' $\rightarrow$ mueve el iterador a la primera posición de la línea actual.
	\item ``GoToEndOfLine()'' $\rightarrow$ mueve el iterador una posición más allá de la última posición válida de la línea actual.
	\item ``IsAtReverseEndOfLine()'' $\rightarrow$ devuelve verdadero si el iterador apunta a una posición anterior a la primera posición de la línea actual.
	\item ``IsAtEndOfLine()'' $\rightarrow$ devuelve verdadero si el iterador apunta a una posición más allá de la última posición válida de la línea actual.
\end{itemize}

\subsubsection{ImageSliceIteratorWithIndex}
La clase itk::ImageSliceIteratorWithIndex es una extensión de itk::ImageLinearIteratorWithIndex, pasando de iterar a lo de largo de las líneas a iterar tanto a lo largo de las líneas como de los planos de la imagen. Una capa es un plano 2D abarcado por dos vectores apuntando a lo largo del eje de coordenadas ortogonal. La orientación de la capa está definida por la especificación de sus dos ejes de expansión.
\begin{itemize}
	\item ``SetFirstDirection()'' $\rightarrow$ especifica la primera dirección del eje de coordenadas de la capa.
	\item ``SetSecondDirection()'' $\rightarrow$ especifica la segunda dirección del eje de coordenadas de la capa.
\end{itemize}

Varios métodos controlan el movimiento de una capa a otra:
\begin{itemize}
	\item ``NextSlice()'' $\rightarrow$ mueve el iterador a la primera posición de la siguiente capa en la imagen.
	\item ``PreviousSlice()'' $\rightarrow$ mueve el iterador a la última posición válida en la capa anterior.
	\item ``IsAtReverseEndOfSlice()'' $\rightarrow$ devuelve verdadero si el iterador apunta a una posición anterior a la primera posición de la capa actual.
	\item ``IsAtEndOfSlice()'' $\rightarrow$ devuelve verdadero si el iterador apunta a una posición más allá de la última posición válida de la capa actual.
\end{itemize}

El iterador de capas se mueve línea a línea utilizando NextLine() y PreviousLine(). La dirección de la línea es paralela a la dirección del segundo eje de coordenadas del plano de la capa.

\subsubsection{ImageRandomConstIteratorWithIndex}
itk::ImageRandomConstIteratorWithIndex fue desarrollado para elegir aleatoriamente valores de una muestra. Cuando incrementamos o decrementamos el iterador este salta a una posición aleatoria en la región de la imagen.


El usuario debe especificar el tamaño de la muestra cuando se crea el iterador. ``IsAtEnd()'' devuelve verdadero cuando el número actual de la muestra es igual al tamaño de la muestra. ``IsAtBegin()'' devuelve verdadero cuando el número actual de la muestra es igual a cero. Una diferencia importante es que a diferencia de los otros iteradores, este iterador puede visitar la posición más de una vez.


Este iterador puede ser usado para calcular datos estadísticos de una imagen, como por ejemplo la media.

\subsection{Clase Neighborhood Iterators}
En Insight Toolkit la vecindad de un pixel está definida como un conjunto pequeño de píxeles localmente adyacentes unos a otros en una imagen. El tamaño y la forma de la vecindad, también la conectividad entre los pixeles de una vecindad, puede variar con la aplicación.

\begin{figure}
\centering
\includegraphics[scale=0.7]{image007.PNG}%ext=pdf,jpg,png
\caption{Neighborhood Iterator \cite{ITK05}}
\label{fig:iteradorV}
\end{figure}

Muchos algoritmos de procesamiento de imágenes están basados en vecindades, es decir, el resultado de un pixel i se calcula a partir de los valores de los pixeles en la vecindad ND de i. Un ejemplo común en el que se usan vecindades son las operaciones que incluyen convoluciones.


Por tanto, en este apartado se describirán aquellos iteradores que están diseñados para trabajar con las vecindades de los pixeles. En Insight Toolkit los iteradores de vecindades recorren la región de la imagen como un iterador normal, pero en vez de referenciar sólo a un único pixel en cada paso, apunta simultáneamente a toda la vecindad ND. Como ampliación de los iteradores normales podemos tener acceso de lectura y escritura a todos los pixeles vecinos e información sobre el tamaño, extensión y posición de la vecindad.


En la figura \ref{fig:iteradorV} podemos ver un iterador de vecindades moviéndose a través de una región de iteración. Este iterador define una vecindad de 3x3 alrededor de cada pixel que visita. El centro de la vecindad está siempre posicionado en el índice actual y el resto de los índices de los pixeles serán referenciados mediante el desplazamiento desde el centro.

Además de un puntero a la imagen y a la región de iteración, el constructor del iterador de vecindades necesita un argumento que especifique la extensión de la vecindad a cubrir. La extensión de la vecindad es simétrica y viene dada por un vector de N distancias que se denomina radio. Cada elemento ``d'' del radio, donde 0 $<$ d $<$ N y N es la dimensionalidad de la vecindad, da la extensión de la vecindad en pixeles para la dimensión N. La longitud de cada cara del cubo resultante es de 2d+1 pixeles.

El radio de un iterador de vecindades puede ser consultado. Otros métodos proporcionan información útil acerca del iterador y de su imagen:

\begin{itemize}
	\item ``SizeType GetRadius()'' $\rightarrow$ devuelve el radio ND de una vecindad como un itk::Size.
	\item ``Const ImageType *GetImagePointer()'' $\rightarrow$ devuelve un puntero a la imagen referenciada por el iterador.
	\item ``Unsigned long Size()'' $\rightarrow$ devuelve el tamaño en número de pixeles de la vecindad.
	\item
\end{itemize}

El iterador de vecindades extiende el concepto de obtener y fijar los valores de un pixel con respecto al iterador normal. La vecindad de un pixel se puede ver como un vector linear donde cada pixel tiene un único índice entero. El pixel central está siempre en la posición n/2, donde n es el tamaño del vector.
\begin{itemize}
	\item ``PixelType GetPixel(const unsigned int i)'' $\rightarrow$ devuelve el valor del pixel que se encuentra  en la posición i de la vecindad.
	\item ``Void SetPixel(const unsigned int i, PixelType p)'' $\rightarrow$ cambia el valor del pixel en la posición i por el valor p.	
\end{itemize}


Otra forma de pensar en la posición de un pixel en una vecindad es como desplazamientos ND desde el centro de la vecindad. La esquina superior izquierda de una vecindad 3x3x3, por ejemplo, puede ser descrita mediante el desplazamiento (-1,-1,-1). La esquina inferior derecha de la misma vecindad tendrá el desplazamiento (1,1,1).
\begin{itemize}
	\item ``PixelType GetPixel(const OffsetType $\&$o)'' $\rightarrow$ toma el valor del pixel que se encuentra en la posición dada por el desplazamiento o medido desde el centro de la vecindad.
	\item ``void SetPixel(const OffsetType $\&$o, PixelType p)'' $\rightarrow$ cambia el valor que se encuentra en la posición dada por el desplazamiento o medido desde el centro de la vecindad por el valor p.
\end{itemize}


Los iteradores de vecindades también proporcionan formas de obtener y fijar el valor del pixel central de una vecindad.
\begin{itemize}
	\item ``PixelType GetCenterPixel()'' $\rightarrow$ toma el valor del pixel central de la vecindad.
	\item ``void  SetCenterPixel(PixelType p)'' $\rightarrow$ cambia el valor del pixel central de la vecindad por el valor p.
\end{itemize}


Hay otras formas de obtener y fijar valores de pixeles que están a cierta distancia del centro de la vecindad.
\begin{itemize}
	\item ``PixelType GetNext(unsigned int d)'' $\rightarrow$ toma el valor adyacente al pixel central de la vecindad en la dirección positiva del eje d.
	\item ``void  SetNext(unsigned int d, PixelType p)'' $\rightarrow$ cambia el valor adyacente al pixel central de la vecindad en la dirección positiva del eje d por el valor p.
	\item ``PixelType GetPrevios(unsigned int d)'' $\rightarrow$ toma el valor adyacente al pixel central de la vecindad en la dirección negativa del eje d.
	\item ``void SetPrevious(unsigned int d, PixelType p)'' $\rightarrow$ cambia el valor adyacente la pixel central de la vecindad en la dirección negativa del eje d por el valor p.
	\item ``PixelType GetNext(unsigned int d, unsigned int s)'' $\rightarrow$ toma el valor del pixel que se encuentra a s pixeles del pixel central de la vecindad en la dirección positiva del eje d.
	\item ``void SetNext(unsigned int d, unsigned s, PixelType p)'' $\rightarrow$ cambia el valor del pixel que se encuentra a s pixeles del pixel central de la vecindad en la dirección positiva del eje d por el valor p.
	\item ``PixelType GetPrevious(unsigned int d, unsigned int s)'' $\rightarrow$ toma el valor del pixel que se encuentra a s pixeles del pixel central de la vecindad en la dirección negativa del eje d.
	\item ``void SetPrevious(unsigned int d,unsigned int s, PixelType p)'' $\rightarrow$ cambia el valor del pixel que se encuentra a s pixeles del pixel central de la vecindad en la dirección negativa del eje d por el valor p.
\end{itemize}


Es posible extraer un conjunto de valores de una vecindad en una sola vez. Esto puede ser útil en algoritmos que realizan un gran número de operaciones en una vecindad y que requieren un gran número de referencias a los mismos pixeles.
\begin{itemize}
	\item ``NeighborhoodType GetNeighborhood()'' $\rightarrow$ devuelve un itk::Neighbordhood del mismo tamaño y forma que el iterador de vecindades y contiene todos los valores del iterador en esa posición.
	\item ``void  SetNeighborhood(NeighborhoodType $\&$N)'' $\rightarrow$ cambia todos los valores de una vecindad a los valores contenidos en la vecindad N, la cual debe ser del mismo tamaño y forma.
\end{itemize}


Varios métodos están definidos para proporcionar información acerca de la vecindad.
\begin{itemize}
	\item ``IndexType GetIndex()'' $\rightarrow$ devuelve el índice del pixel central de la vecindad.
	\item ``IndexType  GetIndex(OffsetType o)'' $\rightarrow$ devuelve el índice del pixel que se encuentra en la posición indicada por el desplazamiento o medida desde el centro de la vecindad.
	\item ``IndexType GetIndex(unsigned int i)'' $\rightarrow$ devuelve el índice del pixel que se encuentra en la posición i del vector.
	\item ``OffsetType GetOffset(unsigned int i)'' $\rightarrow$ devuelve el desplazamiento desde el centro de la vecindad que se encuentra en la posición i del vector.
	\item ``unsigned long GetNeighborhoodIndex(OffsetType o)'' $\rightarrow$ devuelve la posición del vector con desplazamiento o desde el centro de la vecindad.
	\item ``std::slice GetSlice(unsigned int n)'' $\rightarrow$ devuelve un std::slice a través del iterador de vecindades a lo largo del eje n.
\end{itemize}


Un cálculo basado en vecindades en una vecindad cercana a los límites de la imagen puede requerir que los datos estén por fuera de los límites. Cuando la extensión de una vecindad cae fuera de los límites de una imagen, los valores para los vecinos perdidos son facilitados según una regla, normalmente elegidos para satisfacer las necesidades numéricas del algoritmo. Una regla para facilitar los valores fuera de los límites de llama condición límite.


Los iteradores de vecindades en Insight Toolkit detectan las referencias fuera de los límites devolviendo valores acordes a las condiciones límites. El tipo de la condición límite viene especificada el segundo parámetro del iterador (opcional). Por defecto, los iteradores de vecindades usan la condición de Neumann donde la primera derivada a través del límite es cero. La regla de Neumann devuelve los valores de los pixeles más cercanos a aquellos que se han solicitado y que están fuera de los límites. Existen varios métodos de condiciones límite en Insight Toolkit. Uno de estos es la condición periódica que devuelve el valor del pixel que se encuentra en el lado contrario, o la condición de valores constantes que devuelve un conjunto de valores para todos los pixeles que están fuera de los límites. Esto es como si rellenásemos la imagen con los valores.


El chequeo de límites es una operación con un alto coste computacional porque se realiza cada vez que el iterador es incrementado. Para aumentar la eficiencia, los iteradores de vecindades automáticamente deshabilitan esta opción cuando detectan que no es necesario. El usuario debería también especificar si desea tener el chequeo de límites habilitado o no.
\begin{itemize}
	\item ``void NeedToUseBoundaryConditionOn()'' $\rightarrow$ se activa el chequeo de límites.
	\item ``void  NeedToUseBoundaryConditionOff()'' $\rightarrow$ se desactiva el chequeo de límites.
	\item ``void  NeedToUseBoundaryConditionOff() $\rightarrow$ se desactiva el chequeo de límites.
	\item ``void OverrideBoundaryCondition(BoundaryConditionType *b)'' $\rightarrow$ cambia la condición límite por la condición límite b. Este método se puede utilizar para cambiar en tiempo de ejecución el comportamiento del iterador.
	\item ``void ResetBoundaryCondition()'' $\rightarrow$ se deja de utilizar cualquier condición de límite especificada (en tiempo de ejecución) y se vuelve a utilizar la condición de base.
	\item ``void SetPixel(unsigned int i, PixelType p, bool status)'' $\rightarrow$ se cambia el valor de una posición i del vector de vecindades por el valor p. Si la posición i está fuera de los límites, status contendrá false, en caso contrario contendrá true.
\end{itemize}

\subsection{Clase Mesh}
\subsubsection{Crear una malla}
Esta clase representa formas en el espacio. Deriva de la clase ``PointSet'' y por tanto hereda todas las funcionalidades relacionadas con los puntos y el acceso a la información de los píxeles asociados a estos puntos. Como todas las clases en Insight Toolkit, la clase Mesh permite utilizar cualquier dimensión.

En la práctica la clase Mesh puede ser vista como un conjuntos de puntos en el que las células de diferentes dimensiones y tamaños han sido añadidas. Las células en la malla se definen en términos de los puntos existentes utilizando los identificadores de los puntos.

Existen dos tipos de mallas disponibles, estáticas y dinámicas. La primera de ellas se utiliza cuando el número de células en el conjunto es conocido a priori y se espera que no cambie debido a las manipulaciones realizadas en el conjunto. Si utilizamos mallas dinámicas las usaremos para insertar y quitar células de manera eficiente. La razón de hacer la distinción entre los dos estilos es facilitar el ajuste de su comportamiento con el fin de optimizar el rendimiento y la gestión de memoria.

Debido a que las mallas suelen ocupar mucha memoria se las referencia utilizando un contador de objetos y se manejan usando punteros inteligentes.

Los puntos que forman la malla pueden ser añadidos mediante el método {\em SetPoint()}. Los puntos se copiarán dentro de la estructura de la malla. Esto significa que las instancias locales de los puntos pueden ser modificadas sin afectar al contenido de la malla.

El número actual de puntos de una malla se obtiene mediante el método {\em GetNumberOfPoints()}

Se puede acceder a los puntos de manera eficiente utilizando un iterador.

\subsubsection{Insertar una célula}
Las mallas pueden contener diferentes tipos de células. Las células más comunes son {\em LineCell}, {\em TriangleCell}, {\em QuadrilateralCell} y {\em TetrahedronCell}. En el caso de las células se tiene mayor flexibilidad a la hora de manejarlas a costa de tener un poco más de complejidad.

La principal diferencia entre cómo se manejan las células y los puntos en la malla es que los puntos se guardan por copia mientras que las células se guardan utilizando punteros.

\section{Filtro Non Local Means Básico}
El diseño principal de nuestro filtro ``Basic NL-Means'' viene determinado por las consideraciones especificadas por Insight Toolkit a la hora de programar un filtro, por tanto, la realización del mismo se ha basado en estas restricciones.


A continuación recordaremos estas restricciones para tener presente cada paso que hemos dado en el diseño de dicho filtro. También cabe destacar que gracias a la gran cantidad de herramientas de que disponemos en Insight Toolkit hemos podido partir de otro filtro similar que nos ha servido de ayuda. 


En primer lugar debemos tener en cuenta que Insight Toolkit tiene utiliza la filosofía multihilos, característica que nos será de gran ayuda a la hora de procesar imágenes de gran tamaño y dimensión.


Otra de las características de Insight Toolkit es que parte de una programación genérica, que como ya se ha visto se fundamenta en los contenedores que se utilizan para almacenar datos, los iteradores para acceder a estos datos y los algoritmos genéricos que usan contenedores e iteradores para crear de manera eficiente algoritmos fundamentales tales como la clasificación. También es importante resaltar que la programación genérica viene soportada por un mecanismo de programación que utiliza template, proporcionando de esta forma reusabilidad al código y a las funciones.


Otra de las ventajas a la hora de utilizar template es que Insight Toolkit busca poder tratar cualquier imagen de cualquier tipo de datos y sin tener en cuenta la dimensión de la misma. Este hecho queda cumplido gracias a los template.


Por último, Insight Toolkit tiene establecida una ``clasificación'' en la que ir englobando cada una de las funcionalidades que proporciona, sobre todo en lo que concierne a los filtros, por tanto:
\begin{itemize}
	\item Filtros de imágenes
	\item Filtros de mallas
	\item Filtros de transformaciones geométricas
	\item Filtros de correspondencia entre imágenes
	\item Filtros de entrada/salida (I/O)
\end{itemize}
En el caso en el que estamos nuestro filtro irá englobado en filtros de imágenes, ya que el mecanismo de procesado es la adquisición de una imagen para su tratamiento, la aplicación del filtro en cuestión y la generación de una nueva imagen.
Los filtros se definen respecto al tipo de datos de entrada (sea cual sea) y al tipo de datos de salida (sea cual sea). La clave para escribir un filtro en Insight Toolkit es la de identificar el número y tipo de las imágenes de entrada y de salida. Una vez tengamos eso, normalmente existe una superclase que simplifica esta tarea a través de derivación de clases. Por ejemplo, casi todos los filtros en Insight Toolkit toman una imagen simple como entrada y producen una imagen simple como salida. La superclase itk::ImageToImageFilter es la clase adecuada que proporciona la suficiente funcionalidad para ese filtro.


Algunas clases base para incluir nuevos filtros son:
\begin{itemize}
	\item ImageToImagFilter: el filtro base más común para los algoritmos de segmentación. Toma una imagen y produce una nueva imagen, por defecto con la misma dimensión.
	\item UnaryFunctorImageFilter: se utiliza cuando se define un filtro que aplica una función a una imagen.
	\item BinaryFunctorImageFilter: se utiliza cuando se define un filtro que aplica una operación a dos imágenes.
	\item ImageFunction: un funtor que puede ser aplicado a una imagen, evaluando f(x) en cada punto de la imagen.
	\item MeshToMeshFilter: un filtro que transforma mallas, como mosaicos, reducción de polígonos, etc...
	\item LightObject: base abstracta para los filtros que no se pueden incluir en ninguna otra clase de la jerarquía.
\end{itemize}
Una vez que se identifica la superclase a utilizar, el escritor del filtro implementa la clase definiendo los métodos requeridos por la gran mayoría de los objetos en Insight Toolkit: New(), PrintSelf(), un constructor protegido, una copia del constructor, un destructor y un operador =. Es importante no olvidar la definición de tipos estándar como Self, Superclass, Pointer y ConstPointer. A continuación, el escritor del filtro puede centrarse en las partes más importantes de la implementación: definición de la API, data members y otros detalles de la implementación del algoritmo. En particular, el escritor del filtro tendrá que implementar el método GenerateData() o ThreadedGenerateData().


Un detalle importante es que el método GenerateData() necesita reservar memoria para la salida mientras que el método ThreadedGenerateData() no. En las implementaciones por defecto GenerateData() reserva memoria y después invoca a ThreadedGenerateData().


Una de las decisiones más importantes que un desarrollador debe tomar es si el filtro separará la imagen en partes; esto quiere decir que sólo se procesará una porción de la entrada para generar una porción de la salida. A menudo, la superclase realiza bien su trabajo: si el filtro procesa la entrada utilizando acceso único a píxeles, entonces el comportamiento por defecto será el adecuado. Si no es así, el usuario tendrá que:
\begin{enumerate}
	\item Obtener una clase más especializada para derivar a partir de ella.
	\item Sobrescribir uno o más métodos que controlen cómo el filtro operará durante la ejecución del pipeline. Estos métodos se describirán a continuación.
\end{enumerate}

Los datos asociados con las imágenes multidimensionales son grandes y pueden llegar a ser más grandes. Esta tendencia se debe a los avances de en la resolución de escaneo, así como los aumentos de capacidad de computación. Cualquier software de segmentación o de correspondencia de imágenes debe hacer frente a este hecho con el fin de ser útil en cualquier aplicación. Insight Toolkit aborda este problema a través de su facilidad de flujo de datos (``data streaming'').


En Insight Toolkit, ``streaming'' es el proceso de dividir información en partes o en regiones, y a continuación procesar esta información a través del pipeline. Recordar que el pipeline se basa en un conjunto de objetos de procesos que generan objetos de datos conectados en la topología del pipeline. La entrada a un objeto de proceso es un objeto de dato (a menos que el proceso inicialice el pipeline y a continuación sea una fuente de objeto de proceso). Estos objetos de datos, a su vez, se consumen por otros objetos de procesos, y así sucesivamente, de manera que se construye un gráfico de flujo de datos. Finalmente el pipeline termina por uno o más ``mappers'', que podrán escribir información a almacenar, o por una interface gráfica u otro sistema.


El beneficio significativo que se consigue con esta arquitectura es que la relativa complejidad del proceso de manejo de ejecución del pipeline está diseñada en el sistema. Esto quiere decir que el mantenimiento del pipeline al día, la ejecución en el pipeline sólo de aquellas partes que hayan cambiado, la ejecución utilizando multihilos, el manejo de la reserva de memoria y el ``streaming'' son todos construidos en la arquitectura. Sin embargo, estas características introducen complejidad al sistema. A continuación se describirá el proceso de ejecución del pipeline en detalle, centrándonos en el flujo de datos (``data streaming'').


El proceso de ejecución del pipeline realiza varias funciones importantes:
\begin{enumerate}
	\item Determina qué filtro, en un pipeline de filtros necesita ser ejecutado. Esto evita la ejecución redundante y minimiza el tiempo de ejecución global.
	\item Inicializa la salida de los objetos de datos, preparándose para nueva información. Además determina qué cantidad de memoria debe reservar cada filtro para su salida y la reserva.
	\item El proceso de ejecución determina qué cantidad de información debe procesar un filtro con el fin de producir una salida lo suficientemente grande para los filtros; también tiene en cuenta los límites de la memoria o las necesidades especiales del filtro. Otro de los factores incluye el tamaño de la información que son capaces de procesar los núcleos, que afecta a la cantidad de datos que se necesita.
	\item Subdivide la información en subpartes utilizadas para la ejecución multihilos. (Se debe tener en cuenta que la división de la información en subpartes es exactamente el mismo problema de dividir la información en partes para el ``streaming''; por tanto, la ejecución multihilos se incluye como parte de la arquitectura del  ``streaming'').
	\item Puede liberar la información de salida si los filtros no la necesitan más para calcular, y el usuario puede solicitar que la información sea liberada. (Se debe tener en cuenta que los objetos de salida de los filtros se consideran como una caché. Si a la caché se le permite permanecer entre la ejecución del pipeline y el filtro, o la entrada del filtro nunca cambia, entonces los objetos de procesos de los filtros sólo utilizarán la caché del filtro para volver a ejecutarse.)
\end{enumerate}
Para realizar estas funciones, el proceso de ejecución negocia con los filtros que definen el pipeline. Sólo cada filtro puede saber cuánta información se necesita en la entrada para generar una cierta salida. Por ejemplo, un filtro de reducción con un factor de reducción de dos necesita una imagen dos veces mayor que la entrada para generar una salida en particular. Un filtro de convolución de imágenes necesita una entrada extra dependiendo del tamaño del núcleo de convolución. Algunos filtros necesitan toda la imagen de entrada para producir la salida (por ejemplo, un histograma), y tienen la opción de solicitar toda la imagen de entrada. (En este caso el ``streaming'' no se ejecutará a menos que el desarrollador cree un filtro que sea capaz de solicitar la información en partes, tomando el estado entre cada parte y juntándolo todo al final como salida.)


En última instancia, el proceso de negociación está controlado por la solicitud de información de un cierto tamaño (por ejemplo, una región). Puede ser que el usuario solicite que se procese una región de interés dentro de la totalidad de la imagen, o que debido a las limitaciones de memoria se procese la información en varias partes. Por ejemplo, una aplicación puede calcular la memoria que necesita el pipeline y después utilizar el ``streaming'' para dividir la información a procesar en varias partes. La información solicitada se propaga a través del pipeline en dirección ascendente y el proceso de negociación configura cada filtro para producir la información de salida de un cierto tamaño.


El secreto para crear un filtro de ``streaming'' es entender cómo trabaja el proceso de negociación, y cómo anula su comportamiento por defecto utilizando las funciones virtuales apropiadas.

 
Por regla general la ejecución del pipeline se inicializa cuando un objeto de proceso recibe la invocación del método ``ProcessObject::Update()''. Este método es simplemente delegado a la salida del filtro, invocando al método ``DataObject::Update()''. Este comportamiento es normal en la interacción entre ``ProcessObject'' y ``DataObject'': un método invocado en uno es normalmente delegado en el otro. En este sentido la información solicitada por el pipeline es propagada hacia arriba, inicializando el flujo de datos que retornará.

 
El método ``DataObject::Update()''  a su vez invoca a otros tres métodos:
\begin{itemize}
	\item DataObject::UpdateOutputInformation().
	\item DataObject::PropagateRequestedRegion().
	\item DataObject::UpdateOutputData().
\end{itemize}

Una vez planteadas estas consideraciones, pasaremos a analizar más en profundidad el problema que nos concierne, el filtro ``Basic NL-Means''. En primer lugar tendremos en cuenta que al utilizar un mecanismo de programación que utiliza template se suele aplicar el convenio de utilizar dos archivos, uno ``.h'' que contendrá las cabeceras y puede que los constructores y destructores y un ``.txx'' dónde se implementarán las funciones template. 


Nuestro filtro está diseñado de manera que se ha creado una clase formada por una zona pública, otra privada y otra protegida. En cada una de ellas irán los métodos y atributos correspondientes. A continuación de comentará lo que se ha establecido en cada una de estas ``zonas'':
\begin{itemize}
	\item Zona pública $\rightarrow$ contendrá los tipos públicos de la propia clase, de la superclase que utiliza y de los punteros inteligentes constantes o no. También tendrá todas aquellas macros utilizadas para poder agregar ``parámetros'' a nuestro filtro usando el mecanismo de ``object factory'' proporcionado por Insight Toolkit.
	\item Zona protegida $\rightarrow$ el constructor por defecto irá aquí y proporcionará por defecto valores para todos los parámetros. También declararemos aquí el destructor y las funciones propias de nuestro filtro, las cuales harán uso de la opción multihilos. Por último, deberemos agregar la cabecera de la función de testeo de Insight Toolkit.
	\item Zona privada $\rightarrow$ la copia del constructor y del operador de asignación deben ser declarados como privados y no deben ser implementados para prevenir la instanciación del filtro sin los métodos de ``object factory''. Dentro de la zona privada deben figurar todos aquellos parámetros necesarios para la aplicación de nuestro filtro. Los valores de los mismos serán establecidos mediantes las macros definidas en la zona protegida de la clase.
\end{itemize}
Por último, el nombre del fichero el cual contiene la implementación del código template (fichero ``.txx'') debe ser incluido. Por tanto, lo expuesto anteriormente concierne al fichero con extensión ``.h''.


En cuanto al fichero ``.txx'' deberemos incluir aquellas funciones necesarias para el tratamiento de los datos teniendo en cuenta que usaremos multihilos. Por tanto, necesitamos dos funciones principales, una encargada de procesar los datos antes de realizar el filtro en cuestión y otra que lo ejecutará.


Debemos tener en cuenta que como utilizamos multihilos la imagen se dividirá en tantos procesadores como tengamos, por lo que la ejecución del filtro se llevará a cabo en un tiempo menor.

En la figura {\ref{fig:Pipeline} y {\ref{fig:Pipeline2} se pueden ver el flujo de ejecución y el estado del pipeline del filtro Non Local Means Básico, respectivamente.

\begin{figure}
\centering
\includegraphics[scale=0.7]{sshot-2.PNG}%ext=pdf,jpg,png
\caption{Flujo de ejecución}
\label{fig:Pipeline}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.7]{sshot-3.PNG}%ext=pdf,jpg,png
\caption{Pipeline}
\label{fig:Pipeline2}
\end{figure}

Por último se muestra en la figura {\ref{fig:itif} que este filtro hereda de la clase ImageToImageFilter, al igual que lo hace la clase LocalMeanImageFilter y TranslateImageFilter (clase implementada para un algoritmo que debido a problemas de patentes no se describirá).

\begin{figure}
\centering
\includegraphics[scale=0.7]{imagetoimagefilter.pdf}%ext=pdf,jpg,png
\caption{Herencia de ImageToImageFilter}
\label{fig:itif}
\end{figure}

Este filtro necesita como parámetros de entrada:
\begin{itemize}
\item La imagen de entrada.
\item El tamaño de la ventana de búsqueda.
\item El tamaño de la ventana patrón.
\item El valor del umbral.
\item El tipo de ruido.
\end{itemize}

En la figura {\ref{fig:nlmb} se puede ver la clase con sus atributos y métodos.

\begin{figure}
\centering
\includegraphics[scale=0.7]{basicnlmeansfilter.pdf}%ext=pdf,jpg,png
\caption{Clase Non Local Means Básica}
\label{fig:nlmb}
\end{figure}


\section{Segmentación de la carótida}
El proceso de segmentación de la carótida, tanto externa como interna, se divide en varias etapas:
\begin{itemize}
\item Selección de la región a segmentar (ROI).
\item Cálculos de probabilidad, media local.
\item Cálculo de la medida de Vesselness.
\item Cálculo de los caminos mínimos de cada carótida.
\item Cálculo de la bifurcación entre las dos carótidas.
\item Cálculo del Level Sets de cada una de las carótidas partiendo de los caminos calculados previamente.
\end{itemize}

Para empezar, se crea una región de interés (ROI) que contiene los tres puntos dados. La creación de la región de interés permite reducir el tiempo total de cómputo antes de la detección del lugar de la bifurcación. Dentro de esta región de interés, se crea una imagen de velocidad combinando los resultados de la medida de vesselness y una imagen de probabilidad basada en las estadísticas locales de intensidad de la imagen. Partiendo de la imagen de velocidad, se crea un recorrido entre la arteria carótida común y cada una de las otras dos arterías, permitiendo identificar la posición de la bifurcación y a qué arteria pertenece cada recorrido. 

Una vez visto el proceso general de la segmentación de las carótidas pasaremos a detallar cada paso y a comentar qué clases serán necesarias para su posterior implementación.

\subsection{Clase LocalMeanImageFilter}
Debido a que las regiones de interés pueden contener muchas estructuras tubulares que no necesariamente tienen porque pertenecer a las arterias carótidas principales, y ya que la respuesta de vesselness es sensible a la presencia de calcificaciones, utilizaremos una imagen adicional basada en las estadísticas locales de intensidad para crear la imagen de velocidad utilizada para calcular el recorrido de coste mínimo (BackTracking).

Se crean dos imágenes, una con la media local de la intensidad denominada $I_{lm}$ y otra con la deviación estándar local de la intensidad denominada $I_{sdm}$. Basándonos en estas dos imágenes se crea una nueva imagen denominada imagen de probabilidad utilizando la expresión siguiente:
\begin{equation}
I_p = f(I_{lm})*g(I_{sdm})
\label{eqn:prop}
\end{equation}
dónde f es una versión suavizada de una función que es igual a 1 dentro del rango de intensidades [1050, 1600] y 0 en otros lugares, y g se define como la expresión:
\begin{equation}
g(x) = e^{-\frac{x^2}{2.3^2}}
\label{eqn:prop2}
\end{equation}

Se ha visto la necesidad de crear una nueva clase que calcule la media local, debido a que en las herramientas proporcionadas por Insight Toolkit no existía una que realizase lo que se buscaba. 

A continuación, en la figura {\ref{fig:lmif} se puede ver la clase con sus principales atributos y métodos. Los únicos parámetros necesarios son la imagen de entrada y el tamaño de la ventana dónde se va a realizar la media local. A continuación se hará una media por ejes de coordenadas, es decir, primero en $x$, después en $y$ y por último en $z$ si la imagen fuese en 3D.
Como resultado obtendremos una única imagen con la media local computada.

\begin{figure}
\centering
\includegraphics[scale=0.7]{localmeanimagefilter.pdf}%ext=pdf,jpg,png
\caption{Diagrama de Clases de la clase LocalMeanImageFilter}
\label{fig:lmif}
\end{figure}

Por último, decir que esta clase hereda de la clase {\em ImageToImageFilter} como se puede ver en la figura {\ref{fig:itif}.

\subsection{Clase Vesselness}
En cuanto al cálculo de la medida de vesselness se ha hecho uso de la clases proporcionadas por Insight Toolkit. Ha sido necesario utilizar: 
\begin{itemize}
\item {\em Hessian3DToVesselnessMeasureImageFilter} $\rightarrow$ Es un filtro lineal que proporciona una medida vesselness para objetos tubulares partiendo de la matriz Hessiana. El filtro toma como entrada una imagen y mantiene aquellos píxeles que sus autovalores $\lambda_3$ estén cercanos a 0 y $\lambda_2$ y $\lambda_1$ sean valores negativos.
\begin{equation}
\lambda_1 < \lambda_2 < \lambda_3
\label{eqn:hessian}
\end{equation}
El filtro tiene en cuenta que los autovalores juegan un papel crucial en la discriminación de formas y orientación de estructuras.

Las estructuras tubulares brillantes tendrán valores pequeños de $\lambda_1$ y valores negativos en $\lambda_2$ y $\lambda_3$. Mientras que las estructuras tubulares oscuras tendrán valores bajos de $\lambda_1$ y valores positivos de $\lambda_2$ y $\lambda_3$.
\item {\em MultiScaleHessianBasedMeasureImageFilter} $\rightarrow$ Es un filtro que intensifica las estructuras utilizando un sistema Hessiano basado en medidas en un framework multiescala.

El filtro evalúa las medidas de intensificación basadas en la matriz Hessiana, como la medida vesselness, en diferentes escalas. La medida basada en la matriz Hessiana calcula en cada escala la matriz Hessiana y se selecciona la mejor respuesta.

El valor mínimo y máximo de sigma se fija utilizando los métodos {\em SetMinSigma} y {\em SetMaxSigma}. Mientras que el número de escalas vendrá determinado por el método {\em SetNumberOfSigmaSteps}. Con estos valores se calculará de manera exponencial las diferentes escalas partiendo del valor mínimo de sigma y llegando al máximo.
\item {\em HessianObjectnessMeasureImageFilter} $\rightarrow$ Es un filtro que intensifica objetos en imágenes de cualquier dimensión. Este filtro se ha utilizado para hacer el cálculo de la medida de vesselness en imágenes 2D.
La medida de objectness es una generalización de la medida de vesselness de Frangi, la cuál está basada en el análisis del sistema de autovalores y autovectores de la matriz Hessiana. Este filtro es capaz de intensificar casi cualquier tipo de estructura.
\end{itemize}

\subsection{Clase BackTracking}
Se extraen dos recorridos, uno entre la arteria carotida cómun y la arteria carótida externa y otro entre la arteria carotida común y la arteria carótida interna, intentando maximizar la probabilidad de estar dentro y en el centro del vaso buscado.

Los recorridos son creados utilizando el método de BackTracking, partiendo de el resultado del filtro Fast Marching.

Una vez ambos recorridos han sido detectados, el punto de bifurcación se define como el punto dónde la distancia entre los dos recorridos llega a ser mayor de 1mm, empezando en su extremo común en la arteria carótida común. En el punto de bifurcación, el recorrido con mayor valor en el eje de las Y se selecciona como recorrido de la arteria carótida interna, y el otro recorrido se selecciona como arteria carótida externa. 
Una vez que la bifurcación y ambos recorridos han sido detectados e identificados, el recorrido será cortado o extendido dependiendo de su actual distancia a la bifurcación o de si cumple los requisitos de longitud. La extensión de los recorridos se obtiene mediante la ejecución de un algoritmo de recorrido de coste mínimo.

Para el cálculo de los caminos mínimos entre dos puntos dados se hace necesario la creación de una clase que lo realice ya que en Insight Toolkit no está esta funcionalidad.

Este filtro crea un camino empezando en un punto y siguiendo los desplazamientos dados por el vector de la imagen de entrada ({\em the input vector field image}). Si la entrada es escalar se calcula el correspondiente vector a partir de su gradiente por interpolación lineal. El seguimiento del camino se para por alguno de estos motivos:
\begin{itemize}
\item Se ha alcanzado la distancia máxima.
\item Los valores cercanos a la posición actual tienen intensidad negativa.
\item El gradiente actual es muy pequeño.
\end{itemize}

Se ha partido de la implementación realizada en AMILab para adaptarla y convertirla en un filtro de Insight Toolkit. Este nuevo filtro será del tipo ImageToMeshFilter. En la figura {\ref{fig:btmf} podemos ver la nueva clase con sus atributos y métodos. Mientras que en la figura {\ref{fig:btmf2} se muestra la clase de la cuál la nueva clase heredará sus atributos y métodos.

\begin{figure}
\centering
\includegraphics[scale=0.7]{backtrackingmeshfilter.pdf}%ext=pdf,jpg,png
\caption{Diagrama de Clases de la clase BackTrackingMeshFilter}
\label{fig:btmf}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.7]{ImageToMeshFilter.pdf}%ext=pdf,jpg,png
\caption{Diagrama de Clases ImageToMeshFilter}
\label{fig:btmf2}
\end{figure}

La clase BackTracking necesita una serie de parámetros:
\begin{itemize}
\item La imagen de entrada que provendrá de la salida del filtro Fast Marching. Para poder hacer mejor los cálculos entre los diferentes pasos hasta llegar a la solución final conviene que la imagen de entrada sea de tipo {\em double}.
\item Las coordenadas del punto dónde va a comenzar el camino.
\item El intervalo de tiempo utilizado para la evolución.
\item La distancia máxima euclídea del camino.
\item Un valor delta que es un incremento pequeño utilizado para estimar las derivadas basadas en interpolación lineal.
\end{itemize}

La salida de este filtro será una malla que representa el camino obtenido.

\subsection{Clase Level Sets}
Para la segmentación de las carótidas se utiliza en última instancia la clase Level Sets que creará la segmentación final partiendo de unos finos tubos iniciales creados alrededor de los caminos obtenidos en la fase de BackTracking.

En este caso se ha hecho uso de la clase {\em GeodesicActiveContourLevelSetImageFilter} que proporciona una segmentación similar a la deseada.

Este filtro segmenta estructuras en imágenes basándose en una imagen proporcionada por el usuario que es un mapa de bordes. Un contorno inicial se propoga hacia el exterior o hacia el interior hasta que pega los límites de la forma. Esto es posible gracias a una función de velocidad basada en un mapa de bordes proporcionado por el usuario.

El filtro necesita dos entradas. La primera entrada es un Level Set inicial. El Level Set inicial es una imagen real que contiene el contorno o superficie inicial. El contorno inicial no tiene porque estar totalmente dentro de la forma a segmentar. El término de advección atrae el contorno hasta el límite de la forma a segmentar.
La segunda entrada es una imagen de características, para este filtro es el mapa de bordes. Una de las características generales del mapa de bordes es que tiene valores cercanos a cero en las regiones próximas a los bordes y valores cercanos a uno dentro de la propia forma. Normalmente, el mapa de bordes se calcula utilizando el gradiente, por ejemplo:

\begin{equation}
g(I) = 1 / ( 1 + | (\nabla * G)(I)| )
\label{eqn:gradiente}
\end{equation}
\begin{equation}
g(I) = \exp^{-|(\nabla * G)(I)|}
\label{eqn:gradiente2}
\end{equation}

donde $I$ es la intensidad de la imagen y $(\nabla * G)$ es la derivada del operador gaussiano.

Como resto de parámetros tenemos la escala de propagación que se puede utilizar para cambiar el tipo de propagación, si es positiva será una propagación hacia el exterior mientras que si es negativa será hacia el interior. Además también tenemos los términos curvatura y advección. El término de curvatura se utiliza para suavizar el resultado de los contornos. Mientras que el término de advección sirve para atraer el contorno hasta el límite de la forma.

El resultado del filtro será una imagen escalar y de valores reales. Los valores negativos en la imagen de salida representan el interior de la región segmentada y valores positivos en la imagen representan la parte exterior de la región segmentada.

\chapter{Implementación}
\section{Filtro Non Local Means Básico con iteradores de vecindades}
El algoritmo Non Local Means, como ya se ha explicado anteriormente, es un filtro que facilita la eliminación de ruido de una imagen. Partiendo de la base de que dicho método se puede implementar de múltiples maneras, aquí hemos optado por la forma básica, la más lenta. En un futuro se pretende realizar las implementaciones más rápidas para comprobar si ITK favorece su rapidez o todo lo contrario.

Para ayudarnos a implementar el método Non Local Means nos hemos ayudado de un filtro propio de ITK que calcula la media local. Hemos seleccionado esta implementación debido a que hace uso de los iterados de vecindades, gran utilidad, que en principio nos será de gran ayuda.

Debido al diseño implícito de ITK, nuestro filtro constará con dos métodos que se ejecutarán en base a los procesadores y por consiguiente hilos que se lancen. 

Tenemos un primer método que se ejecutará antes del método principal, es el encargado de crear un vector que contendrá una serie de pesos ponderados para después ser utilizados en la reducción de ruido de la imagen. Estos pesos serán creados partiendo básicamente del tamaño de la ventana patrón, f.

El segundo método a ejecutar es el encargado de aplicar el filtro en cuestión, se basa en el hecho del uso de múltiples hilos para su aplicación. En base al número de procesadores se lanzará dicho método por cada procesador, procesando la imagen en secciones y de manera más rápida. El método implementa el algoritmo de Non Local Means, explicado anteriormente, teniendo en cuenta que tendremos varias regiones de la imagen sobre las que iremos trabajando.

Gracias a los iteradores de vecindades podemos controlar que los mismos no se salgan de los límites de la imagen establecidos. ITK tiene la opción de activar la comprobación de bordes o no en sus iteradores de vecindades, de esta forma permite que se realice un trabajo más eficiente y evita que se hagan comprobaciones innecesarias. Para reducir estas comprobaciones hemos implementado el método de forma que la ventana de búsqueda, t, sea calculada aparte, por lo que para ella no haremos uso de los iteradores de vecindades.

Otro detalle a tener en cuenta es el uso de ``caras'', esto permite que una región se divida en varias pequeñas regiones, haciendo distinción entre las que tocan el borde y las que no. Esto permite que para aquellas zonas que no sea necesario comprobación de bordes no se realice.

Uno de los problemas que se plantea y que perjudica al tiempo de ejecución del algoritmo es el uso del método GetPixel, ya que la utilización del mismo, como bien se plantea en ITK, hace que se tarde más en acceder al valor de ese pixel en concreto. La filosofía de ITK busca la utilización de otras herramientas que pone a disposición de los usuarios, el problema en este caso es que al utilizar los iteradores de vecindades nos vemos obligados a utilizar este método.

Por último, cabe destacar que los dos métodos implementados son de tipo template, permitiendo que la reducción de ruido se aplique sobre cualquier tipo de imagen. La única restricción es que se haga sobre una imagen 2D o 3D.

\section{Nuevas funcionalidades de AMILab}
El primer detalle a tener en cuenta es que hemos cambiado la organización de las funciones implementadas utilizando ITK, hemos pasado de tener todo en un solo archivo a tenerlo en archivos separados. Ahora por cada función nueva se crea un nuevo archivo que formará parte del conjunto WrapITK en el cuál se engloban todas aquellas funciones que AMILAB utiliza y que se implementan usando librerías ITK.

Se parte del fichero ``wrapITK.cpp'' en el que se declara un procedimiento propio de AMILAB que sirve para añadir nuevas variables al programa. Gracias a este procedimiento podemos incluir, siempre que queramos, funcionalidades implementadas en ITK. Esto se hará mediante el procedimiento {\em ADDOBJECTVAR\_NAME} al que se le pasa el tipo de la funcionalidad a añadir:
\begin{itemize}
	\item C\_wrap\_procedure
	\item C\_wrap\_imagefunction
	\item C\_wrap\_varfunction
\end{itemize}
A continuación se especifica el nombre de la funcionalidad a incluir, que será el que usemos a la hora de invocarla. Y por último el nombre del procedimiento o función que implementa la nueva funcionalidad. Gracias a estos sencillos pasos hemos logrado incluir nuestra nueva función en AMILAB.

Cada nueva funcionalidad será implementada en un fichero a parte permitiendo de esta forma un mayor entendimiento del código, acceso al mismo (posibles modificaciones) y facilidad de uso.

Un paso importante que se ha dado es la creación de dos funciones de tipo template encargadas de transformar una imagen ITK en el tipo de imagen propio de AMILAB (InrImage) y viceversa. De esta forma cuando se invoca una funcionalidad desde AMILAB se le pasará una imagen del tipo InrImage que deberá ser transformada en el formato de ITK, para una vez aplicado el filtro o el tratamiento a esta imagen reconvertirla en el formato InrImage pudiéndola utilizar por AMILAB.

Gracias a esta pequeña modificación en el código logramos que no exista código repetido, lo que provoca implementaciones poco legibles y pesadas de entender.

Las dos funciones de tipo template implementadas están englobadas en el archivo wrapConversion.tpp. El hecho de que sean de tipo template nos permite que sean utilizadas con cualquier tipo de imagen que se necesite,tanto en 2D como en 3D.

Para todas las nuevas funcionalidades, se deben recoger los parámetros de entrada de alguna manera para después poder ejecutarlas. Esto se hace mediante una serie de funciones, a continuación se mostrarán las más relevantes y utilizadas en el desarrollo del proyecto:

\begin{itemize}
\item get\_val\_ptr\_param$<$string$>$ $\rightarrow$ función utilizada para analizar una variable de tipo string en una lista de parámetros y devolver un puntero a su valor.
\item get\_val\_ptr\_param$<$InrImage$>$ $\rightarrow$ función utilizada para analizar una variable de tipo InrImage (tipo de imagen propia de AMILab) en una lista de parámetros y devolver un puntero a su valor.
\item get\_val\_param$<$float$>$ $\rightarrow$ función utilizada para analizar una variable de tipo float en una lista de parámetros y devolver su valor.
\item get\_int\_param $\rightarrow$ función utilizada para analizar un entero en una lista de parámetros.
\end{itemize}

Gracias a estas funciones se recorrerá la lista de parámetros y se irán cogiendo uno a uno para su posterior uso.

El tipo de datos utilizado en cada nueva funcionalidad, a no ser que se especifique lo contrario, será de tipo float. Esto es así debido a los cálculos que se realizan en cada filtro.

A continuación se citarán las diferentes funcionalidades agregadas a AMILab, aunque no se utilicen directamente para el desarrollo final del proyecto han ayudado a la comprensión y estudio de ITK, es por eso que son nombradas en este apartado.

\subsection{wrapITKWrite}
Esta nueva funcionalidad permite guardar imágenes, para posteriormente poder utilizarlas en otros filtros, por ejemplo. Los parámetros de entrada serán una imagen en 2D o 3D, de tipo:
\begin{itemize}
	\item Unsigned\_char
	\item Unsigned\_short
	\item Signed\_short
	\item Unsigned\_int
	\item Signed\_int
	\item Unsigned\_long
	\item Float
	\item Double
\end{itemize}
y la ruta dónde queremos que se guarde la imagen.

El mecanismo mediante el cual se guarda la imagen viene dado por la creación de la clase itkWriteClass en la que se hace uso de la clase itkImageFileWriter  proporcionada por ITK. Esta clase permite guardar una imagen, tan sólo se le debe pasar por parámetro la ruta dónde se va a guardar la imagen y la imagen a guardar.

Por tanto, la nueva funcionalidad implementada toma una imagen y la guarda en la ruta indicada.

\subsection{wrapITKBackTrackingMeshFilter}
Para esta nueva funcionalidad ha sido necesario, como ya se ha comentado anteriormente, crear una nueva clase en ITK. La nueva clase creada es {\em BackTrackingImageFilter}, que viene definida por dos archivos, el ``.h'' y el ``.txx''. Dentro del fichero ``itkBackTrackingMeshFilter.h'' encontramos la declaración de los métodos y atributos necesarios mientras que en el fichero ``itkBackTrackingMeshFilter.txx'' se implementa la nueva clase. El algoritmo principal está centrado en el método {\em GenerateData} dentro del cuál se realizan todas las operaciones necesarias. 

Para poder ir creando el camino a lo largo del vaso se ha hecho uso de algunas clases proporcionadas por ITK, como son

\begin{itemize}
\item itkLinearInterpolateImageFunction $\rightarrow$ necesaria para el cálculo del gradiente que asegura que la evolución del camino va a través de valores de intensidades bajas.
\item itkMesh $\rightarrow$ esta clase proporciona la ayuda necesaria para poder utilizar mallas. Gracias a esto, se puede ir creando el camino y guardarlo como una malla. Para poder guardarlo como tal es necesario partir de un nivel inferior, en este caso sería una línea formada por puntos. Estos se irán agregando a la línea a medida que se avanza en la evolución.
\item itkLineCell $\rightarrow$ nos permitirá ir añadiendo puntos a la línea final que será el camino buscado.
\end{itemize}

Una vez tenemos la clase, podemos incluirla en el fichero encargado de instanciarla, en este caso en el fichero ``wrapitkBackTrackingMeshFilter.cpp''.

Un detalle a tener en cuenta es que una vez obtenido el camino entre dos puntos dados vendrá devuelto como una malla de ITK. Para poder utilizarla en AMILab se debe convertir a un tipo que sea legible, en este caso {\em SurfacePoly}. Esta superficie será rellenada con los puntos de la malla, de esta manera se podrá utilizar desde AMILab.

\subsection{wrapITKBasicNLMeansFilter}
En esta funcionalidad se ha hecho necesario la creación de una nueva clase. Esta clase es ``Non Local Means Básica'', formada por ``itkBasicNLMeansFilter.h'' y ``itkBasicNLMeansFilter.txx''. Al igual que con otras clases está también posee sus atributos y métodos propios. Se han utilizado dos métodos principales para su implementación, ``BeforeThreadedGenerateData()'' y ``ThreadedGenerateData''. El primero se encarga de realiza una serie de cálculos previos al algoritmo principal. Mientras que el segundo ejecuta el método de reducción de ruido basado en vecindades.

Un detalle a tener en cuenta en esta clase es que se ha hecho uso de la tecnología multihilos que proporciona ITK, permitiendo aprovechar todos los procesadores del ordenador utilizado.

Debido a la complejidad de la arquitectura de ITK, no se ha logrado una implementación eficiente y rápida, impidiendo que esta clase sea viable de utilizar, sobretodo en imágenes 3D. El principal problema es el tipo de iterador empleado, el iterador de vecindades provoca que se realicen muchas comprobaciones que verifican que se está dentro de los límites permitidos.

El archivo dónde se instancia esta clase es ``wrapitkBasicNLMeansFilter.cpp'', en el que se recogen los parámetros necesarios y se hace la llamada al filtro para que se ejecute.

\subsection{wrapITKBinaryThresholdImageFilter}
Para esta funcionalidad basta con utilizar la clase proporcionada por ITK que consta de ``itkBinaryThresholdImageFilter.h'' y ``itkBinaryThresholdImageFilter.txx''. Esta funcionalidad en concreto no ha sido implementada para el desarrollo final del proyecto pero ha ayudado a la evolución del mismo. 

\subsection{wrapITKDICOMRead}
El permitir la lectura de imágenes en formato DICOM es una funcionalidad importante que se ha añadido a AMILab, es un detalle que poseen muchos otros programas de tratamiento de imágenes médicas, ya que este formato es muy utilizado en esta disciplina.

Debido a que en el tratamiento de imágenes médicas se utiliza un número ``reducido'' de tipos de imágenes y dimensiones se ha tomado la decisión de soportar imágenes en 2D y 3D con los siguientes tipos de datos:

\begin{itemize}
\item {\em unsigned char}
\item {\em unsigned short}
\item {\em signed short}
\end{itemize}

Esta funcionalidad utiliza las herramientas disponibles en ITK para la lectura y escritura de imágenes de tipo DICOM.

\subsection{wrapITKFastMarchingImageFilter}
Para realizar el filtro Fast Marching se ha usado la clase proporcionada por ITK que se compone de los ficheros ``itkFastMarchingImageFilter.h'' y ``itkFastMarchingImageFilter.txx''.

La nueva funcionalidad se podrá encontrar en ``wrapitkFastMarchingImageFilter.cpp''.

\subsection{wrapITKLevelSet}
ITK proporciona una serie de clases que permiten la segmentación utilizando Level Sets. En nuestro caso, la clase que utilizaremos será la formada por los ficheros ``itkGeodesicActiveContourLevelSetImageFilter.h'' y ``itkGeodesicActiveContourLevelSetImageFilter.txx''

\subsection{wrapITKMultiScaleVesselnessFilter}
En el caso del cálculo de medida de Vesselness se ha hecho uso de los ficheros proporcionados por la publicación \cite{Vesselness}, debido a que en su momento ITK no proporcionaba esta funcionalidad.

\subsection{wrapITKRecursiveGaussianImageFilter}
Esta funcionalidad viene proporcionada por ITK y la clase se compone de los ficheros ``itkRecursiveGaussianImageFilter.h'' y ``itkRecursiveGaussianImageFilter.txx''. 

\subsection{wrapitkLocalMeanImageFilter}
Aunque ITK proporciona esta funcionalidad se ha decidido implementarla de nuevo porque se necesitaba velocidad, cosa que en ITK no se conseguía. La nueva clase se compone, como el resto, de dos ficheros que son ``itkLocalMeanImageFilter.h'' y ``itkLocalMeanImageFilter.txx''


\section{Script Proceso Completo}
Esta sección se intentará hacer un recorrido por todas las diferentes etapas que se siguen para el desarrollo del proceso completo de segmentación de carótidas.

Lo primero y más importante es destacar que el proceso completo está implementado mediante scripts que corren sobre AMILab, es por esto que el método está distribuido en varios scripts. Cada script que se utiliza es una clase en el lenguaje interpretado, pero que a efectos de programación y diseño es muy similar a una clase implementada en un lenguaje de alto nivel.

Se debe tener en cuenta que existen diferentes scripts para desarrollar el proceso completo de segmentación de carótidas. Cada uno de ellos es una clase en lenguaje interpretado que tiene sus propios métodos y atributos. Uno de estos métodos, común a muchas de las clases utilizadas, será el que se encargue de tomar una imagen e introducirla en la clase.

A continuación se detallarán las diferentes etapas. En las siguientes secciones se hablará de clases haciendo referencia a las creadas en los scripts mediante lenguaje interpretado, por tanto, se hace mención a un script diferente al script del proceso global.

\subsection{Preprocesado}
En primer lugar se debe configurar el script que contiene las rutas de los datos, tanto imágenes como software de evaluación del método. Este fichero se encuentra en la misma ruta que se encuentra el script del proceso global. Es una clase, que contiene los siguientes atributos:
\begin{itemize}
\item {\em ::data\_dir} $\rightarrow$ Especifica la ruta dónde están las imágenes de entrada, tanto las de Training como las de Testing.
\item {\em ::groundtruth\_dir} $\rightarrow$ Indica la ruta dónde podemos encontrar el ``groundtruth'' (resultados originales de la segmentación) de aquellas imágenes tipo Training.
\item {\em ::results\_dir} $\rightarrow$ Indica la ruta dónde se irán almacenando los resultados del proceso de segmentación. Aquí, no sólo se guardará el resultado final, sino que también se incluirán aquellos obtenidos en los pasos intermedios del proceso.
\item {\em ::evaluation\_bindir} y {\em ::evaluation\_scriptdir} $\rightarrow$ Indican las rutas dónde se encuentran los programas que validan el método y lo evalúan.
\end{itemize}

Una vez hecha esta primera etapa, ya se puede ejecutar el script del proceso completo. 

Lo primero que se hace en el script es leer la imagen, leer los tres puntos proporcionados por el usuario para la segmentación y después se recorta. Existen zonas de esta que no nos interesan ni serán relevantes para la segmentación de las carótidas, por eso se eliminan. De esta forma el tiempo de procesamiento será menor, ya que las imágenes médicas en 3D (TAC) ocupan bastante espacio.

La lectura de los tres puntos iniciales se realiza mediantes la clase ``ReadPointsClass'', en concreto utilizando el método ``ReadPoints''. Después, para realizar el corte de la imagen se utiliza la clase ``CropImageFromPointsClass'', en concreto el método ``CropImageFromPoints'' \ref{fig:scriptRE} obteniendo una región de interés (ROI).

A continuación se lee el groundtruth, sólo en el caso de las imágenes de Training ya que las imágenes de Testing no poseen groundtruth. Sino se quiere no hace falta leer estos datos ya que no se utilizan para los cálculos que se realizan.

\subsection{Local Stats}
Una vez tenemos todos los datos de entrada pasaremos a realizar el algoritmo en cuestión de segmentación de carótidas. En primer lugar se hará un cálculo de la media local de la imagen. El resultado obtenido se utilizará posteriormente junto con el resultado de la medida de Vesselness para obtener la imagen de velocidad que será la entrada del proceso de {\em BackTracking}.

En este caso la principal clase utilizada será ``itkCreateProbabilityClass'', que como su nombre indica realiza la media local usando la nueva funcionalidad implementada en ITK \ref{fig:scriptRE}, ``itkLocalMeanImageFilter''.

\subsection{Vesselness}
El cálculo de la medida de vesselness se realiza partiendo de la imagen de entrada recortada (ROI). Para ello se utiliza la clase ``itkVesselnessClass'' \ref{fig:scriptRE}. En este caso, necesitamos que la clase tenga la imagen a procesar, esto lo haremos mediante el método ``set\_input(IMAGE im)''. El método encargado de realizar el cálculo es ``Run'' que llamará a la funcionalidad ``itkMultiScaleVesselnessFilter'', implementada en ITK.

\subsection{BackTracking}
En el cálculo de los caminos, se realiza primero el de la arteria interna y después el de la arteria externa. Para ambos, el método es el mismo.
Lo primero que se debe hacer es fijar las esferas iniciales que serán los tres puntos dados por el usuario. Esto se hace mediante la clase ``CreateInitialSpheresClass'' en concreto con el método ``CheckInitialPoints'', este a su vez hace uso de la clase ``AddSphereClass'' y del método ``AddBrightSphereGlobal\_mm''. Después se comprobarán una serie de medidas en estos puntos, las cuales servirán para determinar si los tres puntos dados son válidos y asi poder continuar con el proceso de BackTraking.

A continuación, partiendo del resultado de Local Stats y de la media de vesselness, se obtiene la imagen que daremos como entrada al proceso de BackTracking. La clase que lo implementa es ``itkSPClass'' \ref{fig:scriptRE}, tomando como entrada la imagen de la región de interés y la imagen calculada previamente. Ambas, serán pasadas a la clase mediante los métodos ``set\_input(IMAGE im)'' y ``set\_speed(IMAGE im)'' respectivamente. También es necesario indicarle a la clase los tres puntos que indican el comienzo y los finales de las arterias. Esto se hará mediante los métodos ``SetStartPointWorld'' y ``SetEndPointWorld'' respectivamente.

Ahora se puede pasar al cálculo de los caminos. Basta con utilizar el método ``Run''.

\subsection{Bifurcación}
Se realiza el cálculo de la bifurcación entre las dos arterias, interna y externa. Por último se comprueba si la longitud de los caminos es la adecuada, en caso contrario se hace crecer de nuevo el camino.

\subsection{Level Sets}
La última etapa es la segmentación de las arterias utilizando Level Sets. Al igual que en la etapa del cálculo de los caminos, primero se realizará una arteria y después la otra, siendo el proceso exactamente el mismo. Para ello utilizaremos la clase ``itkLevelSetClass'' \ref{fig:scriptRE}. Partiremos de un cilindro formado alrededor del camino calculado previamente, esto hará que la segmentación sea más controlada y precisa.

Como métodos principales existen ``set\_initial'' y ``set\_edge'' que definirán las imágenes de entrada y por último el método encargado de ejecutar el proceso, en este caso ``Run''. ``Run'' hará uso de la funcionalidad implementada en ITK para la segmentación mediante Level Sets.

\subsection{Resultado Final}
El resultado final vendrá dado por la unión de la segmentación de la arteria interna y de la arteria externa.


En la figura {\ref{fig:scriptRE} podemos ver el diagrama de clases que representa todas las clases necesarias para la segmentación de carótidas. Por otro lado, en la figura {\ref{fig:peRE} se muestra el proceso de ejecución que se sigue para llegar al resultado.
\begin{figure}
\centering
\includegraphics[scale=0.7]{scriptRE.pdf}%ext=pdf,jpg,png
\caption{Diagrama de Clases Script RunExperiments}
\label{fig:scriptRE}
\end{figure}

\begin{landscape}
\newpage
%\thispagestyle{empty}
\begin{figure}
\centering
\includegraphics[scale=0.7]{pescript.pdf}%ext=pdf,jpg,png
\caption{Proceso de Ejecución Script RunExperiments}
\label{fig:peRE}
\end{figure}
\end{landscape}

\chapter{Resultados y conclusiones}
\section{Resultados}
Para la etapa de validación y obtención de resultados se ha decidido realizar una batería de pruebas con 15 datos reales de pacientes. Se parte de los datos en cuestión y del resultado ideal (referencia) que se debería obtener. Con esta información se realiza un test de evaluación y cuantificación de los datos. Las medidas usadas para validar la calidad de los resultados han sido las mismas utilizadas durante el Challengue MICCAI'09. A continuación se detallarán cuáles son:
\begin{enumerate}
\item El índice de similitud ``Dice´s coefficient'' $D_{si}$:
\begin{equation}
D_{si} = \frac{2*|pv_r \cap pv_p|}{|pv_r| + |pv_p|}
\label{eqn:dsi}
\end{equation}
donde $pv_r$ y $pv_p$ es el volumen de referencia y el obtenido por el usuario respectivamente. La operación de intersección es la operación mínima de voxelwise.

\item La media de la distancia de la superficie $D_{msd}$:
\begin{equation}
D_{msd} = \frac{1}{2}*\left( \frac{\int_{S_r} |sdm_p|ds}{|S_r|}+\frac{\int_{S_p} |sdm_r|ds}{|S_p|}\right)
\label{eqn:dmsd}
\end{equation}
donde $sdm_r$ y $sdm_p$ son los mapas de distancia de las segmentaciones de referencia y del usuario respectivamente. $S_r$ y $S_p$ son las superficies límite de los vasos (las isosuperficies de los mapas de distancia en el valor 0), y $|S_i|$ es el área de la superficie $S_i$, por ejemplo $|S_i| = \int_{S_i}ds$.

\item La media de la raíz cuadrada de la distancia de la superficie $D_{rmssd}$:
\begin{equation}
D_{rmssd} = \frac{1}{2}*\left(\sqrt{\frac{\int_{S_r}sdm_p^2ds}{|S_r|}}+\sqrt{\frac{\int_{S_p}sdm_r^2ds}{|S_p|}}\right)
\label{eqn:drmssd}
\end{equation}

\item Máxima distancia en la superficie $D_{max}$:
\begin{equation}
D_{\max} = \frac{1}{2}*\left(\max \limits_{x\in S_r}|sdm_p(x)| + \max \limits_{x\in S_p}|sdm_r(x)| \right)
\label{eqn:dmax}
\end{equation}
\end{enumerate}

Una vez conocemos las medidas a utilizar podemos hacer una comparación entre el método base y el método ITK. A continuación se muestran dos tablas \ref{tresultados} y \ref{tresultadosITK} con los datos correspondientes a los 15 pacientes. Se ha considerado útil incluir el tiempo de ejecución del método para cada dato.

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline \textbf{DataSet} & \textbf{$D_{si} \%$ } & \textbf{$D_{msd}$ mm} & \textbf{$D_{rmssd}$ mm} & \textbf{$D_{max}$ mm} & \textbf{Tiempo} \\ 
\hline \textbf{000} & 0.95 & 0.14 & 0.28 & 2.24  & 15min20seg\\ 
\hline \textbf{001} & 0.93 & 0.17 & 0.22 & 0.94  & 20min59seg\\ 
\hline \textbf{002} & 0.95 & 0.97 & 0.13 & 1.05  & 13min8seg\\ 
\hline \textbf{003} & 0.9  & 0.25 & 0.39 & 2.18  & 21min29seg\\ 
\hline \textbf{004} & 0.9  & 0.28 & 0.47 & 2.42  & 11min12seg\\ 
\hline \textbf{005} & 0.93 & 0.16 & 0.2  & 1.33  & 19min2seg\\ 
\hline \textbf{006} & 0.76 & 1.6  & 3.46 & 11.73 & 13min31seg\\ 
\hline \textbf{007} & 0.94 & 0.15 & 0.26 & 2.24  & 20min46seg\\ 
\hline \textbf{008} & 0.94 & 0.18 & 0.24 & 1.1   & 19min58seg\\ 
\hline \textbf{100} & 0.89 & 0.31 & 0.44 & 2.39  & 3min34seg\\ 
\hline \textbf{101} & 0.92 & 0.17 & 0.26 & 1.46  & 2min43seg\\ 
\hline \textbf{102} & 0.89 & 0.4  & 0.96 & 5.4   & 5min50seg\\ 
\hline \textbf{200} & 0.82 & 1.96 & 4.06 & 14.76 & 2min52seg\\ 
\hline \textbf{201} & 0.29 & 2.89 & 4.07 & 10.1  & 9min32seg\\ 
\hline \textbf{202} & 0.92 & 0.2  & 0.28 & 1.02  & 4min40seg\\ 
\hline 
\end{tabular}
\caption{Resultados Método Base}
\label{tresultados}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline \textbf{DataSet} & \textbf{$D_{si} \%$ } & \textbf{$D_{msd}$ mm} & \textbf{$D_{rmssd}$ mm} & \textbf{$D_{max}$ mm} & \textbf{Tiempo} \\ 
\hline \textbf{000} & 0.67 & 0.8  & 0.86 & 1.56  & 11min46seg\\ 
\hline \textbf{001} & 0.74 & 0.63 & 0.77 & 1.64  & 15min13seg\\ 
\hline \textbf{002} & 0.72 & 0.57 & 0.64 & 1.39  & 9min9seg\\ 
\hline \textbf{003} & 0.74 & 0.61 & 0.72 & 1.64  & 15min26seg\\ 
\hline \textbf{004} & 0.74 & 0.67 & 0.94 & 2.51  & 8min38seg\\ 
\hline \textbf{005} & 0.77 & 0.55 & 0.68 & 1.75  & 14min15seg\\ 
\hline \textbf{006} & 0.73 & 0.59 & 0.67 & 1.68  & 10min1seg\\ 
\hline \textbf{007} & 0.72 & 0.63 & 0.73 & 1.68  & 15min26seg\\ 
\hline \textbf{008} & 0.72 & 0.77 & 1.14 & 3     & 15min53seg\\ 
\hline \textbf{100} & 0.81 & 0.56 & 0.66 & 1.54  & 3min24seg\\ 
\hline \textbf{101} & 0.89 & 0.26 & 0.39 & 1.68  & 2min24seg\\ 
\hline \textbf{102} & 0.49 & 1.83 & 3    & 10.39 & 5min2seg\\ 
\hline \textbf{200} & 0.75 & 0.66 & 0.7  & 1.03  & 1min45sg\\ 
\hline \textbf{201} & 0.32 & 3.78 & 5.41 & 14.01 & 3min55seg\\ 
\hline \textbf{202} & 0.13 & 5.07 & 5.44 & 4.79  & 3min25seg\\ 
\hline 
\end{tabular}
\caption{Resultados Método ITK}
\label{tresultadosITK}
\end{table}

Para apreciar mejor los resultados obtenidos se han realizado una serie de gráficas que comparan el método base con el método ITK \ref{fig:graf1}, \ref{fig:graf2}, \ref{fig:graf3} y \ref{fig:graf4}.

Por último, en el ``apéndice A'' podemos encontrar una comparativa gráfica entre los resultados del método base y los de ITK.

\begin{figure}
\centering
\includegraphics[scale=0.7]{Libro1.pdf}%ext=pdf,jpg,png
\caption{$D_{si}$}
\label{fig:graf1}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.7]{Libro2.pdf}%ext=pdf,jpg,png
\caption{$D_{msd}$}
\label{fig:graf2}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.7]{Libro3.pdf}%ext=pdf,jpg,png
\caption{$D_{max}$}
\label{fig:graf3}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.7]{Libro4.pdf}%ext=pdf,jpg,png
\caption{Tiempo}
\label{fig:graf4}
\end{figure}

\section{Conclusiones}
En este apartado intentaré dar una visión global del estado final del proyecto, de mis opiniones y de los resultados obtenidos. Comenzaré por comentar el estado de los objetivos planteados, si se han conseguido alcanzar o no. Continuaré con una visión general de mi opinión acerca del proyecto y terminaré haciendo un repaso por los resultados obtenidos haciendo hincapié en aquellos más representativos o problemáticos.

Los objetivos planteados para este proyecto han sido alcanzados en mayor o menor medida, y a continuación explicaré porqué. Se planteaba la adaptación de la totalidad o parte del método de segmentación de vasos coronarios, esto se ha realizado con éxito, aunque teniendo en cuenta unos pequeños detalles. Para la realización del método completo ha sido necesario implementar nuevas clases y utilizar otras existentes en ITK.

Debido a la especialización del método no ha sido posible adaptarlo totalmente, es decir, el método base está realizado específicamente para la segmentación de carótidas, mientras que el método ITK parte de filtros genéricos no diseñados para este fin.

Por otro lado, se buscaba incluir las nuevas funcionalidades en el software de tratamiento de imágenes AMILab. Esto ha sido posible gracias a la gran versatilidad disponible a la hora de añadir nuevos filtros o métodos. Se ha conseguido, por otra parte, reestructurar la organización interna de los filtros, ayudando a su mayor compresión, modificación y localización.

Por último, en cuanto al entendimiento de los métodos a utilizar se ha hecho un estudio de los mismos, logrando una comprensión de su funcionamiento. Permitiendo de esta manera la implementación de las nuevas funcionalidades. Sin este paso, decisivo, no hubiese sido posible la realización del proyecto, ya que es una parte muy importante del mismo.

A continuación, me gustaría comentar una serie de aspectos, algunos han sido de ayuda y otros han complicado más el proceso de aprendizaje. 

En primer lugar, hay que destacar que este proyecto parte de uno ya existente por lo que es evidente que ha sido de gran ayuda el comenzar de una base. Por otro lado, a veces se hace tedioso comprender el código ajeno, pero mi tutor siempre ha estado ahí para aclarar y explicar cualquier duda que pudiese surgir.
Otro detalle qué destacaría, es que siempre es bueno que un software, de la envergadura de AMILab, tenga varios desarrolladores y no se centre sólo en uno. De esta manera, existen más personas capaces de darse cuenta o ver las cosas de otra forma. Gracias a esto, AMILab, bajo mi punto de vista, ha mejorado bastante en cuanto a estabilidad bajo el S.O. Windows. Al comienzo de este proyecto, AMILab no era del todo operativo sobre Windows y era complicado trabajar con él, pero a día de hoy, salvo por ciertos problemas funciona perfectamente.

En cuanto al trabajo realizado con las librerías ITK me gustaría comentar que al principio resultó complicado adaptarse a ellas porque están basadas en el uso de templates y yo durante la carrera no los había utilizado demasiado. Una vez que uno se adapta es relativamente sencillo usarlas. También quería destacar que debido a la complejidad que existe detrás de las librerías ITK es difícil comprender todo el funcionamiento de las mismas y dominarlas por completo, para ello haría falta un estudio más profundo y más tiempo. Por último, muchas veces el trabajo se ha alargado debido a que se intentaba hacer que una funcionalidad se ejecutase más rápido, esto es complicado ya que, como comentaba antes, existen muchos detalles a tener en cuenta y el desconocimiento de los mismos provoca que no se consigan los resultados esperados o la velocidad deseada.

En resumen, me ha gustado trabajar tanto con ITK como con AMILab, he aprendido múltiples conceptos que desconocía y he profundizado en una rama de la informática interesante y, desde mi punto de vista, con bastante salida en el mercado.

Por último, pero no menos importante, quiero hacer un recorrido por los resultados obtenidos y comparar aquellos más relevantes ayudándome de las gráficas realizadas y de las imágenes capturadas.

En general, los resultados obtenidos han sido mucho mejores de lo esperado, ya que el método ITK es menos especializado que el método base y sinceramente no creía que pudiese conseguir que funcionase correctamente. Cierto es que detrás de ese funcionamiento existe un trabajo de pruebas y búsqueda de los mejores parámetros e imágenes de entrada.

Para todos los datos existe una pérdida de precisión respecto al método base, se puede apreciar en los resultados que las arterias segmentadas con el método ITK tienen menos definición de detalles y son ligeramente más ``delgadas''. Esto es debido a los parámetros del Level Sets, se debería ``jugar'' un poco más con ellos para intentar conseguir resultados mejores. No obstante, como se puede ver, gracias a la medida de evaluación ``Dice'' \ref{fig:graf1}, los porcentajes de superposición con el resultado ideal varían entre un 60 y un 80$\%$ de acierto, salvo casos excepcionales que debido a problemas concretos, como calcificaciones, se han obtenido valores inferiores al 50$\%$.

Se puede destacar que el tiempo de ejecución del método ITK es inferior al método base \ref{fig:graf4}. Esto es debido a que el cálculo de la medida de Vesselness en el método base requiere más tiempo que en el método ITK, debido a la especialización del mismo.

Por tanto, se puede concluir que el método base es mejor que el método ITK, ya que los resultados obtenidos se aproximan más a valores ideales. No obstante, no se debe olvidar que el método base está bastante especializado para la segmentación de carótidas mientras que el método ITK no.


\appendix
\chapter{Resultados}
A continuación se muestran los resultados obtenidos para los 15 datos de entrada y con los dos métodos de segmentación de carótidas. A la izquierda de la imagen se ve el resultado utilizando el método base, mientras que a la derecha se encuentra el resultado usando el método ITK.

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re000.png}%ext=pdf,jpg,png
\caption{challenge 000}
\label{fig:re000}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re001.png}%ext=pdf,jpg,png
\caption{challenge 001}
\label{fig:re001}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re002.png}%ext=pdf,jpg,png
\caption{challenge 002}
\label{fig:re002}
\end{figure}
\end{landscape}


\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re003.png}%ext=pdf,jpg,png
\caption{challenge 003}
\label{fig:re003}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re004.png}%ext=pdf,jpg,png
\caption{challenge 004}
\label{fig:re004}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re005.png}%ext=pdf,jpg,png
\caption{challenge 005}
\label{fig:re005}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re006.png}%ext=pdf,jpg,png
\caption{challenge 006}
\label{fig:re006}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re007.png}%ext=pdf,jpg,png
\caption{challenge 007}
\label{fig:re007}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re008.png}%ext=pdf,jpg,png
\caption{challenge 008}
\label{fig:re008}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re100.png}%ext=pdf,jpg,png
\caption{challenge 100}
\label{fig:re100}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re101.png}%ext=pdf,jpg,png
\caption{challenge 101}
\label{fig:re101}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re102.png}%ext=pdf,jpg,png
\caption{challenge 102}
\label{fig:re102}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re200.png}%ext=pdf,jpg,png
\caption{challenge 200}
\label{fig:re200}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re201.png}%ext=pdf,jpg,png
\caption{challenge 201}
\label{fig:re201}
\end{figure}
\end{landscape}

\begin{landscape}
\newpage
\thispagestyle{empty}
\begin{figure}
%\centering
\includegraphics[scale=0.6]{re202.png}%ext=pdf,jpg,png
\caption{challenge 202}
\label{fig:re202}
\end{figure}
\end{landscape}

\chapter{Manuales de usuario}

\section{¿Cómo compilar AMILab con Visual Studio?}
Para compilar AMILab con Visual Studio se deberán seguir los siguientes puntos:
\begin{itemize}
\item Descargar e instalar CMake.
\item Descargar los ficheros fuente de ITK.
\item Configurar ITK con CMake deshabilitando todas las opciones de compilación (doxygen, ejemplos, librerías compartidas y testing).
\item Compilar ITK con VC++ en modo ``Release''.
\item Descargar los ficheros fuente de VTK.
\item Configurar VTK con CMake deshabilitando todas las opciones de compilación (documentación, ejemplos, librerías compartidas, testing).
\item Compilar VTK con VC++ en modo ``Release''.
\item Descargar wxWidgets.
\item Cambiar la macro wxUSE\_GLCANVAS de 0 a 1 en el fichero {\em include/wx/msw/setup0.h, include/wx/msw/setup.h, include/wx/setup.h, include/wx/setup\_inc.h}.
\item Compilar wxWidgets con VC++ en modo ``Release'' (el proyecto está wxWidgets/wxWidgets-2.8.10/build/msw).
\item Para la versión de desarrollo de AMILab (trunk subversion), se debe compilar la librería ``stc contrib'' que se encuentra en {\em contrib/src/stc}.
\item Después, se debe copiar {\em contrib/include/wx/stc} dentro de {\em include/wx}.
\item Descargar ``pthreads-w32-x-x-x-release.exe'' y ejecutarlo.
\item Descargar los ficheros fuente ``bzip2 zip'' y ``zlib zip''.
\item Descomprimir bzip2 y zlib.
\item Poner los ficheros fuente de bzip2 y zlib en un directorio que el nombre no contenga espacios en blanco.
\item Descargar los ficheros fuente de Boost.
\item Ejecutar {\em sourceBoost/tools/jam/build\_dist.bat}.
\item Copiar {\em sourceBoost/tools/jam/stage/bin.ntx86/bjam.exe} a {\em sourceBoost/}.
\item Cambiar la macro en {\em zlib-x.x.x-src/src/zlib/x.x.x/zlib-x.x.x/zconf.h}:

\#if 1           /* HAVE\_UNISTD\_H -- this line is updated by ./configure */

\#  include $<$sys/types.h$>$ /* for off\_t */

\#  include $<$unistd.h$>$    /* for SEEK\_* and off\_t */

\#  ifdef VMS

\#    include $<$unixio.h$>$   /* for off\_t */

\#  endif

\#  define z\_off\_t off\_t

\#endif
 
a
 
\#if 0           /* HAVE\_UNISTD\_H -- this line is updated by ./configure */

\#  include $<$sys/types.h$>$ /* for off\_t */

\#  include $<$unistd.h$>$    /* for SEEK\_* and off\_t */

\#  ifdef VMS

\#    include $<$unixio.h$>$   /* for off\_t */

\#  endif

\#  define z\_off\_t off\_t

\#endif
\item Ejecutar en la consola de windows:
 {\em bjam.exe toolset=msvc-9.0 link=static -sNO\_COMPRESSION=0 
 -sZLIB\_INCLUDE=D:/Universidad/PFC/pruebazb/zlib-1.2.3-src/src/zlib/1.2.3/zlib-1.2.3 
 -sZLIB\_SOURCE=D:/Universidad/PFC/pruebazb/zlib-1.2.3-src/src/zlib/1.2.3/zlib-1.2.3 
 -sBZIP2\_INCLUDE=D:/Universidad/PFC/pruebazb/bzip2-1.0.5/bzip2-1.0.5 
 -sBZIP2\_SOURCE=D:/Universidad/PFC/pruebazb/bzip2-1.0.5/bzip2-1.0.5
 --build-type=complete --with-iostreams --with-filesystem --with-regex --with-date\_time install}
\item Descargar tortoisesvn
\item Copiar {\em glext.h} a {\em C:/Program Files/Microsoft SDKs/Windows/v6.0A/Include/gl}
\item Descargar AMILab.
\item Configurar libAMIFluid con CMake.
\item Compilar libAMIFluid con VC++ en modo ``Release''.
\item Configurar AMILab con CMake.
\item Escribir ``/NODEFAULTLIB:LIBCMTD'' en la línea de comandos de VC++ (este paso es automático para las versiones superiores a 2.0.4).
\item Compilar AMILab con VC++ en modo ``Release''.
\item Copiar la librería ``pthreadVC2.dll'' al directorio dónde esté el ejecutable ``amilab\_x.x.x.exe''.
\item Descargar Bison para Windows en un directorio que no contenga espacios en blanco.
\item Poner como variable de entorno la ruta a los ficheros binarios de Bison (se debe reiniciar para que este cambio tenga efecto).
\item Descargar cygwin.
\item Inslatar Flex con cygwin.
\item Activar ``AMI\_USE\_FLEXBISON'' en la configuración de CMake para AMILab.
\item Poner el directoria ``include'' de Flex como {\em src/Language/FlexInclude}.
\item Generar el proyecto y compilar.
\end{itemize}

\section{Script Segmentación de Carótidas}
Este script proporciona una interfaz para calcular el método ITK aplicado al ``Carotid Bifurcation Workshop''.

Para utilizar este script primero se debe comprobar el fichero de configuración ``carotidchallenge\_config.amil''. Se debe especificar los siguientes parámetros:
\begin{enumerate}
  \item Data\_dir = directorio dónde se encuentran los datos.
  \item Groundtruth\_dir = directorio dónde se encuentran los datos referencia (groundtruth).
  \item Results\_dir = directorio dónde se guardarán los resultados obtenidos.
  \item Evaluation\_bindir = directorio de evaluación del método.
  \item Evaluation\_scriptdir = directorio de evaluación del método.
\end{enumerate}
La interfaz se divide en una serie de páginas:
\begin{itemize}
\item Input Page \ref{fig:e1}: si se quiere utilizar el modo avanzado se deberá marcar la opción ``Advanced Mode''. De esta manera se podrán cambiar todas las opciones en la pestaña ``Adv''. Además, también se activarán algunas pestañas como:
\begin{itemize}
\item Crop, utiliza para cortar la imagen. La imagen es cortada por defecto, pero se pueden cambiar los límites.
\item Dir, se pueden cambiar los directorios a utilizar por defecto. Además, si se marca la opción No\_interaction no se mostrarán cuadros de diálogo durante la ejecución del proceso.
\item Adv, ver la explicación que sigue.
\end{itemize}
Seleccionar el Datacenter: Erasmus MC, Hadassah or Louis Pradel.

Seleccionar el Datatype: Training, Testing o On-site. El modo Testing no tiene groundtruth.

Seleccionar el número del dato (Data Number).

Para leer y cortar la imagen se utiliza el botón {\bf Read Data}.

Para leer el groundtruth se usará el boton {\bf Read GT}.

\item Prob+Speed Page \ref{fig:e2}: 
Utilizar el botón {\bf Apply} para calcular LocalStats.

Se puede cambiar la intensidad máxima y mínima para el cálculo de vesselness. Los valores 1150 y 1600 están fijados por defecto.

Para calcular la medida de vesselness se usará el botón {\bf Vesselness}.

Por último para guardar el resultado, se utilizará el botón {\bf Save}. Así se podrá leer el resultado de la medida de vesselness utilizando el botón {\bf Read}.

\item Run Page \ref{fig:e3}:
Para crear los caminos, tanto internos como externos, se debe utilizar el boton {\bf Create}. Con el botón {\bf Save} se podrán guardar los resultados. Para leerlos basta con pulsar el botón {\bf Read}.

Para calcular la bifurcación se pueden cambiar los parámetros de Threshold y Resample pero los valores fijados por defecto hacen que la detección de la misma funcione correctamente. Para calcularla se debe pulsar el boton {\bf Junction}.

Se podrá ver el resultado obtenido pulsando el boton {\bf Display}. Se mostrará una image, la esfera verde es la bifurcación.

Para guardar el resultado se pulsará el botón {\bf Save}.

Para el cálculo del Level Sets a partir de los camino se pulsará primero el botón {\bf External} para obtener la segmentación externa, a continuación se pulsará el botón {\bf Internal} y se obtendrá la segmentación interna. 

Para poder mostrar el resultado se debe guardar primero.

\item Adv Page \ref{fig:e4}: 
En esta página se muestran las opciones avanzadas. Para poder usarlas habrá que utilizar las ayudas correspondientes.

\item Help Page \ref{fig:e5}:
Se muestra la ayuda del script.
\end{itemize}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{e1.png}%ext=pdf,jpg,png
\caption{Script Segmentación de Carótidas}
\label{fig:e1}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{e2.png}%ext=pdf,jpg,png
\caption{Script Segmentación de Carótidas}
\label{fig:e2}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{e3.png}%ext=pdf,jpg,png
\caption{Script Segmentación de Carótidas}
\label{fig:e3}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{e4.png}%ext=pdf,jpg,png
\caption{Script Segmentación de Carótidas}
\label{fig:e4}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{e5.png}%ext=pdf,jpg,png
\caption{Script Segmentación de Carótidas}
\label{fig:e5}
\end{figure}
\end{landscape}

\section{Script Vesselness}
Este script proporciona una interfaz al usuario para calcular la medida de vesselness de objetos tubulares partiendo de la matriz Hessiana.

Los diferentes pasos para obtener la medida de Vesselness son:
\begin{itemize}
\item Seleccionar y cargar la imagen de entrada.
\item Seleccionar la dimensión de la imagen (2D o 3D).
\item Seleccionar los valores de sigmaMin y sigmaMax.
\item Seleccionar el número de escalas.
\item Ejecutar el filtro.
\item Mostrar el resultado.
\end{itemize}
La interfaz se divide en varias páginas:
\begin{itemize}
\item Input Image \ref{fig:ve1}: lo primero de todo es elegir la imagen de entrada y cargarla mediante el botón {\bf Load}. El parámetro de Dimensión permite elegir la dimensión de la imagen (2D o 3D).

\item Param Page \ref{fig:ve2}:
Seleccionar valor máximo y mínimo de sigma.
Seleccionar el número de escalas.
Ahora se puede ejecutar el filtro con el botón {\bf Run}.
Para ver el resultado se debe pulsar el botón de {\bf Display}.
Por último, el resultado se puede guardar mediante el botón de {\bf Save}.

\item Help Page \ref{fig:ve3}: se muestra la ayuda del script.
\end{itemize}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{ve1.png}%ext=pdf,jpg,png
\caption{Script Vesselness}
\label{fig:ve1}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{ve2.png}%ext=pdf,jpg,png
\caption{Script Vesselness}
\label{fig:ve2}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{ve3.png}%ext=pdf,jpg,png
\caption{Script Vesselness}
\label{fig:ve3}
\end{figure}
\end{landscape}

\section{Script Fast Marching}
Este script proporciona una interfaz para el cálculo del Fast Marching.
Para obtener el cálculo de Fast Marching se han de seguir los siguientes pasos:
\begin{enumerate}
\item Seleccionar el modo de carga de la imagen de entrada (NormGradient o User Velocity Image).
	\begin{enumerate}
	\item Si se selecciona NormGradient se debe seguir la ayuda del filtro SigmoidFilter para saber como utilizarlo.
	\item Si se selecciona User Velocity Image, basta con cargar la imagen de entrada y fijar la dimensión de la misma (2D o 3D).
	\end{enumerate}
\item Seleccionar el punto de partida con el botón {\bf Set Seed Point}.
\item Seleccionar el valor de la variable ``stopping time''.
\item Seleccionar el valor máximo y mínimo del umbral para el filtro binario.
\item Seleccionar el valor del punto que representa el frente inicial.
\item Ejecutar el filtro.
\item Mostrar el resultado.
\end{enumerate}
Esta interfaz se divide en diferentes páginas:
\begin{itemize}
\item Init Page \ref{fig:fast1}, \ref{fig:fast2}: si se selecciona la opción de NormGradient se debe seguir la ayuda del filtro Sigmoid. Sin embargo, si seleccionamos User Velocity Image se tendrá que elegir la imagen de entrada y cargarla con el botón {\bf Load}. Por último, el botón {\bf Dimension} nos permitirá elegir entre 2D o 3D.

\item Param Page \ref{fig:fast3}:
\begin{itemize}
\item Seleccionar el punto de partida con el botón {\bf Set Seed Point}. Aparecerá una imagen y con el botón central del ratón se podrá seleccionar dicho punto. Para que se guarde se debe volver a pulsar el botón de {\bf Set Seed Point}.
\item Seleccionar el valor de la variable ``stopping time''.
\item Seleccionar el máximo y el mínimo valor de umbral para el filtro binario. Esto se utilizará para hacer un umbralizado de la imagen de salida del filtro Fast Marching.
\item Por último se ejecutará el filtro mediante el botón {\bf Run}. Para ver el resultado basta con pulsar el botón de {\bf Display}.
\end{itemize}

\item Help Page \ref{fig:fast4}: se muestra la ayuda del script.
\end{itemize}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{fast1.png}%ext=pdf,jpg,png
\caption{Script Fast Marching}
\label{fig:fast1}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{fast2.png}%ext=pdf,jpg,png
\caption{Script Fast Marching}
\label{fig:fast2}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{fast3.png}%ext=pdf,jpg,png
\caption{Script Fast Marching}
\label{fig:fast3}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{fast4.png}%ext=pdf,jpg,png
\caption{Script Fast Marching}
\label{fig:fast4}
\end{figure}
\end{landscape}

\section{Script BackTracking}
Este script proporciona una interfaz para crear un camino en imágenes 3D.

Los diferentes pasos para obtener el camino son:
\begin{enumerate}
\item Seleccionar y cargar la imagen de entrada.
\item Seleccionar y cargar la imagen de velocidad, si es que se desea utilizar.
\item Seleccionar el punto de comienzo y de final.
\item Si se quiere guardar la imagen resultante de aplicar el filtro Fast Marching se debe activar la casilla Save FastMarching Output.
\item Seleccionar el valor de epsilon.
\item Seleccionar el valor de coste máximo (maxcost).
\item Si se utiliza la imagen de velocidad se debe marcar la opción Use Speed, después se debe seleccionar el valor máximo y mínimo de intensidad y el valor de la velocidad.
\item Seleccionar el valor del tamaño del paso (step size).
\item Seleccionar el valor de la longitud máxima (maxlength).
\item Ejecutar el filtro.
\item Mostrar el resultado.
\end{enumerate}

La interfaz está dividida en varias páginas:
\begin{itemize}
\item Init Page \ref{fig:back1}: lo primero de todo es elegir y cargar la imagen de entrada mediante el botón {\bf Load}. Después, si así lo decide el usuario, se debe elegir y cargar la imagen de velocidad mediante el botón {\bf Load}. 

Para seleccionar el punto inicial se hará mediante el botón {\bf Set Start Point}. Aparecerá una imagen y con el botón central del ratón se seleccionará el punto, a continuación se pulsará de nuevo el botón {\bf Start Point} para guardarlo.
Para seleccionar el punto final se hará mediante el botón {\bf Set End Point}. Aparecerá una imagen y con el botón central del ratón se seleccionará el punto, a continuación se pulsará de nuevo el botón {\bf Set End Point} para guardarlo.

\item Param Page \ref{fig:back2}: si se desea guardar o mostrar la imagen resultado del filtro Fast Marching, se debe activarla casilla Save FastMarching Output.

Seleccionar el valor de epsilon. Este se utiliza, tanto en el filtro Fast Marching como en la creación del camino.
Seleccionar el valor de maxcost, el valor de tiempo máximo.

Si se quiere utilizar la imagen de velocidad se debe activar la casilla Use Speed. Después se podrá seleccionar el máximo y el mínimo valor de la intensidad.
Seleccionar el valor de la velocidad.

Seleccionar el valor del tamaño del paso para la evolución.

Seleccionar el valor máximo de longitud. La distancia máxima euclidiana del camino.

Pulsar el botón {\bf Run} para ejecutar el filtro.
Para mostrar el resultado pulsar el botón {\bf Display}.

\item Help Page \ref{fig:back3}: se muestra la ayuda del script.

\end{itemize}
\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{back1.png}%ext=pdf,jpg,png
\caption{Script BackTracking}
\label{fig:back1}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{back2.png}%ext=pdf,jpg,png
\caption{Script BackTracking}
\label{fig:back2}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{back3.png}%ext=pdf,jpg,png
\caption{Script BackTracking}
\label{fig:back3}
\end{figure}
\end{landscape}

\section{Script Level Sets}
Este script proporciona una interfaz para segmentar estructuras en imágenes basadas en mapas de bordes (edge map).

Los pasos que se han de seguir para obtener la segmentación son:
\begin{enumerate}
\item Seleccionar y cargar la imagen inicial.
\item Seleccionar y cargar el mapa de bordes.
\item Seleccionar la dimensión de la imagen (2D o 3D).
\item Seleccionar el valor de la variable errorRMS.
\item Seleccionar el número de iteraciones que el filtro se ejecutará.
\item Seleccionar el valor de la variable de advección.
\item Seleccionar el valor de la variable de curvatura.
\item Seleccionar el valor de la variable de propagación.
\item Ejecutar el filtro.
\item Mostrar el resultado.
\end{enumerate}

Esta interfaz se divide en un número de páginas:
\begin{itemize}
\item Init Page \ref{fig:level1}: lo primero es elegir y cargar la imagen inicial mediante el botón {\bf Load}. Este es el modelo de Level Set inicial.

A continuación, se debe elegir y cargar la imagen de mapa de bordes con el botón {\bf Load}. Esta es la imagen de características que será utilizada para la función de velocidad en la ecuación de Level Sets.

El parámetro {\bf Dimension} permite seleccionar la dimensión de la imagen (2D o 3D).

\item Level Sets Page \ref{fig:level2}: para aplicar el filtro se deben fijar una serie de parámetros:
\begin{itemize}
\item Seleccionar el valor de ErrorRMS, el máximo error permitido en la solución.
\item Seleccionar el número de iteraciones que el filtro se ejecutará.
\item Seleccionar el valor de la variable advección.
\item Seleccionar el valor de la variable de curvatura. Este parámetro permite aumentar la influencia de la curvatura en el movimiento de la superficie. Si tenemos valores altos de advección y propagación conseguiremos superficies más suavizadas.
\item Seleccionar el valor de la variable de propagación.
\end{itemize}
Ahora se puede ejecutar el filtro con el botón {\bf Run}.
Para ver el resultado se deberá pulsar el botón {\bf Display}.

\item Help Page \ref{fig:level3}: se muestra la ayuda del script.
\end{itemize}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{level1.png}%ext=pdf,jpg,png
\caption{Script Level Sets}
\label{fig:level1}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{level2.png}%ext=pdf,jpg,png
\caption{Script Level Sets}
\label{fig:level2}
\end{figure}
\end{landscape}

\begin{landscape}
\begin{figure}
\centering
\includegraphics[scale=0.7]{level3.png}%ext=pdf,jpg,png
\caption{Script Level Sets}
\label{fig:level3}
\end{figure}
\end{landscape}


\begin{thebibliography}{1}
\bibitem{ITK05} L. Ibáñez, W. Schroeder, L. Ng, J. Cates.{\em ``The ITK Software Guide''} 2005
\bibitem{VTK01} W. Schroeder {\em ``The VTK User´s Guide''} Kitware,Inc. 2001
\bibitem{wx05}	J. Smart, K. Hock, S. Csomor {\em ``Cross-Platform GUI Programming with wxWidgets''} Prentice Hall PTR 2005
\bibitem{WorkshopRules} R.Hameeteman M.Zuluaga L.Joskowicz M.Freiman T. von Walsum {\em ``Carotid Lumen Segmentation and Stenosis Grading Challenge''} 2009
\bibitem{P06} R.S.Pressman {\em ``Ingeniería del Software''} Editorial McGraw-Hill, 6ª Edición, 2006
\bibitem{Boost} Boost C++ Libraries {\em \href {http://en.wikipedia.org/wiki/Boost\_C\%2B\%2B\_Libraries\#Overview}{http://en.wikipedia.org/wiki/Boost\_C\%2B\%2B\_Libraries\#Overview}}
\bibitem{VTK} The Visualization Toolkit {\em \href{http://www.vtk.org/}{http://www.vtk.org/}}
\bibitem{PThreads} PThreads - POSIX Threads {\em \href{https://computing.llnl.gov/tutorials/pthreads/}{https://computing.llnl.gov/tutorials/pthreads/}}
\bibitem{PThreads2} Pthreads Win32 {\em \href{http://sourceware.org/pthreads-win32/}{http://sourceware.org/pthreads-win32/}}
\bibitem{CMake} CMake {\em \href{http://en.wikipedia.org/wiki/CMake}{http://en.wikipedia.org/wiki/CMake}}
\bibitem{AMILab} AMILab {\em \href{http://www.ctm.ulpgc.es/amilab\_dokuwiki/dokuwiki/doku.php}{http://www.ctm.ulpgc.es/amilab\_dokuwiki/dokuwiki/doku.php}}
\bibitem{Lex} Lex {\em \href{http://es.wikipedia.org/wiki/Herramienta\_de\_programaci\%C3\%B3n\_lex}{http://es.wikipedia.org/wiki/Herramienta\_de\_programaci\%C3\%B3n\_lex}}
\bibitem{Yacc} Yacc {\em \href{http://es.wikipedia.org/wiki/Yacc}{http://es.wikipedia.org/wiki/Yacc}}
\bibitem{Template} Template {\em \href{http://en.wikipedia.org/wiki/Template\_(programming)\#Advantages\_and\_disadvantages}{http://en.wikipedia.org/wiki/Template\_(programming)\#Advantages\_and\_disadvantages}}
\bibitem{ProgG} Programación genérica {\em \href{http://es.wikipedia.org/wiki/Programaci\%C3\%B3n\_gen\%C3\%A9rica}{http://es.wikipedia.org/wiki/Programaci\%C3\%B3n\_gen\%C3\%A9rica}}
\bibitem{ITK} ITK {\em \href {http://www.itk.org/}{http://www.itk.org/}}
\bibitem{MITK} MITK {\em \href{http://www.mitk.org/}{http://www.mitk.org/}}
\bibitem{VTKEdge} VTKEdge {\em \href {http://www.vtkedge.org/}{http://www.vtkedge.org/}}
\bibitem{VTK} VTK {\em \href {http://www.vtk.org/}{http://www.vtk.org/}}
\bibitem{IGSTK} IGSTK {\em \href {http://www.igstk.org/}{http://www.igstk.org/}}
\bibitem{CT} Tomografía computarizada {\em \href{http://en.wikipedia.org/wiki/Computed\_tomography\#Diagnostic\_use}{http://en.wikipedia.org/wiki/Computed\_tomography\#Diagnostic\_use}}
\bibitem{CT2} Tomografía computarizada {\em \href{http://www.imaginis.com/ct-scan/why-is-ct-performed-2}{http://www.imaginis.com/ct-scan/why-is-ct-performed-2}}
\bibitem{CT3} Tomografía computarizada {\em \href{http://www.radiologyinfo.org/en/info.cfm?PG=bodyct\#part\_one}{http://www.radiologyinfo.org/en/info.cfm?PG=bodyct\#part\_one}}
\bibitem{Workshop} Artículo Workshop09 {\em \href{http://www.insight-journal.org/browse/publication/672}{http://www.insight-journal.org/browse/publication/672}}
\bibitem{Vesselness} Vesselness {\em \href{http://www.insight-journal.org/browse/publication/163}{http://www.insight-journal.org/browse/publication/163}}
\bibitem{osirix} OsiriX {\em \href{http://www.osirix-viewer.com/}{http://www.osirix-viewer.com/}}
\bibitem{slicer} Slicer {\em \href{http://www.slicer.org/}{http://www.slicer.org/}}
\bibitem{slicer2} Slicer {\em \href{http://wiki.slicer.org/slicerWiki/index.php/Documentation-3.6\#Main\_GUI}{http://wiki.slicer.org/slicerWiki/index.php/Documentation-3.6\#Main\_GUI}}
\end{thebibliography}
\end{document}

%\begin{figure}
%\centering
%\includegraphics[scale=0.7]{image007.PNG}%ext=pdf,jpg,png
%\caption{Neighborhood Iterator \cite{ITK05}}
%\label{fig:iteradorV}
%\end{figure}
